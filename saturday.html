<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1">

<style type="text/css">
@font-face {
font-family: octicons-link;
src: url(data:font/woff;charset=utf-8;base64,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) format('woff');
}
body {
-webkit-text-size-adjust: 100%;
text-size-adjust: 100%;
color: #333;
font-family: "Helvetica Neue", Helvetica, "Segoe UI", Arial, freesans, sans-serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol";
font-size: 16px;
line-height: 1.6;
word-wrap: break-word;
}
a {
background-color: transparent;
}
a:active,
a:hover {
outline: 0;
}
strong {
font-weight: bold;
}
h1 {
font-size: 2em;
margin: 0.67em 0;
}
img {
border: 0;
}
hr {
box-sizing: content-box;
height: 0;
}
pre {
overflow: auto;
}
code,
kbd,
pre {
font-family: monospace, monospace;
font-size: 1em;
}
input {
color: inherit;
font: inherit;
margin: 0;
}
html input[disabled] {
cursor: default;
}
input {
line-height: normal;
}
input[type="checkbox"] {
box-sizing: border-box;
padding: 0;
}
table {
border-collapse: collapse;
border-spacing: 0;
}
td,
th {
padding: 0;
}
* {
box-sizing: border-box;
}
input {
font: 13px / 1.4 Helvetica, arial, nimbussansl, liberationsans, freesans, clean, sans-serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol";
}
a {
color: #4078c0;
text-decoration: none;
}
a:hover,
a:active {
text-decoration: underline;
}
hr {
height: 0;
margin: 15px 0;
overflow: hidden;
background: transparent;
border: 0;
border-bottom: 1px solid #ddd;
}
hr:before {
display: table;
content: "";
}
hr:after {
display: table;
clear: both;
content: "";
}
h1,
h2,
h3,
h4,
h5,
h6 {
margin-top: 15px;
margin-bottom: 15px;
line-height: 1.1;
}
h1 {
font-size: 30px;
}
h2 {
font-size: 21px;
}
h3 {
font-size: 16px;
}
h4 {
font-size: 14px;
}
h5 {
font-size: 12px;
}
h6 {
font-size: 11px;
}
blockquote {
margin: 0;
}
ul,
ol {
padding: 0;
margin-top: 0;
margin-bottom: 0;
}
ol ol,
ul ol {
list-style-type: lower-roman;
}
ul ul ol,
ul ol ol,
ol ul ol,
ol ol ol {
list-style-type: lower-alpha;
}
dd {
margin-left: 0;
}
code {
font-family: Consolas, "Liberation Mono", Menlo, Courier, monospace;
font-size: 12px;
}
pre {
margin-top: 0;
margin-bottom: 0;
font: 12px Consolas, "Liberation Mono", Menlo, Courier, monospace;
}
.select::-ms-expand {
opacity: 0;
}
.octicon {
font: normal normal normal 16px/1 octicons-link;
display: inline-block;
text-decoration: none;
text-rendering: auto;
-webkit-font-smoothing: antialiased;
-moz-osx-font-smoothing: grayscale;
-webkit-user-select: none;
-moz-user-select: none;
-ms-user-select: none;
user-select: none;
}
.octicon-link:before {
content: '\f05c';
}
.markdown-body:before {
display: table;
content: "";
}
.markdown-body:after {
display: table;
clear: both;
content: "";
}
.markdown-body>*:first-child {
margin-top: 0 !important;
}
.markdown-body>*:last-child {
margin-bottom: 0 !important;
}
a:not([href]) {
color: inherit;
text-decoration: none;
}
.anchor {
display: inline-block;
padding-right: 2px;
margin-left: -18px;
}
.anchor:focus {
outline: none;
}
h1,
h2,
h3,
h4,
h5,
h6 {
margin-top: 1em;
margin-bottom: 16px;
font-weight: bold;
line-height: 1.4;
}
h1 .octicon-link,
h2 .octicon-link,
h3 .octicon-link,
h4 .octicon-link,
h5 .octicon-link,
h6 .octicon-link {
color: #000;
vertical-align: middle;
visibility: hidden;
}
h1:hover .anchor,
h2:hover .anchor,
h3:hover .anchor,
h4:hover .anchor,
h5:hover .anchor,
h6:hover .anchor {
text-decoration: none;
}
h1:hover .anchor .octicon-link,
h2:hover .anchor .octicon-link,
h3:hover .anchor .octicon-link,
h4:hover .anchor .octicon-link,
h5:hover .anchor .octicon-link,
h6:hover .anchor .octicon-link {
visibility: visible;
}
h1 {
padding-bottom: 0.3em;
font-size: 2.25em;
line-height: 1.2;
border-bottom: 1px solid #eee;
}
h1 .anchor {
line-height: 1;
}
h2 {
padding-bottom: 0.3em;
font-size: 1.75em;
line-height: 1.225;
border-bottom: 1px solid #eee;
}
h2 .anchor {
line-height: 1;
}
h3 {
font-size: 1.5em;
line-height: 1.43;
}
h3 .anchor {
line-height: 1.2;
}
h4 {
font-size: 1.25em;
}
h4 .anchor {
line-height: 1.2;
}
h5 {
font-size: 1em;
}
h5 .anchor {
line-height: 1.1;
}
h6 {
font-size: 1em;
color: #777;
}
h6 .anchor {
line-height: 1.1;
}
p,
blockquote,
ul,
ol,
dl,
table,
pre {
margin-top: 0;
margin-bottom: 16px;
}
hr {
height: 4px;
padding: 0;
margin: 16px 0;
background-color: #e7e7e7;
border: 0 none;
}
ul,
ol {
padding-left: 2em;
}
ul ul,
ul ol,
ol ol,
ol ul {
margin-top: 0;
margin-bottom: 0;
}
li>p {
margin-top: 16px;
}
dl {
padding: 0;
}
dl dt {
padding: 0;
margin-top: 16px;
font-size: 1em;
font-style: italic;
font-weight: bold;
}
dl dd {
padding: 0 16px;
margin-bottom: 16px;
}
blockquote {
padding: 0 15px;
color: #777;
border-left: 4px solid #ddd;
}
blockquote>:first-child {
margin-top: 0;
}
blockquote>:last-child {
margin-bottom: 0;
}
table {
display: block;
width: 100%;
overflow: auto;
word-break: normal;
word-break: keep-all;
}
table th {
font-weight: bold;
}
table th,
table td {
padding: 6px 13px;
border: 1px solid #ddd;
}
table tr {
background-color: #fff;
border-top: 1px solid #ccc;
}
table tr:nth-child(2n) {
background-color: #f8f8f8;
}
img {
max-width: 100%;
box-sizing: content-box;
background-color: #fff;
}
code {
padding: 0;
padding-top: 0.2em;
padding-bottom: 0.2em;
margin: 0;
font-size: 85%;
background-color: rgba(0,0,0,0.04);
border-radius: 3px;
}
code:before,
code:after {
letter-spacing: -0.2em;
content: "\00a0";
}
pre>code {
padding: 0;
margin: 0;
font-size: 100%;
word-break: normal;
white-space: pre;
background: transparent;
border: 0;
}
.highlight {
margin-bottom: 16px;
}
.highlight pre,
pre {
padding: 16px;
overflow: auto;
font-size: 85%;
line-height: 1.45;
background-color: #f7f7f7;
border-radius: 3px;
}
.highlight pre {
margin-bottom: 0;
word-break: normal;
}
pre {
word-wrap: normal;
}
pre code {
display: inline;
max-width: initial;
padding: 0;
margin: 0;
overflow: initial;
line-height: inherit;
word-wrap: normal;
background-color: transparent;
border: 0;
}
pre code:before,
pre code:after {
content: normal;
}
kbd {
display: inline-block;
padding: 3px 5px;
font-size: 11px;
line-height: 10px;
color: #555;
vertical-align: middle;
background-color: #fcfcfc;
border: solid 1px #ccc;
border-bottom-color: #bbb;
border-radius: 3px;
box-shadow: inset 0 -1px 0 #bbb;
}
.pl-c {
color: #969896;
}
.pl-c1,
.pl-s .pl-v {
color: #0086b3;
}
.pl-e,
.pl-en {
color: #795da3;
}
.pl-s .pl-s1,
.pl-smi {
color: #333;
}
.pl-ent {
color: #63a35c;
}
.pl-k {
color: #a71d5d;
}
.pl-pds,
.pl-s,
.pl-s .pl-pse .pl-s1,
.pl-sr,
.pl-sr .pl-cce,
.pl-sr .pl-sra,
.pl-sr .pl-sre {
color: #183691;
}
.pl-v {
color: #ed6a43;
}
.pl-id {
color: #b52a1d;
}
.pl-ii {
background-color: #b52a1d;
color: #f8f8f8;
}
.pl-sr .pl-cce {
color: #63a35c;
font-weight: bold;
}
.pl-ml {
color: #693a17;
}
.pl-mh,
.pl-mh .pl-en,
.pl-ms {
color: #1d3e81;
font-weight: bold;
}
.pl-mq {
color: #008080;
}
.pl-mi {
color: #333;
font-style: italic;
}
.pl-mb {
color: #333;
font-weight: bold;
}
.pl-md {
background-color: #ffecec;
color: #bd2c00;
}
.pl-mi1 {
background-color: #eaffea;
color: #55a532;
}
.pl-mdr {
color: #795da3;
font-weight: bold;
}
.pl-mo {
color: #1d3e81;
}
kbd {
display: inline-block;
padding: 3px 5px;
font: 11px Consolas, "Liberation Mono", Menlo, Courier, monospace;
line-height: 10px;
color: #555;
vertical-align: middle;
background-color: #fcfcfc;
border: solid 1px #ccc;
border-bottom-color: #bbb;
border-radius: 3px;
box-shadow: inset 0 -1px 0 #bbb;
}
.task-list-item {
list-style-type: none;
}
.task-list-item+.task-list-item {
margin-top: 3px;
}
.task-list-item input {
margin: 0 0.35em 0.25em -1.6em;
vertical-align: middle;
}
:checked+.radio-label {
z-index: 1;
position: relative;
border-color: #4078c0;
}
.sourceLine {
display: inline-block;
}
code .kw { color: #000000; }
code .dt { color: #ed6a43; }
code .dv { color: #009999; }
code .bn { color: #009999; }
code .fl { color: #009999; }
code .ch { color: #009999; }
code .st { color: #183691; }
code .co { color: #969896; }
code .ot { color: #0086b3; }
code .al { color: #a61717; }
code .fu { color: #63a35c; }
code .er { color: #a61717; background-color: #e3d2d2; }
code .wa { color: #000000; }
code .cn { color: #008080; }
code .sc { color: #008080; }
code .vs { color: #183691; }
code .ss { color: #183691; }
code .im { color: #000000; }
code .va {color: #008080; }
code .cf { color: #000000; }
code .op { color: #000000; }
code .bu { color: #000000; }
code .ex { color: #000000; }
code .pp { color: #999999; }
code .at { color: #008080; }
code .do { color: #969896; }
code .an { color: #008080; }
code .cv { color: #008080; }
code .in { color: #008080; }
</style>
<style>
body {
  box-sizing: border-box;
  min-width: 200px;
  max-width: 980px;
  margin: 0 auto;
  padding: 45px;
  padding-top: 0px;
}
</style>

</head>

<body>

<h1 id="news-popularity-saturday-data">News Popularity Saturday Data</h1>
<p>Shuang Du 10/16/2020</p>
<h2 id="load-libraries">Load Libraries</h2>
<pre><code>library(readxl);
library(tidyverse);
library(caret);
library(modelr);
library(rpart);
library(kableExtra);</code></pre>
<h2 id="read-in-data">Read in Data</h2>
<pre><code>getData &lt;- function(day) {

  newsPopData &lt;- read_csv(&quot;raw_data/OnlineNewsPopularity.csv&quot;)
  
  if (day == &#39;monday&#39;) {
    newsPopData &lt;- newsPopData %&gt;% filter(weekday_is_monday == 1)
  } else if(day == &#39;tuesday&#39;) {
    newsPopData &lt;- newsPopData %&gt;% filter(weekday_is_tuesday == 1)
  } else if(day == &#39;wednesday&#39;) {
    newsPopData &lt;- newsPopData %&gt;% filter(weekday_is_wednesday == 1)
  } else if(day == &#39;thursday&#39;) {
    newsPopData &lt;- newsPopData %&gt;% filter(weekday_is_thursday == 1)
  } else if(day == &#39;friday&#39;) {
    newsPopData &lt;- newsPopData %&gt;% filter(weekday_is_friday == 1)
  } else if(day == &#39;saturday&#39;) {
    newsPopData &lt;- newsPopData %&gt;% filter(weekday_is_saturday == 1)
  } else if(day == &#39;sunday&#39;) {
    newsPopData &lt;- newsPopData %&gt;% filter(weekday_is_sunday == 1)
  } else {
    stop(&quot;Invalid date&quot;)
  }
  return(newsPopData)
}

newsPopData &lt;- getData(params$day)</code></pre>
<h2 id="set-aside-training-data">Set Aside Training Data</h2>
<pre><code>set.seed(92)
trainIndex &lt;- createDataPartition(newsPopData$shares, 
                                  p = 0.7, list = FALSE)

newsPopTrain &lt;- newsPopData[as.vector(trainIndex),];
newsPopTest &lt;- newsPopData[-as.vector(trainIndex),];</code></pre>
<h2 id="center-and-scale">Center and Scale</h2>
<pre><code>preProcValues &lt;- preProcess(newsPopTrain, method = c(&quot;center&quot;, &quot;scale&quot;))
newsPopTrain &lt;- predict(preProcValues, newsPopTrain) 
newsPopTest &lt;- predict(preProcValues, newsPopTest)</code></pre>
<h2 id="summary-of-a-few-variables">Summary of a Few Variables</h2>
<p>The plots below show a histogram of the number of shares for the given day. Scatter plots on the effect of max positive polarity, article time delta and number of videos in the article are also included.</p>
<p>As expected the histogram has a strong right tail, as seem by the summary stats which show a very high maximum and a median severals orders of magnitude lower. This is expected for because of the “viral” nature of online popularity.</p>
<pre><code>summary(newsPopTrain$shares)

##     Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
## -0.25079 -0.17423 -0.13160  0.00000 -0.03416 37.37878

g0 &lt;- ggplot(newsPopTrain, aes(x=shares))
g0 + geom_histogram(binwidth = 0.5) + ggtitle(&#39;Histogram for Number of Shares&#39;) + ylab(&#39;Number of Shares&#39;) + xlab(&#39;Shares&#39;)</code></pre>
<p><img src="data:image/png;base64,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" /><!-- --></p>
<pre><code>summary(newsPopTrain$max_positive_polarity)

##     Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
## -3.09122 -0.71581  0.07599  0.00000  0.86780  0.86780

g1 &lt;- ggplot(newsPopTrain, aes(x = max_positive_polarity, y = shares )) 
g1 + geom_point() + ggtitle(&#39;Scatter of Max Positive Polarity Effect&#39;) + ylab(&#39;Shares&#39;) + xlab(&#39;Max Positive Polarity&#39;)</code></pre>
<p><img src="data:image/png;base64,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" /><!-- --></p>
<pre><code>summary(newsPopTrain$timedelta)

##     Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
## -1.60493 -0.94480 -0.02062  0.00000  0.87055  1.76173

g2 &lt;- ggplot(newsPopTrain, aes(x = timedelta, y = shares )) 
g2 + geom_point() + ggtitle(&#39;Scatter of Article Age Effect&#39;) + ylab(&#39;Shares&#39;) + xlab(&#39;Time Delta&#39;)</code></pre>
<p><img src="data:image/png;base64,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" /><!-- --></p>
<pre><code>summary(newsPopTrain$num_videos)

##     Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
## -0.28543 -0.28543 -0.28543  0.00000 -0.04527 17.48692

g3 &lt;- ggplot(newsPopTrain, aes(x = num_videos, y = shares )) 
g3 + geom_point() + ggtitle(&#39;Scatter of Videos Number Effect&#39;) + ylab(&#39;Shares&#39;) + xlab(&#39;Number of Videos&#39;)</code></pre>
<p><img src="data:image/png;base64,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" /><!-- --></p>
<h2 id="modeling">Modeling</h2>
<h3 id="standard-tree-based-model-no-ensemble">Standard Tree Based Model (no ensemble)</h3>
<p>The type of model being fitted here is a decision tree. The tree splits are based on minimizing the residual sum of squares for each region.</p>
<pre><code>rpartFit &lt;- train(shares ~ timedelta + n_tokens_title + n_tokens_content + n_unique_tokens + n_non_stop_words + n_non_stop_unique_tokens
                 + num_hrefs + num_self_hrefs + num_imgs + num_videos + average_token_length + num_keywords + data_channel_is_lifestyle +
                 data_channel_is_entertainment + data_channel_is_bus + data_channel_is_socmed + data_channel_is_tech + data_channel_is_world +
                 self_reference_min_shares + self_reference_max_shares + self_reference_avg_sharess + global_subjectivity + global_sentiment_polarity
                 + global_rate_positive_words + global_rate_negative_words + rate_positive_words + rate_negative_words + avg_positive_polarity +
                  min_positive_polarity + max_positive_polarity + avg_negative_polarity + min_negative_polarity + max_negative_polarity + title_subjectivity
                 + title_sentiment_polarity + abs_title_subjectivity + abs_title_sentiment_polarity, data = newsPopTrain,
             method = &quot;rpart&quot;,
             trControl = trainControl(method = &quot;cv&quot;, number = 10),
             tuneGrid = data.frame(cp = c(.001,.01,.015,.02,.03,.04,.05))
             )
rpartFit

## CART 
## 
## 1719 samples
##   37 predictor
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 1547, 1546, 1546, 1549, 1547, 1546, ... 
## Resampling results across tuning parameters:
## 
##   cp     RMSE       Rsquared    MAE      
##   0.001  0.8204433  0.01499185  0.2560560
##   0.010  0.7974176  0.01183471  0.2430168
##   0.015  0.7967943  0.01172109  0.2418335
##   0.020  0.7963462  0.01170845  0.2401989
##   0.030  0.7963462  0.01170845  0.2401989
##   0.040  0.7963462  0.01170845  0.2401989
##   0.050  0.7961987  0.01300841  0.2400282
## 
## RMSE was used to select the optimal model using the smallest value.
## The final value used for the model was cp = 0.05.

# create the prediction
pred1 &lt;- predict(rpartFit, newdata = newsPopTest)

# compare the prediction vs the actual
resample1 &lt;- postResample(pred1, obs = newsPopTest$shares)
resample1

##         RMSE     Rsquared          MAE 
## 4.499436e-01 8.661662e-06 1.967980e-01</code></pre>
<h3 id="boosted-tree-based-model">Boosted Tree Based Model</h3>
<p>A boosted tree is an ensemble method which slowly approaches the tree prediction which would result from the original data. In general, an ensemble model model will have a lower RSME than a single tree model.</p>
<pre><code>gbmFit &lt;- train(shares ~ timedelta + n_tokens_title + n_tokens_content + n_unique_tokens + n_non_stop_words + n_non_stop_unique_tokens
                 + num_hrefs + num_self_hrefs + num_imgs + num_videos + average_token_length + num_keywords + data_channel_is_lifestyle +
                 data_channel_is_entertainment + data_channel_is_bus + data_channel_is_socmed + data_channel_is_tech + data_channel_is_world +
                 self_reference_min_shares + self_reference_max_shares + self_reference_avg_sharess + global_subjectivity + global_sentiment_polarity
                 + global_rate_positive_words + global_rate_negative_words + rate_positive_words + rate_negative_words + avg_positive_polarity +
                  min_positive_polarity + max_positive_polarity + avg_negative_polarity + min_negative_polarity + max_negative_polarity + title_subjectivity
                 + title_sentiment_polarity + abs_title_subjectivity + abs_title_sentiment_polarity, data = newsPopTrain,
             method = &quot;gbm&quot;,
             trControl = trainControl(method = &quot;cv&quot;, number = 10))

## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0970             nan     0.1000   -0.0003
##      2        1.0923             nan     0.1000    0.0016
##      3        1.0883             nan     0.1000   -0.0011
##      4        1.0874             nan     0.1000    0.0004
##      5        1.0847             nan     0.1000    0.0003
##      6        1.0844             nan     0.1000   -0.0002
##      7        1.0816             nan     0.1000   -0.0001
##      8        1.0795             nan     0.1000   -0.0021
##      9        1.0789             nan     0.1000   -0.0001
##     10        1.0798             nan     0.1000   -0.0031
##     20        1.0722             nan     0.1000    0.0009
##     40        1.0567             nan     0.1000   -0.0025
##     60        1.0439             nan     0.1000   -0.0003
##     80        1.0309             nan     0.1000   -0.0031
##    100        1.0192             nan     0.1000    0.0012
##    120        1.0161             nan     0.1000   -0.0014
##    140        1.0076             nan     0.1000   -0.0016
##    150        1.0029             nan     0.1000   -0.0038
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0745             nan     0.1000   -0.0001
##      2        1.0576             nan     0.1000   -0.0018
##      3        1.0558             nan     0.1000   -0.0001
##      4        1.0337             nan     0.1000   -0.0042
##      5        1.0326             nan     0.1000    0.0003
##      6        1.0147             nan     0.1000   -0.0007
##      7        1.0002             nan     0.1000   -0.0049
##      8        0.9873             nan     0.1000   -0.0029
##      9        0.9861             nan     0.1000   -0.0005
##     10        0.9742             nan     0.1000   -0.0032
##     20        0.8930             nan     0.1000   -0.0049
##     40        0.8038             nan     0.1000   -0.0066
##     60        0.7420             nan     0.1000   -0.0019
##     80        0.7014             nan     0.1000   -0.0099
##    100        0.6577             nan     0.1000   -0.0041
##    120        0.6138             nan     0.1000   -0.0063
##    140        0.5865             nan     0.1000   -0.0008
##    150        0.5672             nan     0.1000   -0.0080
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0978             nan     0.1000   -0.0003
##      2        1.0960             nan     0.1000   -0.0010
##      3        1.0793             nan     0.1000   -0.0014
##      4        1.0599             nan     0.1000   -0.0002
##      5        1.0454             nan     0.1000   -0.0045
##      6        1.0285             nan     0.1000   -0.0018
##      7        1.0298             nan     0.1000   -0.0042
##      8        1.0308             nan     0.1000   -0.0047
##      9        1.0134             nan     0.1000   -0.0036
##     10        1.0150             nan     0.1000   -0.0054
##     20        0.9834             nan     0.1000   -0.0007
##     40        0.8851             nan     0.1000   -0.0055
##     60        0.8067             nan     0.1000   -0.0071
##     80        0.7350             nan     0.1000   -0.0039
##    100        0.6641             nan     0.1000   -0.0013
##    120        0.6242             nan     0.1000   -0.0058
##    140        0.5594             nan     0.1000   -0.0013
##    150        0.5324             nan     0.1000   -0.0019
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0894             nan     0.1000    0.0007
##      2        1.0847             nan     0.1000   -0.0010
##      3        1.0817             nan     0.1000    0.0006
##      4        1.0787             nan     0.1000   -0.0013
##      5        1.0766             nan     0.1000   -0.0016
##      6        1.0749             nan     0.1000   -0.0036
##      7        1.0740             nan     0.1000   -0.0004
##      8        1.0722             nan     0.1000   -0.0005
##      9        1.0710             nan     0.1000    0.0009
##     10        1.0697             nan     0.1000    0.0010
##     20        1.0590             nan     0.1000   -0.0008
##     40        1.0457             nan     0.1000    0.0006
##     60        1.0333             nan     0.1000   -0.0031
##     80        1.0259             nan     0.1000   -0.0025
##    100        1.0185             nan     0.1000   -0.0020
##    120        1.0123             nan     0.1000   -0.0029
##    140        1.0029             nan     0.1000   -0.0031
##    150        0.9969             nan     0.1000   -0.0014
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0926             nan     0.1000    0.0001
##      2        1.0754             nan     0.1000   -0.0002
##      3        1.0740             nan     0.1000   -0.0004
##      4        1.0728             nan     0.1000    0.0000
##      5        1.0514             nan     0.1000   -0.0003
##      6        1.0493             nan     0.1000   -0.0008
##      7        1.0323             nan     0.1000   -0.0018
##      8        1.0316             nan     0.1000   -0.0002
##      9        1.0172             nan     0.1000   -0.0049
##     10        1.0174             nan     0.1000   -0.0020
##     20        0.9438             nan     0.1000   -0.0022
##     40        0.8686             nan     0.1000   -0.0000
##     60        0.7979             nan     0.1000   -0.0097
##     80        0.7252             nan     0.1000   -0.0020
##    100        0.6826             nan     0.1000   -0.0007
##    120        0.6328             nan     0.1000   -0.0029
##    140        0.5955             nan     0.1000   -0.0054
##    150        0.5770             nan     0.1000   -0.0027
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0928             nan     0.1000   -0.0001
##      2        1.0907             nan     0.1000    0.0006
##      3        1.0636             nan     0.1000   -0.0017
##      4        1.0468             nan     0.1000   -0.0033
##      5        1.0448             nan     0.1000   -0.0004
##      6        1.0439             nan     0.1000   -0.0004
##      7        1.0431             nan     0.1000   -0.0005
##      8        1.0258             nan     0.1000   -0.0007
##      9        1.0094             nan     0.1000   -0.0033
##     10        0.9955             nan     0.1000   -0.0047
##     20        0.9150             nan     0.1000   -0.0125
##     40        0.7664             nan     0.1000   -0.0011
##     60        0.6948             nan     0.1000   -0.0045
##     80        0.5998             nan     0.1000   -0.0033
##    100        0.5468             nan     0.1000   -0.0019
##    120        0.4900             nan     0.1000   -0.0043
##    140        0.4509             nan     0.1000   -0.0057
##    150        0.4259             nan     0.1000   -0.0003
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0898             nan     0.1000    0.0018
##      2        1.0854             nan     0.1000   -0.0006
##      3        1.0821             nan     0.1000   -0.0020
##      4        1.0803             nan     0.1000   -0.0019
##      5        1.0791             nan     0.1000   -0.0020
##      6        1.0784             nan     0.1000   -0.0005
##      7        1.0789             nan     0.1000   -0.0023
##      8        1.0782             nan     0.1000   -0.0004
##      9        1.0789             nan     0.1000   -0.0028
##     10        1.0786             nan     0.1000    0.0001
##     20        1.0662             nan     0.1000    0.0005
##     40        1.0458             nan     0.1000    0.0013
##     60        1.0332             nan     0.1000    0.0012
##     80        1.0230             nan     0.1000   -0.0022
##    100        1.0148             nan     0.1000   -0.0018
##    120        1.0075             nan     0.1000   -0.0021
##    140        0.9996             nan     0.1000   -0.0023
##    150        0.9978             nan     0.1000   -0.0024
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0924             nan     0.1000   -0.0005
##      2        1.0912             nan     0.1000   -0.0000
##      3        1.0683             nan     0.1000    0.0063
##      4        1.0673             nan     0.1000   -0.0000
##      5        1.0667             nan     0.1000   -0.0002
##      6        1.0516             nan     0.1000   -0.0022
##      7        1.0351             nan     0.1000   -0.0038
##      8        1.0207             nan     0.1000   -0.0022
##      9        1.0217             nan     0.1000   -0.0035
##     10        1.0211             nan     0.1000   -0.0006
##     20        0.9860             nan     0.1000   -0.0027
##     40        0.8464             nan     0.1000    0.0021
##     60        0.7878             nan     0.1000   -0.0052
##     80        0.7323             nan     0.1000   -0.0061
##    100        0.6908             nan     0.1000   -0.0056
##    120        0.6412             nan     0.1000    0.0008
##    140        0.6064             nan     0.1000   -0.0015
##    150        0.5949             nan     0.1000   -0.0033
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0759             nan     0.1000   -0.0012
##      2        1.0526             nan     0.1000   -0.0035
##      3        1.0525             nan     0.1000   -0.0020
##      4        1.0372             nan     0.1000   -0.0062
##      5        1.0365             nan     0.1000   -0.0017
##      6        1.0341             nan     0.1000    0.0002
##      7        1.0358             nan     0.1000   -0.0051
##      8        1.0372             nan     0.1000   -0.0054
##      9        1.0365             nan     0.1000   -0.0007
##     10        1.0356             nan     0.1000   -0.0005
##     20        0.9278             nan     0.1000   -0.0033
##     40        0.8334             nan     0.1000   -0.0003
##     60        0.7437             nan     0.1000   -0.0066
##     80        0.6884             nan     0.1000    0.0003
##    100        0.6198             nan     0.1000   -0.0009
##    120        0.5538             nan     0.1000   -0.0005
##    140        0.5051             nan     0.1000   -0.0036
##    150        0.4936             nan     0.1000   -0.0030
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0240             nan     0.1000   -0.0000
##      2        1.0237             nan     0.1000   -0.0002
##      3        1.0198             nan     0.1000   -0.0012
##      4        1.0197             nan     0.1000   -0.0002
##      5        1.0187             nan     0.1000    0.0013
##      6        1.0166             nan     0.1000   -0.0010
##      7        1.0164             nan     0.1000   -0.0002
##      8        1.0163             nan     0.1000   -0.0004
##      9        1.0161             nan     0.1000   -0.0002
##     10        1.0145             nan     0.1000   -0.0014
##     20        1.0049             nan     0.1000   -0.0015
##     40        0.9913             nan     0.1000   -0.0019
##     60        0.9862             nan     0.1000   -0.0020
##     80        0.9757             nan     0.1000   -0.0020
##    100        0.9700             nan     0.1000    0.0016
##    120        0.9666             nan     0.1000   -0.0021
##    140        0.9630             nan     0.1000   -0.0024
##    150        0.9607             nan     0.1000    0.0010
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0272             nan     0.1000    0.0003
##      2        1.0096             nan     0.1000   -0.0022
##      3        1.0091             nan     0.1000   -0.0003
##      4        1.0090             nan     0.1000   -0.0007
##      5        0.9926             nan     0.1000   -0.0020
##      6        0.9921             nan     0.1000   -0.0005
##      7        0.9917             nan     0.1000   -0.0002
##      8        0.9796             nan     0.1000   -0.0085
##      9        0.9785             nan     0.1000    0.0009
##     10        0.9799             nan     0.1000   -0.0041
##     20        0.8697             nan     0.1000   -0.0038
##     40        0.8065             nan     0.1000   -0.0009
##     60        0.7411             nan     0.1000   -0.0048
##     80        0.6983             nan     0.1000   -0.0037
##    100        0.6457             nan     0.1000   -0.0077
##    120        0.6236             nan     0.1000   -0.0042
##    140        0.6030             nan     0.1000   -0.0043
##    150        0.5857             nan     0.1000   -0.0041
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0264             nan     0.1000   -0.0001
##      2        1.0256             nan     0.1000   -0.0001
##      3        1.0088             nan     0.1000   -0.0037
##      4        0.9920             nan     0.1000   -0.0017
##      5        0.9783             nan     0.1000   -0.0027
##      6        0.9776             nan     0.1000   -0.0005
##      7        0.9766             nan     0.1000    0.0000
##      8        0.9603             nan     0.1000   -0.0020
##      9        0.9480             nan     0.1000   -0.0061
##     10        0.9333             nan     0.1000   -0.0009
##     20        0.8934             nan     0.1000   -0.0045
##     40        0.8020             nan     0.1000   -0.0093
##     60        0.7294             nan     0.1000   -0.0058
##     80        0.6490             nan     0.1000   -0.0013
##    100        0.6176             nan     0.1000   -0.0058
##    120        0.5502             nan     0.1000   -0.0016
##    140        0.5201             nan     0.1000   -0.0024
##    150        0.5037             nan     0.1000   -0.0058
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0976             nan     0.1000    0.0012
##      2        1.0968             nan     0.1000    0.0002
##      3        1.0957             nan     0.1000   -0.0003
##      4        1.0956             nan     0.1000   -0.0002
##      5        1.0954             nan     0.1000   -0.0002
##      6        1.0907             nan     0.1000   -0.0019
##      7        1.0875             nan     0.1000   -0.0020
##      8        1.0858             nan     0.1000   -0.0021
##      9        1.0847             nan     0.1000    0.0009
##     10        1.0829             nan     0.1000   -0.0043
##     20        1.0688             nan     0.1000   -0.0031
##     40        1.0528             nan     0.1000   -0.0029
##     60        1.0425             nan     0.1000   -0.0032
##     80        1.0309             nan     0.1000   -0.0016
##    100        1.0250             nan     0.1000   -0.0022
##    120        1.0148             nan     0.1000    0.0011
##    140        1.0012             nan     0.1000   -0.0012
##    150        0.9958             nan     0.1000   -0.0019
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.1012             nan     0.1000    0.0009
##      2        1.1003             nan     0.1000   -0.0007
##      3        1.0821             nan     0.1000   -0.0010
##      4        1.0804             nan     0.1000   -0.0009
##      5        1.0799             nan     0.1000   -0.0013
##      6        1.0791             nan     0.1000   -0.0007
##      7        1.0784             nan     0.1000   -0.0006
##      8        1.0618             nan     0.1000   -0.0053
##      9        1.0435             nan     0.1000   -0.0024
##     10        1.0187             nan     0.1000    0.0002
##     20        0.9167             nan     0.1000   -0.0020
##     40        0.7919             nan     0.1000   -0.0040
##     60        0.7310             nan     0.1000   -0.0033
##     80        0.6651             nan     0.1000   -0.0029
##    100        0.6245             nan     0.1000   -0.0021
##    120        0.5941             nan     0.1000   -0.0044
##    140        0.5723             nan     0.1000   -0.0066
##    150        0.5550             nan     0.1000   -0.0025
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.1004             nan     0.1000    0.0000
##      2        1.0716             nan     0.1000    0.0002
##      3        1.0698             nan     0.1000    0.0001
##      4        1.0687             nan     0.1000   -0.0007
##      5        1.0676             nan     0.1000   -0.0007
##      6        1.0668             nan     0.1000   -0.0005
##      7        1.0658             nan     0.1000    0.0001
##      8        1.0459             nan     0.1000   -0.0057
##      9        1.0294             nan     0.1000   -0.0031
##     10        1.0289             nan     0.1000   -0.0005
##     20        0.9656             nan     0.1000   -0.0041
##     40        0.8666             nan     0.1000   -0.0015
##     60        0.7460             nan     0.1000   -0.0014
##     80        0.6763             nan     0.1000    0.0000
##    100        0.5980             nan     0.1000   -0.0006
##    120        0.5360             nan     0.1000   -0.0008
##    140        0.4998             nan     0.1000   -0.0017
##    150        0.4864             nan     0.1000   -0.0026
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0960             nan     0.1000    0.0001
##      2        1.0920             nan     0.1000   -0.0006
##      3        1.0910             nan     0.1000   -0.0004
##      4        1.0873             nan     0.1000   -0.0022
##      5        1.0839             nan     0.1000    0.0006
##      6        1.0825             nan     0.1000   -0.0004
##      7        1.0798             nan     0.1000   -0.0008
##      8        1.0773             nan     0.1000   -0.0002
##      9        1.0757             nan     0.1000   -0.0007
##     10        1.0743             nan     0.1000   -0.0025
##     20        1.0646             nan     0.1000   -0.0015
##     40        1.0528             nan     0.1000   -0.0021
##     60        1.0373             nan     0.1000   -0.0018
##     80        1.0273             nan     0.1000   -0.0036
##    100        1.0177             nan     0.1000   -0.0018
##    120        1.0104             nan     0.1000   -0.0018
##    140        1.0015             nan     0.1000    0.0013
##    150        0.9980             nan     0.1000    0.0009
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0993             nan     0.1000    0.0006
##      2        1.0761             nan     0.1000   -0.0008
##      3        1.0750             nan     0.1000   -0.0004
##      4        1.0549             nan     0.1000    0.0042
##      5        1.0410             nan     0.1000   -0.0067
##      6        1.0278             nan     0.1000   -0.0038
##      7        1.0263             nan     0.1000   -0.0006
##      8        1.0088             nan     0.1000   -0.0016
##      9        1.0075             nan     0.1000   -0.0010
##     10        0.9920             nan     0.1000   -0.0080
##     20        0.9303             nan     0.1000   -0.0006
##     40        0.8551             nan     0.1000   -0.0044
##     60        0.7509             nan     0.1000   -0.0070
##     80        0.6803             nan     0.1000   -0.0025
##    100        0.6407             nan     0.1000   -0.0057
##    120        0.6161             nan     0.1000   -0.0096
##    140        0.5791             nan     0.1000   -0.0064
##    150        0.5663             nan     0.1000   -0.0089
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0987             nan     0.1000    0.0003
##      2        1.0813             nan     0.1000   -0.0013
##      3        1.0800             nan     0.1000   -0.0003
##      4        1.0596             nan     0.1000   -0.0017
##      5        1.0443             nan     0.1000   -0.0027
##      6        1.0438             nan     0.1000   -0.0026
##      7        1.0276             nan     0.1000   -0.0104
##      8        1.0283             nan     0.1000   -0.0033
##      9        1.0110             nan     0.1000   -0.0017
##     10        0.9969             nan     0.1000   -0.0045
##     20        0.9394             nan     0.1000   -0.0095
##     40        0.8494             nan     0.1000   -0.0073
##     60        0.7684             nan     0.1000   -0.0005
##     80        0.7097             nan     0.1000   -0.0052
##    100        0.6346             nan     0.1000   -0.0013
##    120        0.5900             nan     0.1000   -0.0056
##    140        0.5521             nan     0.1000   -0.0031
##    150        0.5243             nan     0.1000   -0.0053
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        0.1794             nan     0.1000    0.0002
##      2        0.1787             nan     0.1000    0.0002
##      3        0.1782             nan     0.1000   -0.0000
##      4        0.1775             nan     0.1000   -0.0000
##      5        0.1769             nan     0.1000   -0.0002
##      6        0.1764             nan     0.1000   -0.0002
##      7        0.1758             nan     0.1000   -0.0002
##      8        0.1754             nan     0.1000    0.0000
##      9        0.1749             nan     0.1000   -0.0004
##     10        0.1748             nan     0.1000   -0.0001
##     20        0.1712             nan     0.1000   -0.0003
##     40        0.1654             nan     0.1000   -0.0001
##     60        0.1620             nan     0.1000   -0.0003
##     80        0.1585             nan     0.1000   -0.0000
##    100        0.1559             nan     0.1000   -0.0003
##    120        0.1538             nan     0.1000   -0.0006
##    140        0.1523             nan     0.1000    0.0001
##    150        0.1516             nan     0.1000   -0.0001
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        0.1796             nan     0.1000   -0.0002
##      2        0.1779             nan     0.1000    0.0000
##      3        0.1770             nan     0.1000   -0.0001
##      4        0.1753             nan     0.1000    0.0001
##      5        0.1745             nan     0.1000   -0.0008
##      6        0.1738             nan     0.1000    0.0006
##      7        0.1735             nan     0.1000   -0.0004
##      8        0.1720             nan     0.1000    0.0001
##      9        0.1713             nan     0.1000   -0.0003
##     10        0.1707             nan     0.1000    0.0002
##     20        0.1642             nan     0.1000    0.0000
##     40        0.1560             nan     0.1000   -0.0001
##     60        0.1504             nan     0.1000   -0.0003
##     80        0.1434             nan     0.1000   -0.0000
##    100        0.1380             nan     0.1000   -0.0001
##    120        0.1328             nan     0.1000   -0.0007
##    140        0.1298             nan     0.1000   -0.0002
##    150        0.1277             nan     0.1000   -0.0006
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        0.1778             nan     0.1000   -0.0001
##      2        0.1762             nan     0.1000    0.0000
##      3        0.1750             nan     0.1000   -0.0000
##      4        0.1742             nan     0.1000   -0.0006
##      5        0.1723             nan     0.1000   -0.0001
##      6        0.1713             nan     0.1000    0.0006
##      7        0.1705             nan     0.1000   -0.0000
##      8        0.1698             nan     0.1000   -0.0003
##      9        0.1686             nan     0.1000    0.0008
##     10        0.1676             nan     0.1000   -0.0002
##     20        0.1590             nan     0.1000   -0.0000
##     40        0.1484             nan     0.1000   -0.0010
##     60        0.1380             nan     0.1000    0.0001
##     80        0.1294             nan     0.1000   -0.0004
##    100        0.1231             nan     0.1000    0.0001
##    120        0.1161             nan     0.1000   -0.0005
##    140        0.1102             nan     0.1000   -0.0003
##    150        0.1082             nan     0.1000   -0.0002
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0869             nan     0.1000   -0.0006
##      2        1.0827             nan     0.1000    0.0019
##      3        1.0791             nan     0.1000   -0.0006
##      4        1.0788             nan     0.1000   -0.0001
##      5        1.0780             nan     0.1000    0.0002
##      6        1.0781             nan     0.1000   -0.0006
##      7        1.0756             nan     0.1000   -0.0010
##      8        1.0736             nan     0.1000   -0.0018
##      9        1.0728             nan     0.1000   -0.0006
##     10        1.0707             nan     0.1000   -0.0003
##     20        1.0558             nan     0.1000   -0.0002
##     40        1.0436             nan     0.1000   -0.0015
##     60        1.0321             nan     0.1000   -0.0015
##     80        1.0169             nan     0.1000   -0.0017
##    100        1.0037             nan     0.1000    0.0010
##    120        0.9982             nan     0.1000   -0.0010
##    140        0.9920             nan     0.1000   -0.0024
##    150        0.9874             nan     0.1000   -0.0031
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0861             nan     0.1000    0.0002
##      2        1.0851             nan     0.1000   -0.0005
##      3        1.0845             nan     0.1000   -0.0005
##      4        1.0656             nan     0.1000   -0.0023
##      5        1.0653             nan     0.1000   -0.0006
##      6        1.0488             nan     0.1000   -0.0016
##      7        1.0478             nan     0.1000    0.0001
##      8        1.0475             nan     0.1000   -0.0002
##      9        1.0463             nan     0.1000   -0.0008
##     10        1.0320             nan     0.1000   -0.0036
##     20        0.9651             nan     0.1000   -0.0072
##     40        0.8271             nan     0.1000   -0.0040
##     60        0.7422             nan     0.1000   -0.0005
##     80        0.6864             nan     0.1000   -0.0061
##    100        0.6337             nan     0.1000   -0.0003
##    120        0.5918             nan     0.1000    0.0001
##    140        0.5640             nan     0.1000   -0.0108
##    150        0.5439             nan     0.1000   -0.0007
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0705             nan     0.1000   -0.0012
##      2        1.0528             nan     0.1000   -0.0021
##      3        1.0309             nan     0.1000   -0.0019
##      4        1.0151             nan     0.1000   -0.0028
##      5        0.9992             nan     0.1000   -0.0087
##      6        0.9790             nan     0.1000    0.0004
##      7        0.9786             nan     0.1000   -0.0021
##      8        0.9649             nan     0.1000   -0.0010
##      9        0.9499             nan     0.1000   -0.0011
##     10        0.9481             nan     0.1000    0.0002
##     20        0.8711             nan     0.1000   -0.0013
##     40        0.7527             nan     0.1000   -0.0022
##     60        0.6817             nan     0.1000   -0.0078
##     80        0.6417             nan     0.1000   -0.0049
##    100        0.6122             nan     0.1000   -0.0039
##    120        0.5406             nan     0.1000   -0.0032
##    140        0.4780             nan     0.1000    0.0003
##    150        0.4638             nan     0.1000   -0.0010
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.1008             nan     0.1000   -0.0003
##      2        1.1001             nan     0.1000   -0.0002
##      3        1.0946             nan     0.1000   -0.0005
##      4        1.0906             nan     0.1000   -0.0008
##      5        1.0883             nan     0.1000    0.0004
##      6        1.0877             nan     0.1000    0.0002
##      7        1.0869             nan     0.1000   -0.0007
##      8        1.0869             nan     0.1000   -0.0004
##      9        1.0845             nan     0.1000   -0.0023
##     10        1.0837             nan     0.1000   -0.0001
##     20        1.0726             nan     0.1000   -0.0007
##     40        1.0567             nan     0.1000   -0.0025
##     60        1.0457             nan     0.1000    0.0005
##     80        1.0371             nan     0.1000   -0.0014
##    100        1.0276             nan     0.1000   -0.0022
##    120        1.0268             nan     0.1000   -0.0017
##    140        1.0186             nan     0.1000   -0.0025
##    150        1.0146             nan     0.1000   -0.0004
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0999             nan     0.1000    0.0004
##      2        1.0792             nan     0.1000    0.0050
##      3        1.0638             nan     0.1000   -0.0026
##      4        1.0488             nan     0.1000   -0.0044
##      5        1.0356             nan     0.1000   -0.0041
##      6        1.0204             nan     0.1000   -0.0020
##      7        1.0187             nan     0.1000   -0.0002
##      8        1.0174             nan     0.1000    0.0007
##      9        1.0033             nan     0.1000   -0.0017
##     10        0.9874             nan     0.1000   -0.0018
##     20        0.9271             nan     0.1000   -0.0023
##     40        0.7835             nan     0.1000   -0.0049
##     60        0.6953             nan     0.1000   -0.0000
##     80        0.6520             nan     0.1000   -0.0063
##    100        0.6066             nan     0.1000    0.0006
##    120        0.5626             nan     0.1000    0.0008
##    140        0.5343             nan     0.1000   -0.0003
##    150        0.5234             nan     0.1000   -0.0014
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0999             nan     0.1000   -0.0001
##      2        1.0978             nan     0.1000    0.0012
##      3        1.0733             nan     0.1000   -0.0037
##      4        1.0504             nan     0.1000   -0.0005
##      5        1.0318             nan     0.1000   -0.0012
##      6        1.0177             nan     0.1000   -0.0049
##      7        1.0171             nan     0.1000   -0.0027
##      8        1.0164             nan     0.1000   -0.0004
##      9        1.0165             nan     0.1000   -0.0028
##     10        1.0187             nan     0.1000   -0.0062
##     20        0.9552             nan     0.1000   -0.0021
##     40        0.8219             nan     0.1000   -0.0069
##     60        0.7237             nan     0.1000   -0.0064
##     80        0.6425             nan     0.1000   -0.0023
##    100        0.5967             nan     0.1000   -0.0056
##    120        0.5618             nan     0.1000   -0.0037
##    140        0.5129             nan     0.1000   -0.0037
##    150        0.4983             nan     0.1000   -0.0038
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0984             nan     0.1000    0.0005
##      2        1.0944             nan     0.1000    0.0007
##      3        1.0912             nan     0.1000    0.0001
##      4        1.0906             nan     0.1000   -0.0005
##      5        1.0897             nan     0.1000   -0.0001
##      6        1.0897             nan     0.1000   -0.0005
##      7        1.0890             nan     0.1000   -0.0001
##      8        1.0886             nan     0.1000   -0.0005
##      9        1.0882             nan     0.1000   -0.0007
##     10        1.0875             nan     0.1000   -0.0005
##     20        1.0759             nan     0.1000   -0.0030
##     40        1.0602             nan     0.1000   -0.0010
##     60        1.0454             nan     0.1000   -0.0023
##     80        1.0395             nan     0.1000   -0.0027
##    100        1.0271             nan     0.1000   -0.0030
##    120        1.0211             nan     0.1000   -0.0023
##    140        1.0189             nan     0.1000   -0.0013
##    150        1.0155             nan     0.1000   -0.0024
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.1029             nan     0.1000   -0.0006
##      2        1.0766             nan     0.1000   -0.0023
##      3        1.0598             nan     0.1000   -0.0018
##      4        1.0584             nan     0.1000   -0.0009
##      5        1.0576             nan     0.1000   -0.0001
##      6        1.0401             nan     0.1000   -0.0036
##      7        1.0250             nan     0.1000   -0.0031
##      8        1.0250             nan     0.1000   -0.0021
##      9        1.0112             nan     0.1000   -0.0098
##     10        0.9962             nan     0.1000   -0.0106
##     20        0.9457             nan     0.1000   -0.0052
##     40        0.8423             nan     0.1000   -0.0040
##     60        0.7463             nan     0.1000   -0.0079
##     80        0.7061             nan     0.1000   -0.0071
##    100        0.6461             nan     0.1000   -0.0038
##    120        0.6087             nan     0.1000   -0.0069
##    140        0.5721             nan     0.1000   -0.0122
##    150        0.5626             nan     0.1000   -0.0027
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.1016             nan     0.1000    0.0004
##      2        1.1004             nan     0.1000    0.0001
##      3        1.0995             nan     0.1000   -0.0006
##      4        1.0988             nan     0.1000   -0.0004
##      5        1.0980             nan     0.1000   -0.0006
##      6        1.0963             nan     0.1000    0.0001
##      7        1.0778             nan     0.1000   -0.0022
##      8        1.0768             nan     0.1000   -0.0005
##      9        1.0760             nan     0.1000   -0.0014
##     10        1.0590             nan     0.1000   -0.0017
##     20        1.0211             nan     0.1000   -0.0005
##     40        0.8763             nan     0.1000    0.0045
##     60        0.8176             nan     0.1000   -0.0012
##     80        0.7602             nan     0.1000   -0.0032
##    100        0.7087             nan     0.1000   -0.0087
##    120        0.6575             nan     0.1000   -0.0050
##    140        0.6005             nan     0.1000   -0.0075
##    150        0.5615             nan     0.1000   -0.0020
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        0.9988             nan     0.1000    0.0001
##      2        0.9952             nan     0.1000    0.0014
##      3        0.9948             nan     0.1000   -0.0001
##      4        0.9941             nan     0.1000   -0.0002
##      5        0.9936             nan     0.1000   -0.0007
##      6        0.9932             nan     0.1000   -0.0002
##      7        0.9902             nan     0.1000    0.0007
##      8        0.9899             nan     0.1000   -0.0000
##      9        0.9873             nan     0.1000   -0.0000
##     10        0.9872             nan     0.1000   -0.0005
##     20        0.9754             nan     0.1000   -0.0021
##     40        0.9586             nan     0.1000   -0.0003
##     50        0.9553             nan     0.1000   -0.0020

gbmFit

## Stochastic Gradient Boosting 
## 
## 1719 samples
##   37 predictor
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 1546, 1546, 1548, 1547, 1548, 1547, ... 
## Resampling results across tuning parameters:
## 
##   interaction.depth  n.trees  RMSE       Rsquared     MAE      
##   1                   50      0.6493460  0.016736436  0.2271626
##   1                  100      0.6606866  0.020616440  0.2382202
##   1                  150      0.6692479  0.024297807  0.2421840
##   2                   50      0.7230450  0.010658377  0.2513860
##   2                  100      0.7650257  0.013312855  0.2753723
##   2                  150      0.7969166  0.013017631  0.2907066
##   3                   50      0.7128736  0.009601075  0.2485394
##   3                  100      0.7476245  0.007816833  0.2688073
##   3                  150      0.7738168  0.011321534  0.2830293
## 
## Tuning parameter &#39;shrinkage&#39; was held constant at a value of 0.1
## Tuning parameter &#39;n.minobsinnode&#39; was held constant at a value
##  of 10
## RMSE was used to select the optimal model using the smallest value.
## The final values used for the model were n.trees = 50, interaction.depth = 1, shrinkage = 0.1 and n.minobsinnode = 10.

# create the prediction
pred2 &lt;- predict(gbmFit, newdata = newsPopTest)

# compare the prediction vs the actual
resample2 &lt;- postResample(pred2, obs = newsPopTest$shares)
resample2

##       RMSE   Rsquared        MAE 
## 0.42052722 0.01055786 0.20971264</code></pre>
<h3 id="linear-regression-model">Linear Regression Model</h3>
<p>Linear regression is used to predict the outcome of a response variable for 1 to n predictors. The aim is to establish a linear relationship between the predictor variable(s) and response variable so we can predict the value of the response when only the predictor variable(s) is(are) known.</p>
<pre><code># train the linear model for main effects + interactions on first 3 preds
lmFit &lt;- train(shares ~ timedelta*n_tokens_title*n_tokens_content, data = newsPopTrain,
                                                                   method = &quot;lm&quot;, preProces = c(&quot;center&quot;, &quot;scale&quot;),
                                                                   trControl = trainControl(method = &quot;cv&quot;, number = 10))
lmFit

## Linear Regression 
## 
## 1719 samples
##    3 predictor
## 
## Pre-processing: centered (7), scaled (7) 
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 1546, 1549, 1548, 1547, 1548, 1546, ... 
## Resampling results:
## 
##   RMSE       Rsquared     MAE      
##   0.6640295  0.008738918  0.2220189
## 
## Tuning parameter &#39;intercept&#39; was held constant at a value of TRUE

# create the prediction
pred3 &lt;- predict(lmFit, newdata = newsPopTest)

# compare the prediction vs the actual
resample3 &lt;- postResample(pred3, obs = newsPopTest$shares)
resample3

##        RMSE    Rsquared         MAE 
## 0.413042854 0.002514807 0.202086754</code></pre>
<h3 id="comparison">Comparison</h3>
<p>Below is a comparison of the 3 methods. All have relatively high root mean square errors.</p>
<pre><code>comparison &lt;- data.frame(&quot;RSME&quot; = c(resample1[[1]], resample2[[1]], resample3[1]), &quot;MAE&quot; = c(resample1[[3]], resample2[[3]], resample3[[3]]))
rownames(comparison) &lt;- c(&quot;RPART&quot;,&quot;GBM&quot;, &quot;LM&quot;)
kable(comparison)</code></pre>
<table>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
RSME
</th>
<th style="text-align:right;">
MAE
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
RPART
</td>
<td style="text-align:right;">
0.4499436
</td>
<td style="text-align:right;">
0.1967980
</td>
</tr>
<tr>
<td style="text-align:left;">
GBM
</td>
<td style="text-align:right;">
0.4205272
</td>
<td style="text-align:right;">
0.2097126
</td>
</tr>
<tr>
<td style="text-align:left;">
LM
</td>
<td style="text-align:right;">
0.4130429
</td>
<td style="text-align:right;">
0.2020868
</td>
</tr>
</tbody>
</table>

</body>
</html>
