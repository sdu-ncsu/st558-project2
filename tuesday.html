<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1">

<style type="text/css">
@font-face {
font-family: octicons-link;
src: url(data:font/woff;charset=utf-8;base64,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) format('woff');
}
body {
-webkit-text-size-adjust: 100%;
text-size-adjust: 100%;
color: #333;
font-family: "Helvetica Neue", Helvetica, "Segoe UI", Arial, freesans, sans-serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol";
font-size: 16px;
line-height: 1.6;
word-wrap: break-word;
}
a {
background-color: transparent;
}
a:active,
a:hover {
outline: 0;
}
strong {
font-weight: bold;
}
h1 {
font-size: 2em;
margin: 0.67em 0;
}
img {
border: 0;
}
hr {
box-sizing: content-box;
height: 0;
}
pre {
overflow: auto;
}
code,
kbd,
pre {
font-family: monospace, monospace;
font-size: 1em;
}
input {
color: inherit;
font: inherit;
margin: 0;
}
html input[disabled] {
cursor: default;
}
input {
line-height: normal;
}
input[type="checkbox"] {
box-sizing: border-box;
padding: 0;
}
table {
border-collapse: collapse;
border-spacing: 0;
}
td,
th {
padding: 0;
}
* {
box-sizing: border-box;
}
input {
font: 13px / 1.4 Helvetica, arial, nimbussansl, liberationsans, freesans, clean, sans-serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol";
}
a {
color: #4078c0;
text-decoration: none;
}
a:hover,
a:active {
text-decoration: underline;
}
hr {
height: 0;
margin: 15px 0;
overflow: hidden;
background: transparent;
border: 0;
border-bottom: 1px solid #ddd;
}
hr:before {
display: table;
content: "";
}
hr:after {
display: table;
clear: both;
content: "";
}
h1,
h2,
h3,
h4,
h5,
h6 {
margin-top: 15px;
margin-bottom: 15px;
line-height: 1.1;
}
h1 {
font-size: 30px;
}
h2 {
font-size: 21px;
}
h3 {
font-size: 16px;
}
h4 {
font-size: 14px;
}
h5 {
font-size: 12px;
}
h6 {
font-size: 11px;
}
blockquote {
margin: 0;
}
ul,
ol {
padding: 0;
margin-top: 0;
margin-bottom: 0;
}
ol ol,
ul ol {
list-style-type: lower-roman;
}
ul ul ol,
ul ol ol,
ol ul ol,
ol ol ol {
list-style-type: lower-alpha;
}
dd {
margin-left: 0;
}
code {
font-family: Consolas, "Liberation Mono", Menlo, Courier, monospace;
font-size: 12px;
}
pre {
margin-top: 0;
margin-bottom: 0;
font: 12px Consolas, "Liberation Mono", Menlo, Courier, monospace;
}
.select::-ms-expand {
opacity: 0;
}
.octicon {
font: normal normal normal 16px/1 octicons-link;
display: inline-block;
text-decoration: none;
text-rendering: auto;
-webkit-font-smoothing: antialiased;
-moz-osx-font-smoothing: grayscale;
-webkit-user-select: none;
-moz-user-select: none;
-ms-user-select: none;
user-select: none;
}
.octicon-link:before {
content: '\f05c';
}
.markdown-body:before {
display: table;
content: "";
}
.markdown-body:after {
display: table;
clear: both;
content: "";
}
.markdown-body>*:first-child {
margin-top: 0 !important;
}
.markdown-body>*:last-child {
margin-bottom: 0 !important;
}
a:not([href]) {
color: inherit;
text-decoration: none;
}
.anchor {
display: inline-block;
padding-right: 2px;
margin-left: -18px;
}
.anchor:focus {
outline: none;
}
h1,
h2,
h3,
h4,
h5,
h6 {
margin-top: 1em;
margin-bottom: 16px;
font-weight: bold;
line-height: 1.4;
}
h1 .octicon-link,
h2 .octicon-link,
h3 .octicon-link,
h4 .octicon-link,
h5 .octicon-link,
h6 .octicon-link {
color: #000;
vertical-align: middle;
visibility: hidden;
}
h1:hover .anchor,
h2:hover .anchor,
h3:hover .anchor,
h4:hover .anchor,
h5:hover .anchor,
h6:hover .anchor {
text-decoration: none;
}
h1:hover .anchor .octicon-link,
h2:hover .anchor .octicon-link,
h3:hover .anchor .octicon-link,
h4:hover .anchor .octicon-link,
h5:hover .anchor .octicon-link,
h6:hover .anchor .octicon-link {
visibility: visible;
}
h1 {
padding-bottom: 0.3em;
font-size: 2.25em;
line-height: 1.2;
border-bottom: 1px solid #eee;
}
h1 .anchor {
line-height: 1;
}
h2 {
padding-bottom: 0.3em;
font-size: 1.75em;
line-height: 1.225;
border-bottom: 1px solid #eee;
}
h2 .anchor {
line-height: 1;
}
h3 {
font-size: 1.5em;
line-height: 1.43;
}
h3 .anchor {
line-height: 1.2;
}
h4 {
font-size: 1.25em;
}
h4 .anchor {
line-height: 1.2;
}
h5 {
font-size: 1em;
}
h5 .anchor {
line-height: 1.1;
}
h6 {
font-size: 1em;
color: #777;
}
h6 .anchor {
line-height: 1.1;
}
p,
blockquote,
ul,
ol,
dl,
table,
pre {
margin-top: 0;
margin-bottom: 16px;
}
hr {
height: 4px;
padding: 0;
margin: 16px 0;
background-color: #e7e7e7;
border: 0 none;
}
ul,
ol {
padding-left: 2em;
}
ul ul,
ul ol,
ol ol,
ol ul {
margin-top: 0;
margin-bottom: 0;
}
li>p {
margin-top: 16px;
}
dl {
padding: 0;
}
dl dt {
padding: 0;
margin-top: 16px;
font-size: 1em;
font-style: italic;
font-weight: bold;
}
dl dd {
padding: 0 16px;
margin-bottom: 16px;
}
blockquote {
padding: 0 15px;
color: #777;
border-left: 4px solid #ddd;
}
blockquote>:first-child {
margin-top: 0;
}
blockquote>:last-child {
margin-bottom: 0;
}
table {
display: block;
width: 100%;
overflow: auto;
word-break: normal;
word-break: keep-all;
}
table th {
font-weight: bold;
}
table th,
table td {
padding: 6px 13px;
border: 1px solid #ddd;
}
table tr {
background-color: #fff;
border-top: 1px solid #ccc;
}
table tr:nth-child(2n) {
background-color: #f8f8f8;
}
img {
max-width: 100%;
box-sizing: content-box;
background-color: #fff;
}
code {
padding: 0;
padding-top: 0.2em;
padding-bottom: 0.2em;
margin: 0;
font-size: 85%;
background-color: rgba(0,0,0,0.04);
border-radius: 3px;
}
code:before,
code:after {
letter-spacing: -0.2em;
content: "\00a0";
}
pre>code {
padding: 0;
margin: 0;
font-size: 100%;
word-break: normal;
white-space: pre;
background: transparent;
border: 0;
}
.highlight {
margin-bottom: 16px;
}
.highlight pre,
pre {
padding: 16px;
overflow: auto;
font-size: 85%;
line-height: 1.45;
background-color: #f7f7f7;
border-radius: 3px;
}
.highlight pre {
margin-bottom: 0;
word-break: normal;
}
pre {
word-wrap: normal;
}
pre code {
display: inline;
max-width: initial;
padding: 0;
margin: 0;
overflow: initial;
line-height: inherit;
word-wrap: normal;
background-color: transparent;
border: 0;
}
pre code:before,
pre code:after {
content: normal;
}
kbd {
display: inline-block;
padding: 3px 5px;
font-size: 11px;
line-height: 10px;
color: #555;
vertical-align: middle;
background-color: #fcfcfc;
border: solid 1px #ccc;
border-bottom-color: #bbb;
border-radius: 3px;
box-shadow: inset 0 -1px 0 #bbb;
}
.pl-c {
color: #969896;
}
.pl-c1,
.pl-s .pl-v {
color: #0086b3;
}
.pl-e,
.pl-en {
color: #795da3;
}
.pl-s .pl-s1,
.pl-smi {
color: #333;
}
.pl-ent {
color: #63a35c;
}
.pl-k {
color: #a71d5d;
}
.pl-pds,
.pl-s,
.pl-s .pl-pse .pl-s1,
.pl-sr,
.pl-sr .pl-cce,
.pl-sr .pl-sra,
.pl-sr .pl-sre {
color: #183691;
}
.pl-v {
color: #ed6a43;
}
.pl-id {
color: #b52a1d;
}
.pl-ii {
background-color: #b52a1d;
color: #f8f8f8;
}
.pl-sr .pl-cce {
color: #63a35c;
font-weight: bold;
}
.pl-ml {
color: #693a17;
}
.pl-mh,
.pl-mh .pl-en,
.pl-ms {
color: #1d3e81;
font-weight: bold;
}
.pl-mq {
color: #008080;
}
.pl-mi {
color: #333;
font-style: italic;
}
.pl-mb {
color: #333;
font-weight: bold;
}
.pl-md {
background-color: #ffecec;
color: #bd2c00;
}
.pl-mi1 {
background-color: #eaffea;
color: #55a532;
}
.pl-mdr {
color: #795da3;
font-weight: bold;
}
.pl-mo {
color: #1d3e81;
}
kbd {
display: inline-block;
padding: 3px 5px;
font: 11px Consolas, "Liberation Mono", Menlo, Courier, monospace;
line-height: 10px;
color: #555;
vertical-align: middle;
background-color: #fcfcfc;
border: solid 1px #ccc;
border-bottom-color: #bbb;
border-radius: 3px;
box-shadow: inset 0 -1px 0 #bbb;
}
.task-list-item {
list-style-type: none;
}
.task-list-item+.task-list-item {
margin-top: 3px;
}
.task-list-item input {
margin: 0 0.35em 0.25em -1.6em;
vertical-align: middle;
}
:checked+.radio-label {
z-index: 1;
position: relative;
border-color: #4078c0;
}
.sourceLine {
display: inline-block;
}
code .kw { color: #000000; }
code .dt { color: #ed6a43; }
code .dv { color: #009999; }
code .bn { color: #009999; }
code .fl { color: #009999; }
code .ch { color: #009999; }
code .st { color: #183691; }
code .co { color: #969896; }
code .ot { color: #0086b3; }
code .al { color: #a61717; }
code .fu { color: #63a35c; }
code .er { color: #a61717; background-color: #e3d2d2; }
code .wa { color: #000000; }
code .cn { color: #008080; }
code .sc { color: #008080; }
code .vs { color: #183691; }
code .ss { color: #183691; }
code .im { color: #000000; }
code .va {color: #008080; }
code .cf { color: #000000; }
code .op { color: #000000; }
code .bu { color: #000000; }
code .ex { color: #000000; }
code .pp { color: #999999; }
code .at { color: #008080; }
code .do { color: #969896; }
code .an { color: #008080; }
code .cv { color: #008080; }
code .in { color: #008080; }
</style>
<style>
body {
  box-sizing: border-box;
  min-width: 200px;
  max-width: 980px;
  margin: 0 auto;
  padding: 45px;
  padding-top: 0px;
}
</style>

</head>

<body>

<h1 id="news-popularity-tuesday-data">News Popularity Tuesday Data</h1>
<p>Shuang Du 10/16/2020</p>
<h2 id="load-libraries">Load Libraries</h2>
<pre><code>library(readxl);
library(tidyverse);
library(caret);
library(modelr);
library(rpart);
library(kableExtra);</code></pre>
<h2 id="read-in-data">Read in Data</h2>
<pre><code>getData &lt;- function(day) {

  newsPopData &lt;- read_csv(&quot;raw_data/OnlineNewsPopularity.csv&quot;)
  
  if (day == &#39;monday&#39;) {
    newsPopData &lt;- newsPopData %&gt;% filter(weekday_is_monday == 1)
  } else if(day == &#39;tuesday&#39;) {
    newsPopData &lt;- newsPopData %&gt;% filter(weekday_is_tuesday == 1)
  } else if(day == &#39;wednesday&#39;) {
    newsPopData &lt;- newsPopData %&gt;% filter(weekday_is_wednesday == 1)
  } else if(day == &#39;thursday&#39;) {
    newsPopData &lt;- newsPopData %&gt;% filter(weekday_is_thursday == 1)
  } else if(day == &#39;friday&#39;) {
    newsPopData &lt;- newsPopData %&gt;% filter(weekday_is_friday == 1)
  } else if(day == &#39;saturday&#39;) {
    newsPopData &lt;- newsPopData %&gt;% filter(weekday_is_saturday == 1)
  } else if(day == &#39;sunday&#39;) {
    newsPopData &lt;- newsPopData %&gt;% filter(weekday_is_sunday == 1)
  } else {
    stop(&quot;Invalid date&quot;)
  }
  return(newsPopData)
}

newsPopData &lt;- getData(params$day)</code></pre>
<h2 id="set-aside-training-data">Set Aside Training Data</h2>
<pre><code>set.seed(92)
trainIndex &lt;- createDataPartition(newsPopData$shares, 
                                  p = 0.7, list = FALSE)

newsPopTrain &lt;- newsPopData[as.vector(trainIndex),];
newsPopTest &lt;- newsPopData[-as.vector(trainIndex),];</code></pre>
<h2 id="center-and-scale">Center and Scale</h2>
<pre><code>preProcValues &lt;- preProcess(newsPopTrain, method = c(&quot;center&quot;, &quot;scale&quot;))
newsPopTrain &lt;- predict(preProcValues, newsPopTrain) 
newsPopTest &lt;- predict(preProcValues, newsPopTest)</code></pre>
<h2 id="summary-of-a-few-variables">Summary of a Few Variables</h2>
<p>The plots below show a histogram of the number of shares for the given day. Scatter plots on the effect of max positive polarity, article time delta and number of videos in the article are also included.</p>
<p>As expected the histogram has a strong right tail, as seem by the summary stats which show a very high maximum and a median severals orders of magnitude lower. This is expected for because of the “viral” nature of online popularity.</p>
<pre><code>summary(newsPopTrain$shares)

##     Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
## -0.31620 -0.22995 -0.18930  0.00000 -0.06826 44.16344

g0 &lt;- ggplot(newsPopTrain, aes(x=shares))
g0 + geom_histogram(binwidth = 0.5) + ggtitle(&#39;Histogram for Number of Shares&#39;) + ylab(&#39;Number of Shares&#39;) + xlab(&#39;Shares&#39;)</code></pre>
<p><img src="data:image/png;base64,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" /><!-- --></p>
<pre><code>summary(newsPopTrain$max_positive_polarity)

##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
## -3.0504 -0.6206  0.1893  0.0000  0.9992  0.9992

g1 &lt;- ggplot(newsPopTrain, aes(x = max_positive_polarity, y = shares )) 
g1 + geom_point() + ggtitle(&#39;Scatter of Max Positive Polarity Effect&#39;) + ylab(&#39;Shares&#39;) + xlab(&#39;Max Positive Polarity&#39;)</code></pre>
<p><img src="data:image/png;base64,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" /><!-- --></p>
<pre><code>summary(newsPopTrain$timedelta)

##     Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
## -1.60954 -0.89161 -0.07578  0.00000  0.87058  1.75168

g2 &lt;- ggplot(newsPopTrain, aes(x = timedelta, y = shares )) 
g2 + geom_point() + ggtitle(&#39;Scatter of Article Age Effect&#39;) + ylab(&#39;Shares&#39;) + xlab(&#39;Time Delta&#39;)</code></pre>
<p><img src="data:image/png;base64,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" /><!-- --></p>
<pre><code>summary(newsPopTrain$num_videos)

##     Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
## -0.31683 -0.31683 -0.31683  0.00000 -0.07667 17.21525

g3 &lt;- ggplot(newsPopTrain, aes(x = num_videos, y = shares )) 
g3 + geom_point() + ggtitle(&#39;Scatter of Videos Number Effect&#39;) + ylab(&#39;Shares&#39;) + xlab(&#39;Number of Videos&#39;)</code></pre>
<p><img src="data:image/png;base64,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" /><!-- --></p>
<h2 id="modeling">Modeling</h2>
<h3 id="standard-tree-based-model-no-ensemble">Standard Tree Based Model (no ensemble)</h3>
<p>The type of model being fitted here is a decision tree. The tree splits are based on minimizing the residual sum of squares for each region.</p>
<pre><code>rpartFit &lt;- train(shares ~ timedelta + n_tokens_title + n_tokens_content + n_unique_tokens + n_non_stop_words + n_non_stop_unique_tokens
                 + num_hrefs + num_self_hrefs + num_imgs + num_videos + average_token_length + num_keywords + data_channel_is_lifestyle +
                 data_channel_is_entertainment + data_channel_is_bus + data_channel_is_socmed + data_channel_is_tech + data_channel_is_world +
                 self_reference_min_shares + self_reference_max_shares + self_reference_avg_sharess + global_subjectivity + global_sentiment_polarity
                 + global_rate_positive_words + global_rate_negative_words + rate_positive_words + rate_negative_words + avg_positive_polarity +
                  min_positive_polarity + max_positive_polarity + avg_negative_polarity + min_negative_polarity + max_negative_polarity + title_subjectivity
                 + title_sentiment_polarity + abs_title_subjectivity + abs_title_sentiment_polarity, data = newsPopTrain,
             method = &quot;rpart&quot;,
             trControl = trainControl(method = &quot;cv&quot;, number = 10),
             tuneGrid = data.frame(cp = c(.001,.01,.015,.02,.03,.04,.05))
             )
rpartFit

## CART 
## 
## 5175 samples
##   37 predictor
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 4657, 4656, 4658, 4659, 4658, 4657, ... 
## Resampling results across tuning parameters:
## 
##   cp     RMSE       Rsquared     MAE      
##   0.001  0.9531612  0.017287810  0.3127114
##   0.010  0.9273818  0.014327726  0.3086837
##   0.015  0.9176725  0.010771757  0.3088906
##   0.020  0.8754890  0.008963537  0.3020529
##   0.030  0.8689058          NaN  0.3038533
##   0.040  0.8689058          NaN  0.3038533
##   0.050  0.8689058          NaN  0.3038533
## 
## RMSE was used to select the optimal model using the smallest value.
## The final value used for the model was cp = 0.05.

# create the prediction
pred1 &lt;- predict(rpartFit, newdata = newsPopTest)

# compare the prediction vs the actual
resample1 &lt;- postResample(pred1, obs = newsPopTest$shares)
resample1

##      RMSE  Rsquared       MAE 
## 0.9605903        NA 0.3123001</code></pre>
<h3 id="boosted-tree-based-model">Boosted Tree Based Model</h3>
<p>A boosted tree is an ensemble method which slowly approaches the tree prediction which would result from the original data. In general, an ensemble model model will have a lower RSME than a single tree model.</p>
<pre><code>gbmFit &lt;- train(shares ~ timedelta + n_tokens_title + n_tokens_content + n_unique_tokens + n_non_stop_words + n_non_stop_unique_tokens
                 + num_hrefs + num_self_hrefs + num_imgs + num_videos + average_token_length + num_keywords + data_channel_is_lifestyle +
                 data_channel_is_entertainment + data_channel_is_bus + data_channel_is_socmed + data_channel_is_tech + data_channel_is_world +
                 self_reference_min_shares + self_reference_max_shares + self_reference_avg_sharess + global_subjectivity + global_sentiment_polarity
                 + global_rate_positive_words + global_rate_negative_words + rate_positive_words + rate_negative_words + avg_positive_polarity +
                  min_positive_polarity + max_positive_polarity + avg_negative_polarity + min_negative_polarity + max_negative_polarity + title_subjectivity
                 + title_sentiment_polarity + abs_title_subjectivity + abs_title_sentiment_polarity, data = newsPopTrain,
             method = &quot;gbm&quot;,
             trControl = trainControl(method = &quot;cv&quot;, number = 10))

## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0463             nan     0.1000    0.0021
##      2        1.0442             nan     0.1000    0.0018
##      3        1.0426             nan     0.1000    0.0001
##      4        1.0401             nan     0.1000    0.0012
##      5        1.0394             nan     0.1000    0.0000
##      6        1.0379             nan     0.1000    0.0009
##      7        1.0365             nan     0.1000    0.0004
##      8        1.0350             nan     0.1000    0.0002
##      9        1.0345             nan     0.1000   -0.0000
##     10        1.0340             nan     0.1000   -0.0000
##     20        1.0275             nan     0.1000    0.0000
##     40        1.0194             nan     0.1000   -0.0007
##     60        1.0144             nan     0.1000   -0.0002
##     80        1.0111             nan     0.1000   -0.0006
##    100        1.0076             nan     0.1000   -0.0011
##    120        1.0055             nan     0.1000   -0.0007
##    140        1.0027             nan     0.1000   -0.0011
##    150        1.0014             nan     0.1000   -0.0007
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0440             nan     0.1000    0.0013
##      2        1.0363             nan     0.1000    0.0026
##      3        1.0324             nan     0.1000    0.0013
##      4        1.0292             nan     0.1000    0.0011
##      5        1.0270             nan     0.1000   -0.0005
##      6        1.0220             nan     0.1000   -0.0010
##      7        1.0206             nan     0.1000   -0.0001
##      8        1.0127             nan     0.1000   -0.0002
##      9        1.0046             nan     0.1000   -0.0019
##     10        1.0032             nan     0.1000    0.0005
##     20        0.9663             nan     0.1000   -0.0002
##     40        0.9350             nan     0.1000   -0.0004
##     60        0.9006             nan     0.1000    0.0003
##     80        0.8864             nan     0.1000   -0.0007
##    100        0.8681             nan     0.1000   -0.0002
##    120        0.8524             nan     0.1000   -0.0012
##    140        0.8339             nan     0.1000   -0.0015
##    150        0.8301             nan     0.1000   -0.0004
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0338             nan     0.1000    0.0015
##      2        1.0270             nan     0.1000    0.0002
##      3        1.0166             nan     0.1000    0.0017
##      4        1.0081             nan     0.1000    0.0003
##      5        0.9998             nan     0.1000   -0.0008
##      6        0.9975             nan     0.1000   -0.0001
##      7        0.9897             nan     0.1000   -0.0016
##      8        0.9885             nan     0.1000   -0.0002
##      9        0.9869             nan     0.1000   -0.0009
##     10        0.9851             nan     0.1000    0.0004
##     20        0.9382             nan     0.1000   -0.0006
##     40        0.8664             nan     0.1000   -0.0015
##     60        0.8173             nan     0.1000   -0.0010
##     80        0.7763             nan     0.1000   -0.0014
##    100        0.7622             nan     0.1000   -0.0013
##    120        0.7352             nan     0.1000   -0.0028
##    140        0.7121             nan     0.1000   -0.0002
##    150        0.7004             nan     0.1000   -0.0013
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0327             nan     0.1000    0.0024
##      2        1.0307             nan     0.1000    0.0008
##      3        1.0287             nan     0.1000    0.0018
##      4        1.0274             nan     0.1000    0.0003
##      5        1.0254             nan     0.1000    0.0013
##      6        1.0238             nan     0.1000    0.0008
##      7        1.0233             nan     0.1000   -0.0001
##      8        1.0219             nan     0.1000    0.0006
##      9        1.0207             nan     0.1000    0.0000
##     10        1.0198             nan     0.1000   -0.0001
##     20        1.0120             nan     0.1000   -0.0006
##     40        1.0035             nan     0.1000   -0.0009
##     60        0.9987             nan     0.1000   -0.0007
##     80        0.9947             nan     0.1000   -0.0004
##    100        0.9912             nan     0.1000    0.0000
##    120        0.9883             nan     0.1000    0.0000
##    140        0.9857             nan     0.1000   -0.0009
##    150        0.9834             nan     0.1000   -0.0002
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0305             nan     0.1000    0.0028
##      2        1.0273             nan     0.1000    0.0005
##      3        1.0238             nan     0.1000    0.0016
##      4        1.0201             nan     0.1000    0.0004
##      5        1.0101             nan     0.1000   -0.0021
##      6        1.0071             nan     0.1000    0.0009
##      7        1.0058             nan     0.1000    0.0005
##      8        1.0032             nan     0.1000    0.0002
##      9        1.0021             nan     0.1000   -0.0004
##     10        1.0006             nan     0.1000   -0.0001
##     20        0.9679             nan     0.1000   -0.0023
##     40        0.9182             nan     0.1000   -0.0008
##     60        0.8804             nan     0.1000   -0.0009
##     80        0.8641             nan     0.1000   -0.0024
##    100        0.8448             nan     0.1000   -0.0011
##    120        0.8297             nan     0.1000   -0.0015
##    140        0.8003             nan     0.1000    0.0003
##    150        0.7961             nan     0.1000   -0.0002
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0284             nan     0.1000    0.0021
##      2        1.0190             nan     0.1000    0.0004
##      3        1.0155             nan     0.1000   -0.0001
##      4        1.0091             nan     0.1000   -0.0010
##      5        1.0019             nan     0.1000   -0.0025
##      6        0.9996             nan     0.1000   -0.0014
##      7        0.9937             nan     0.1000   -0.0028
##      8        0.9867             nan     0.1000    0.0024
##      9        0.9792             nan     0.1000   -0.0011
##     10        0.9781             nan     0.1000   -0.0008
##     20        0.9304             nan     0.1000   -0.0030
##     40        0.8741             nan     0.1000   -0.0020
##     60        0.8242             nan     0.1000   -0.0005
##     80        0.8007             nan     0.1000   -0.0023
##    100        0.7468             nan     0.1000   -0.0015
##    120        0.7178             nan     0.1000   -0.0006
##    140        0.6841             nan     0.1000    0.0007
##    150        0.6740             nan     0.1000   -0.0006
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0622             nan     0.1000    0.0017
##      2        1.0605             nan     0.1000    0.0007
##      3        1.0586             nan     0.1000    0.0010
##      4        1.0583             nan     0.1000   -0.0003
##      5        1.0563             nan     0.1000    0.0017
##      6        1.0545             nan     0.1000   -0.0002
##      7        1.0531             nan     0.1000   -0.0002
##      8        1.0518             nan     0.1000    0.0001
##      9        1.0505             nan     0.1000    0.0007
##     10        1.0490             nan     0.1000    0.0010
##     20        1.0406             nan     0.1000    0.0003
##     40        1.0332             nan     0.1000   -0.0012
##     60        1.0267             nan     0.1000   -0.0010
##     80        1.0235             nan     0.1000   -0.0008
##    100        1.0201             nan     0.1000   -0.0003
##    120        1.0168             nan     0.1000   -0.0001
##    140        1.0139             nan     0.1000   -0.0001
##    150        1.0121             nan     0.1000   -0.0002
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0633             nan     0.1000    0.0011
##      2        1.0527             nan     0.1000   -0.0018
##      3        1.0483             nan     0.1000    0.0012
##      4        1.0470             nan     0.1000    0.0006
##      5        1.0438             nan     0.1000   -0.0006
##      6        1.0396             nan     0.1000   -0.0006
##      7        1.0309             nan     0.1000    0.0032
##      8        1.0292             nan     0.1000   -0.0001
##      9        1.0283             nan     0.1000   -0.0000
##     10        1.0268             nan     0.1000    0.0004
##     20        0.9962             nan     0.1000   -0.0004
##     40        0.9520             nan     0.1000   -0.0006
##     60        0.9221             nan     0.1000   -0.0011
##     80        0.9040             nan     0.1000   -0.0009
##    100        0.8726             nan     0.1000   -0.0010
##    120        0.8428             nan     0.1000   -0.0015
##    140        0.8206             nan     0.1000   -0.0032
##    150        0.8138             nan     0.1000    0.0000
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0586             nan     0.1000    0.0018
##      2        1.0501             nan     0.1000   -0.0007
##      3        1.0332             nan     0.1000    0.0006
##      4        1.0264             nan     0.1000    0.0004
##      5        1.0159             nan     0.1000   -0.0006
##      6        1.0069             nan     0.1000   -0.0004
##      7        1.0016             nan     0.1000   -0.0014
##      8        0.9931             nan     0.1000   -0.0002
##      9        0.9894             nan     0.1000   -0.0020
##     10        0.9872             nan     0.1000    0.0005
##     20        0.9338             nan     0.1000   -0.0010
##     40        0.8745             nan     0.1000   -0.0018
##     60        0.8317             nan     0.1000   -0.0004
##     80        0.7936             nan     0.1000   -0.0008
##    100        0.7558             nan     0.1000   -0.0006
##    120        0.7329             nan     0.1000   -0.0007
##    140        0.6992             nan     0.1000   -0.0019
##    150        0.6898             nan     0.1000   -0.0006
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0577             nan     0.1000    0.0005
##      2        1.0550             nan     0.1000    0.0023
##      3        1.0521             nan     0.1000    0.0015
##      4        1.0505             nan     0.1000    0.0001
##      5        1.0489             nan     0.1000    0.0013
##      6        1.0475             nan     0.1000    0.0006
##      7        1.0458             nan     0.1000    0.0005
##      8        1.0442             nan     0.1000    0.0006
##      9        1.0431             nan     0.1000    0.0007
##     10        1.0421             nan     0.1000    0.0003
##     20        1.0350             nan     0.1000   -0.0003
##     40        1.0274             nan     0.1000   -0.0011
##     60        1.0216             nan     0.1000   -0.0000
##     80        1.0182             nan     0.1000   -0.0003
##    100        1.0158             nan     0.1000   -0.0004
##    120        1.0128             nan     0.1000   -0.0003
##    140        1.0096             nan     0.1000   -0.0005
##    150        1.0084             nan     0.1000   -0.0002
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0556             nan     0.1000    0.0012
##      2        1.0504             nan     0.1000    0.0006
##      3        1.0440             nan     0.1000    0.0001
##      4        1.0400             nan     0.1000   -0.0006
##      5        1.0313             nan     0.1000    0.0029
##      6        1.0234             nan     0.1000   -0.0020
##      7        1.0208             nan     0.1000   -0.0001
##      8        1.0122             nan     0.1000   -0.0019
##      9        1.0103             nan     0.1000    0.0000
##     10        1.0029             nan     0.1000   -0.0011
##     20        0.9758             nan     0.1000   -0.0002
##     40        0.9279             nan     0.1000   -0.0003
##     60        0.9061             nan     0.1000   -0.0004
##     80        0.8793             nan     0.1000   -0.0007
##    100        0.8633             nan     0.1000   -0.0008
##    120        0.8490             nan     0.1000   -0.0011
##    140        0.8330             nan     0.1000   -0.0020
##    150        0.8229             nan     0.1000   -0.0010
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0567             nan     0.1000    0.0021
##      2        1.0488             nan     0.1000    0.0014
##      3        1.0454             nan     0.1000    0.0017
##      4        1.0444             nan     0.1000    0.0001
##      5        1.0413             nan     0.1000    0.0013
##      6        1.0354             nan     0.1000   -0.0016
##      7        1.0308             nan     0.1000    0.0002
##      8        1.0288             nan     0.1000   -0.0004
##      9        1.0217             nan     0.1000    0.0001
##     10        1.0140             nan     0.1000    0.0013
##     20        0.9568             nan     0.1000   -0.0017
##     40        0.8840             nan     0.1000   -0.0010
##     60        0.8163             nan     0.1000   -0.0012
##     80        0.7821             nan     0.1000   -0.0009
##    100        0.7566             nan     0.1000    0.0003
##    120        0.7307             nan     0.1000   -0.0043
##    140        0.7028             nan     0.1000   -0.0019
##    150        0.6909             nan     0.1000   -0.0004
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0621             nan     0.1000    0.0001
##      2        1.0604             nan     0.1000    0.0007
##      3        1.0583             nan     0.1000    0.0004
##      4        1.0567             nan     0.1000   -0.0001
##      5        1.0539             nan     0.1000    0.0027
##      6        1.0514             nan     0.1000    0.0019
##      7        1.0494             nan     0.1000    0.0014
##      8        1.0471             nan     0.1000    0.0012
##      9        1.0459             nan     0.1000    0.0003
##     10        1.0451             nan     0.1000    0.0001
##     20        1.0357             nan     0.1000   -0.0005
##     40        1.0258             nan     0.1000   -0.0002
##     60        1.0210             nan     0.1000   -0.0003
##     80        1.0173             nan     0.1000   -0.0003
##    100        1.0138             nan     0.1000   -0.0007
##    120        1.0109             nan     0.1000   -0.0010
##    140        1.0080             nan     0.1000   -0.0006
##    150        1.0061             nan     0.1000   -0.0008
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0540             nan     0.1000    0.0015
##      2        1.0481             nan     0.1000    0.0010
##      3        1.0432             nan     0.1000    0.0006
##      4        1.0411             nan     0.1000    0.0010
##      5        1.0321             nan     0.1000   -0.0004
##      6        1.0293             nan     0.1000    0.0005
##      7        1.0163             nan     0.1000   -0.0015
##      8        1.0133             nan     0.1000   -0.0001
##      9        1.0119             nan     0.1000   -0.0002
##     10        1.0089             nan     0.1000    0.0004
##     20        0.9702             nan     0.1000   -0.0015
##     40        0.9096             nan     0.1000   -0.0024
##     60        0.8798             nan     0.1000   -0.0016
##     80        0.8645             nan     0.1000   -0.0033
##    100        0.8421             nan     0.1000   -0.0007
##    120        0.8172             nan     0.1000   -0.0005
##    140        0.8045             nan     0.1000   -0.0007
##    150        0.8009             nan     0.1000   -0.0024
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0438             nan     0.1000   -0.0012
##      2        1.0353             nan     0.1000    0.0018
##      3        1.0233             nan     0.1000    0.0029
##      4        1.0129             nan     0.1000    0.0006
##      5        1.0061             nan     0.1000   -0.0012
##      6        1.0036             nan     0.1000    0.0002
##      7        0.9945             nan     0.1000   -0.0009
##      8        0.9859             nan     0.1000   -0.0006
##      9        0.9786             nan     0.1000   -0.0041
##     10        0.9730             nan     0.1000   -0.0025
##     20        0.9276             nan     0.1000   -0.0004
##     40        0.8620             nan     0.1000   -0.0013
##     60        0.8081             nan     0.1000   -0.0026
##     80        0.7722             nan     0.1000   -0.0005
##    100        0.7492             nan     0.1000   -0.0013
##    120        0.7160             nan     0.1000   -0.0002
##    140        0.6850             nan     0.1000   -0.0024
##    150        0.6736             nan     0.1000   -0.0008
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        0.4353             nan     0.1000    0.0008
##      2        0.4340             nan     0.1000    0.0010
##      3        0.4325             nan     0.1000    0.0014
##      4        0.4315             nan     0.1000    0.0008
##      5        0.4308             nan     0.1000    0.0001
##      6        0.4302             nan     0.1000   -0.0000
##      7        0.4290             nan     0.1000    0.0009
##      8        0.4286             nan     0.1000   -0.0002
##      9        0.4280             nan     0.1000   -0.0002
##     10        0.4272             nan     0.1000    0.0004
##     20        0.4219             nan     0.1000   -0.0001
##     40        0.4141             nan     0.1000   -0.0000
##     60        0.4095             nan     0.1000    0.0002
##     80        0.4065             nan     0.1000   -0.0002
##    100        0.4041             nan     0.1000   -0.0002
##    120        0.4022             nan     0.1000   -0.0007
##    140        0.3999             nan     0.1000   -0.0002
##    150        0.3993             nan     0.1000   -0.0003
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        0.4339             nan     0.1000   -0.0003
##      2        0.4310             nan     0.1000    0.0010
##      3        0.4297             nan     0.1000    0.0000
##      4        0.4272             nan     0.1000    0.0003
##      5        0.4259             nan     0.1000    0.0003
##      6        0.4249             nan     0.1000    0.0000
##      7        0.4226             nan     0.1000   -0.0007
##      8        0.4207             nan     0.1000   -0.0001
##      9        0.4188             nan     0.1000    0.0004
##     10        0.4174             nan     0.1000    0.0006
##     20        0.4056             nan     0.1000   -0.0000
##     40        0.3891             nan     0.1000   -0.0001
##     60        0.3756             nan     0.1000   -0.0008
##     80        0.3663             nan     0.1000   -0.0003
##    100        0.3593             nan     0.1000   -0.0008
##    120        0.3532             nan     0.1000   -0.0010
##    140        0.3476             nan     0.1000   -0.0002
##    150        0.3457             nan     0.1000   -0.0005
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        0.4343             nan     0.1000    0.0011
##      2        0.4303             nan     0.1000    0.0012
##      3        0.4253             nan     0.1000    0.0007
##      4        0.4220             nan     0.1000    0.0001
##      5        0.4200             nan     0.1000    0.0002
##      6        0.4164             nan     0.1000   -0.0002
##      7        0.4149             nan     0.1000    0.0007
##      8        0.4135             nan     0.1000    0.0001
##      9        0.4114             nan     0.1000   -0.0000
##     10        0.4094             nan     0.1000   -0.0002
##     20        0.3927             nan     0.1000    0.0003
##     40        0.3766             nan     0.1000   -0.0007
##     60        0.3616             nan     0.1000   -0.0002
##     80        0.3492             nan     0.1000   -0.0004
##    100        0.3398             nan     0.1000   -0.0011
##    120        0.3300             nan     0.1000   -0.0004
##    140        0.3210             nan     0.1000   -0.0002
##    150        0.3171             nan     0.1000   -0.0010
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0790             nan     0.1000    0.0022
##      2        1.0765             nan     0.1000    0.0022
##      3        1.0759             nan     0.1000    0.0001
##      4        1.0738             nan     0.1000    0.0017
##      5        1.0722             nan     0.1000    0.0003
##      6        1.0709             nan     0.1000    0.0006
##      7        1.0690             nan     0.1000    0.0004
##      8        1.0670             nan     0.1000    0.0008
##      9        1.0663             nan     0.1000    0.0000
##     10        1.0650             nan     0.1000    0.0003
##     20        1.0582             nan     0.1000   -0.0002
##     40        1.0472             nan     0.1000   -0.0001
##     60        1.0419             nan     0.1000   -0.0013
##     80        1.0383             nan     0.1000   -0.0003
##    100        1.0351             nan     0.1000   -0.0003
##    120        1.0321             nan     0.1000   -0.0010
##    140        1.0288             nan     0.1000   -0.0008
##    150        1.0279             nan     0.1000   -0.0007
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0761             nan     0.1000    0.0009
##      2        1.0727             nan     0.1000    0.0014
##      3        1.0682             nan     0.1000    0.0005
##      4        1.0613             nan     0.1000   -0.0002
##      5        1.0531             nan     0.1000   -0.0003
##      6        1.0444             nan     0.1000   -0.0006
##      7        1.0411             nan     0.1000    0.0014
##      8        1.0340             nan     0.1000   -0.0010
##      9        1.0331             nan     0.1000   -0.0000
##     10        1.0296             nan     0.1000   -0.0007
##     20        1.0098             nan     0.1000   -0.0016
##     40        0.9626             nan     0.1000   -0.0015
##     60        0.9193             nan     0.1000   -0.0003
##     80        0.8965             nan     0.1000   -0.0007
##    100        0.8829             nan     0.1000   -0.0033
##    120        0.8605             nan     0.1000   -0.0011
##    140        0.8433             nan     0.1000   -0.0007
##    150        0.8363             nan     0.1000   -0.0012
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0748             nan     0.1000   -0.0001
##      2        1.0668             nan     0.1000   -0.0005
##      3        1.0582             nan     0.1000    0.0001
##      4        1.0514             nan     0.1000   -0.0005
##      5        1.0492             nan     0.1000   -0.0007
##      6        1.0477             nan     0.1000   -0.0002
##      7        1.0303             nan     0.1000   -0.0045
##      8        1.0232             nan     0.1000   -0.0012
##      9        1.0214             nan     0.1000    0.0007
##     10        1.0158             nan     0.1000   -0.0004
##     20        0.9575             nan     0.1000   -0.0007
##     40        0.8793             nan     0.1000    0.0021
##     60        0.8336             nan     0.1000   -0.0010
##     80        0.7948             nan     0.1000   -0.0007
##    100        0.7655             nan     0.1000   -0.0015
##    120        0.7327             nan     0.1000   -0.0008
##    140        0.7046             nan     0.1000   -0.0012
##    150        0.6958             nan     0.1000   -0.0023
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0657             nan     0.1000    0.0017
##      2        1.0639             nan     0.1000    0.0010
##      3        1.0630             nan     0.1000    0.0001
##      4        1.0612             nan     0.1000    0.0014
##      5        1.0597             nan     0.1000   -0.0005
##      6        1.0583             nan     0.1000   -0.0001
##      7        1.0579             nan     0.1000   -0.0003
##      8        1.0574             nan     0.1000   -0.0002
##      9        1.0565             nan     0.1000   -0.0000
##     10        1.0546             nan     0.1000    0.0008
##     20        1.0464             nan     0.1000    0.0006
##     40        1.0381             nan     0.1000   -0.0005
##     60        1.0328             nan     0.1000   -0.0009
##     80        1.0289             nan     0.1000   -0.0007
##    100        1.0253             nan     0.1000   -0.0004
##    120        1.0220             nan     0.1000   -0.0012
##    140        1.0184             nan     0.1000   -0.0001
##    150        1.0170             nan     0.1000   -0.0003
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0633             nan     0.1000    0.0014
##      2        1.0589             nan     0.1000    0.0009
##      3        1.0567             nan     0.1000   -0.0003
##      4        1.0455             nan     0.1000    0.0024
##      5        1.0370             nan     0.1000    0.0003
##      6        1.0272             nan     0.1000   -0.0025
##      7        1.0246             nan     0.1000    0.0012
##      8        1.0183             nan     0.1000   -0.0033
##      9        1.0175             nan     0.1000   -0.0002
##     10        1.0158             nan     0.1000    0.0006
##     20        0.9831             nan     0.1000   -0.0079
##     40        0.9439             nan     0.1000   -0.0010
##     60        0.9116             nan     0.1000   -0.0011
##     80        0.8914             nan     0.1000   -0.0026
##    100        0.8665             nan     0.1000   -0.0004
##    120        0.8572             nan     0.1000   -0.0048
##    140        0.8426             nan     0.1000   -0.0007
##    150        0.8338             nan     0.1000   -0.0003
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0613             nan     0.1000    0.0016
##      2        1.0562             nan     0.1000    0.0006
##      3        1.0528             nan     0.1000    0.0006
##      4        1.0491             nan     0.1000    0.0004
##      5        1.0360             nan     0.1000    0.0057
##      6        1.0280             nan     0.1000   -0.0008
##      7        1.0140             nan     0.1000   -0.0025
##      8        1.0049             nan     0.1000   -0.0009
##      9        0.9987             nan     0.1000   -0.0021
##     10        0.9901             nan     0.1000   -0.0007
##     20        0.9341             nan     0.1000   -0.0026
##     40        0.8683             nan     0.1000   -0.0004
##     60        0.8262             nan     0.1000   -0.0009
##     80        0.7793             nan     0.1000   -0.0015
##    100        0.7558             nan     0.1000    0.0002
##    120        0.7259             nan     0.1000   -0.0011
##    140        0.6963             nan     0.1000   -0.0011
##    150        0.6796             nan     0.1000   -0.0009
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0911             nan     0.1000    0.0014
##      2        1.0906             nan     0.1000   -0.0002
##      3        1.0879             nan     0.1000    0.0017
##      4        1.0854             nan     0.1000    0.0010
##      5        1.0841             nan     0.1000   -0.0001
##      6        1.0832             nan     0.1000   -0.0002
##      7        1.0824             nan     0.1000   -0.0001
##      8        1.0807             nan     0.1000    0.0002
##      9        1.0802             nan     0.1000   -0.0001
##     10        1.0799             nan     0.1000   -0.0006
##     20        1.0706             nan     0.1000    0.0002
##     40        1.0620             nan     0.1000    0.0000
##     60        1.0564             nan     0.1000   -0.0007
##     80        1.0518             nan     0.1000   -0.0010
##    100        1.0485             nan     0.1000   -0.0008
##    120        1.0466             nan     0.1000   -0.0009
##    140        1.0435             nan     0.1000   -0.0012
##    150        1.0414             nan     0.1000   -0.0002
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0866             nan     0.1000    0.0013
##      2        1.0795             nan     0.1000   -0.0022
##      3        1.0737             nan     0.1000    0.0006
##      4        1.0700             nan     0.1000    0.0006
##      5        1.0671             nan     0.1000    0.0005
##      6        1.0624             nan     0.1000    0.0010
##      7        1.0595             nan     0.1000    0.0008
##      8        1.0565             nan     0.1000   -0.0000
##      9        1.0546             nan     0.1000   -0.0004
##     10        1.0521             nan     0.1000   -0.0008
##     20        1.0095             nan     0.1000   -0.0048
##     40        0.9678             nan     0.1000   -0.0014
##     60        0.9402             nan     0.1000   -0.0011
##     80        0.9173             nan     0.1000   -0.0007
##    100        0.8898             nan     0.1000   -0.0017
##    120        0.8697             nan     0.1000   -0.0012
##    140        0.8523             nan     0.1000   -0.0006
##    150        0.8449             nan     0.1000   -0.0014
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0838             nan     0.1000    0.0008
##      2        1.0764             nan     0.1000    0.0019
##      3        1.0663             nan     0.1000    0.0048
##      4        1.0579             nan     0.1000   -0.0001
##      5        1.0493             nan     0.1000   -0.0001
##      6        1.0398             nan     0.1000   -0.0030
##      7        1.0309             nan     0.1000   -0.0012
##      8        1.0237             nan     0.1000   -0.0032
##      9        1.0178             nan     0.1000   -0.0014
##     10        1.0110             nan     0.1000   -0.0002
##     20        0.9588             nan     0.1000   -0.0052
##     40        0.9091             nan     0.1000   -0.0030
##     60        0.8536             nan     0.1000    0.0003
##     80        0.8033             nan     0.1000   -0.0013
##    100        0.7654             nan     0.1000   -0.0019
##    120        0.7338             nan     0.1000   -0.0027
##    140        0.7063             nan     0.1000   -0.0007
##    150        0.6917             nan     0.1000   -0.0017
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0389             nan     0.1000    0.0024
##      2        1.0359             nan     0.1000    0.0007
##      3        1.0337             nan     0.1000    0.0011
##      4        1.0318             nan     0.1000    0.0013
##      5        1.0298             nan     0.1000    0.0008
##      6        1.0283             nan     0.1000    0.0009
##      7        1.0274             nan     0.1000    0.0006
##      8        1.0259             nan     0.1000   -0.0003
##      9        1.0250             nan     0.1000    0.0000
##     10        1.0245             nan     0.1000   -0.0002
##     20        1.0180             nan     0.1000    0.0001
##     40        1.0071             nan     0.1000   -0.0000
##     60        1.0008             nan     0.1000   -0.0003
##     80        0.9977             nan     0.1000   -0.0001
##    100        0.9954             nan     0.1000   -0.0002
##    120        0.9926             nan     0.1000    0.0003
##    140        0.9901             nan     0.1000   -0.0007
##    150        0.9890             nan     0.1000   -0.0005
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0363             nan     0.1000    0.0036
##      2        1.0331             nan     0.1000    0.0023
##      3        1.0282             nan     0.1000    0.0005
##      4        1.0248             nan     0.1000   -0.0015
##      5        1.0166             nan     0.1000   -0.0006
##      6        1.0075             nan     0.1000    0.0043
##      7        0.9997             nan     0.1000   -0.0009
##      8        0.9961             nan     0.1000    0.0003
##      9        0.9951             nan     0.1000    0.0006
##     10        0.9899             nan     0.1000    0.0012
##     20        0.9561             nan     0.1000   -0.0023
##     40        0.9216             nan     0.1000   -0.0008
##     60        0.8952             nan     0.1000   -0.0001
##     80        0.8697             nan     0.1000   -0.0003
##    100        0.8422             nan     0.1000   -0.0014
##    120        0.8249             nan     0.1000   -0.0007
##    140        0.8031             nan     0.1000   -0.0009
##    150        0.7882             nan     0.1000   -0.0003
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0305             nan     0.1000    0.0015
##      2        1.0237             nan     0.1000    0.0007
##      3        1.0159             nan     0.1000    0.0013
##      4        1.0089             nan     0.1000   -0.0005
##      5        1.0035             nan     0.1000   -0.0009
##      6        0.9963             nan     0.1000   -0.0010
##      7        0.9936             nan     0.1000   -0.0002
##      8        0.9916             nan     0.1000    0.0013
##      9        0.9820             nan     0.1000   -0.0004
##     10        0.9747             nan     0.1000    0.0029
##     20        0.9310             nan     0.1000   -0.0003
##     40        0.8499             nan     0.1000   -0.0010
##     60        0.8017             nan     0.1000   -0.0009
##     80        0.7756             nan     0.1000    0.0007
##    100        0.7375             nan     0.1000   -0.0009
##    120        0.7116             nan     0.1000   -0.0003
##    140        0.6916             nan     0.1000   -0.0008
##    150        0.6786             nan     0.1000   -0.0009
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        0.9965             nan     0.1000    0.0020
##      2        0.9943             nan     0.1000    0.0017
##      3        0.9921             nan     0.1000    0.0011
##      4        0.9905             nan     0.1000    0.0009
##      5        0.9893             nan     0.1000    0.0007
##      6        0.9879             nan     0.1000    0.0006
##      7        0.9866             nan     0.1000   -0.0003
##      8        0.9856             nan     0.1000    0.0005
##      9        0.9846             nan     0.1000    0.0002
##     10        0.9834             nan     0.1000    0.0001
##     20        0.9769             nan     0.1000   -0.0006
##     40        0.9692             nan     0.1000   -0.0009
##     50        0.9662             nan     0.1000   -0.0003

gbmFit

## Stochastic Gradient Boosting 
## 
## 5175 samples
##   37 predictor
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 4657, 4658, 4658, 4656, 4657, 4658, ... 
## Resampling results across tuning parameters:
## 
##   interaction.depth  n.trees  RMSE       Rsquared    MAE      
##   1                   50      0.8228995  0.02985847  0.2950095
##   1                  100      0.8236287  0.03199829  0.2961279
##   1                  150      0.8248168  0.03084859  0.2957592
##   2                   50      0.8413666  0.02051948  0.3009141
##   2                  100      0.8569796  0.01801505  0.3087319
##   2                  150      0.8686868  0.01654918  0.3155867
##   3                   50      0.8490519  0.02591793  0.3061468
##   3                  100      0.8624600  0.02259466  0.3144505
##   3                  150      0.8698240  0.02429420  0.3210204
## 
## Tuning parameter &#39;shrinkage&#39; was held constant at a value of 0.1
## Tuning parameter &#39;n.minobsinnode&#39; was held constant at a value
##  of 10
## RMSE was used to select the optimal model using the smallest value.
## The final values used for the model were n.trees = 50, interaction.depth = 1, shrinkage = 0.1 and n.minobsinnode = 10.

# create the prediction
pred2 &lt;- predict(gbmFit, newdata = newsPopTest)

# compare the prediction vs the actual
resample2 &lt;- postResample(pred2, obs = newsPopTest$shares)
resample2

##       RMSE   Rsquared        MAE 
## 0.95542018 0.01247656 0.30161467</code></pre>
<h3 id="linear-regression-model">Linear Regression Model</h3>
<p>Linear regression is used to predict the outcome of a response variable for 1 to n predictors. The aim is to establish a linear relationship between the predictor variable(s) and response variable so we can predict the value of the response when only the predictor variable(s) is(are) known.</p>
<pre><code># train the linear model for main effects + interactions on first 3 preds
lmFit &lt;- train(shares ~ timedelta*n_tokens_title*n_tokens_content, data = newsPopTrain,
                                                                   method = &quot;lm&quot;, preProces = c(&quot;center&quot;, &quot;scale&quot;),
                                                                   trControl = trainControl(method = &quot;cv&quot;, number = 10))
lmFit

## Linear Regression 
## 
## 5175 samples
##    3 predictor
## 
## Pre-processing: centered (7), scaled (7) 
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 4658, 4658, 4657, 4657, 4657, 4657, ... 
## Resampling results:
## 
##   RMSE       Rsquared     MAE      
##   0.8818785  0.001560738  0.3044919
## 
## Tuning parameter &#39;intercept&#39; was held constant at a value of TRUE

# create the prediction
pred3 &lt;- predict(lmFit, newdata = newsPopTest)

# compare the prediction vs the actual
resample3 &lt;- postResample(pred3, obs = newsPopTest$shares)
resample3

##         RMSE     Rsquared          MAE 
## 9.608389e-01 2.425307e-08 3.122606e-01</code></pre>
<h3 id="comparison">Comparison</h3>
<p>Below is a comparison of the 3 methods. All have relatively high root mean square errors.</p>
<pre><code>comparison &lt;- data.frame(&quot;RSME&quot; = c(resample1[[1]], resample2[[1]], resample3[1]), &quot;MAE&quot; = c(resample1[[3]], resample2[[3]], resample3[[3]]))
rownames(comparison) &lt;- c(&quot;RPART&quot;,&quot;GBM&quot;, &quot;LM&quot;)
kable(comparison)</code></pre>
<table>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
RSME
</th>
<th style="text-align:right;">
MAE
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
RPART
</td>
<td style="text-align:right;">
0.9605903
</td>
<td style="text-align:right;">
0.3123001
</td>
</tr>
<tr>
<td style="text-align:left;">
GBM
</td>
<td style="text-align:right;">
0.9554202
</td>
<td style="text-align:right;">
0.3016147
</td>
</tr>
<tr>
<td style="text-align:left;">
LM
</td>
<td style="text-align:right;">
0.9608389
</td>
<td style="text-align:right;">
0.3122606
</td>
</tr>
</tbody>
</table>

</body>
</html>
