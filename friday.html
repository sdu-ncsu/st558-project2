<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1">

<style type="text/css">
@font-face {
font-family: octicons-link;
src: url(data:font/woff;charset=utf-8;base64,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) format('woff');
}
body {
-webkit-text-size-adjust: 100%;
text-size-adjust: 100%;
color: #333;
font-family: "Helvetica Neue", Helvetica, "Segoe UI", Arial, freesans, sans-serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol";
font-size: 16px;
line-height: 1.6;
word-wrap: break-word;
}
a {
background-color: transparent;
}
a:active,
a:hover {
outline: 0;
}
strong {
font-weight: bold;
}
h1 {
font-size: 2em;
margin: 0.67em 0;
}
img {
border: 0;
}
hr {
box-sizing: content-box;
height: 0;
}
pre {
overflow: auto;
}
code,
kbd,
pre {
font-family: monospace, monospace;
font-size: 1em;
}
input {
color: inherit;
font: inherit;
margin: 0;
}
html input[disabled] {
cursor: default;
}
input {
line-height: normal;
}
input[type="checkbox"] {
box-sizing: border-box;
padding: 0;
}
table {
border-collapse: collapse;
border-spacing: 0;
}
td,
th {
padding: 0;
}
* {
box-sizing: border-box;
}
input {
font: 13px / 1.4 Helvetica, arial, nimbussansl, liberationsans, freesans, clean, sans-serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol";
}
a {
color: #4078c0;
text-decoration: none;
}
a:hover,
a:active {
text-decoration: underline;
}
hr {
height: 0;
margin: 15px 0;
overflow: hidden;
background: transparent;
border: 0;
border-bottom: 1px solid #ddd;
}
hr:before {
display: table;
content: "";
}
hr:after {
display: table;
clear: both;
content: "";
}
h1,
h2,
h3,
h4,
h5,
h6 {
margin-top: 15px;
margin-bottom: 15px;
line-height: 1.1;
}
h1 {
font-size: 30px;
}
h2 {
font-size: 21px;
}
h3 {
font-size: 16px;
}
h4 {
font-size: 14px;
}
h5 {
font-size: 12px;
}
h6 {
font-size: 11px;
}
blockquote {
margin: 0;
}
ul,
ol {
padding: 0;
margin-top: 0;
margin-bottom: 0;
}
ol ol,
ul ol {
list-style-type: lower-roman;
}
ul ul ol,
ul ol ol,
ol ul ol,
ol ol ol {
list-style-type: lower-alpha;
}
dd {
margin-left: 0;
}
code {
font-family: Consolas, "Liberation Mono", Menlo, Courier, monospace;
font-size: 12px;
}
pre {
margin-top: 0;
margin-bottom: 0;
font: 12px Consolas, "Liberation Mono", Menlo, Courier, monospace;
}
.select::-ms-expand {
opacity: 0;
}
.octicon {
font: normal normal normal 16px/1 octicons-link;
display: inline-block;
text-decoration: none;
text-rendering: auto;
-webkit-font-smoothing: antialiased;
-moz-osx-font-smoothing: grayscale;
-webkit-user-select: none;
-moz-user-select: none;
-ms-user-select: none;
user-select: none;
}
.octicon-link:before {
content: '\f05c';
}
.markdown-body:before {
display: table;
content: "";
}
.markdown-body:after {
display: table;
clear: both;
content: "";
}
.markdown-body>*:first-child {
margin-top: 0 !important;
}
.markdown-body>*:last-child {
margin-bottom: 0 !important;
}
a:not([href]) {
color: inherit;
text-decoration: none;
}
.anchor {
display: inline-block;
padding-right: 2px;
margin-left: -18px;
}
.anchor:focus {
outline: none;
}
h1,
h2,
h3,
h4,
h5,
h6 {
margin-top: 1em;
margin-bottom: 16px;
font-weight: bold;
line-height: 1.4;
}
h1 .octicon-link,
h2 .octicon-link,
h3 .octicon-link,
h4 .octicon-link,
h5 .octicon-link,
h6 .octicon-link {
color: #000;
vertical-align: middle;
visibility: hidden;
}
h1:hover .anchor,
h2:hover .anchor,
h3:hover .anchor,
h4:hover .anchor,
h5:hover .anchor,
h6:hover .anchor {
text-decoration: none;
}
h1:hover .anchor .octicon-link,
h2:hover .anchor .octicon-link,
h3:hover .anchor .octicon-link,
h4:hover .anchor .octicon-link,
h5:hover .anchor .octicon-link,
h6:hover .anchor .octicon-link {
visibility: visible;
}
h1 {
padding-bottom: 0.3em;
font-size: 2.25em;
line-height: 1.2;
border-bottom: 1px solid #eee;
}
h1 .anchor {
line-height: 1;
}
h2 {
padding-bottom: 0.3em;
font-size: 1.75em;
line-height: 1.225;
border-bottom: 1px solid #eee;
}
h2 .anchor {
line-height: 1;
}
h3 {
font-size: 1.5em;
line-height: 1.43;
}
h3 .anchor {
line-height: 1.2;
}
h4 {
font-size: 1.25em;
}
h4 .anchor {
line-height: 1.2;
}
h5 {
font-size: 1em;
}
h5 .anchor {
line-height: 1.1;
}
h6 {
font-size: 1em;
color: #777;
}
h6 .anchor {
line-height: 1.1;
}
p,
blockquote,
ul,
ol,
dl,
table,
pre {
margin-top: 0;
margin-bottom: 16px;
}
hr {
height: 4px;
padding: 0;
margin: 16px 0;
background-color: #e7e7e7;
border: 0 none;
}
ul,
ol {
padding-left: 2em;
}
ul ul,
ul ol,
ol ol,
ol ul {
margin-top: 0;
margin-bottom: 0;
}
li>p {
margin-top: 16px;
}
dl {
padding: 0;
}
dl dt {
padding: 0;
margin-top: 16px;
font-size: 1em;
font-style: italic;
font-weight: bold;
}
dl dd {
padding: 0 16px;
margin-bottom: 16px;
}
blockquote {
padding: 0 15px;
color: #777;
border-left: 4px solid #ddd;
}
blockquote>:first-child {
margin-top: 0;
}
blockquote>:last-child {
margin-bottom: 0;
}
table {
display: block;
width: 100%;
overflow: auto;
word-break: normal;
word-break: keep-all;
}
table th {
font-weight: bold;
}
table th,
table td {
padding: 6px 13px;
border: 1px solid #ddd;
}
table tr {
background-color: #fff;
border-top: 1px solid #ccc;
}
table tr:nth-child(2n) {
background-color: #f8f8f8;
}
img {
max-width: 100%;
box-sizing: content-box;
background-color: #fff;
}
code {
padding: 0;
padding-top: 0.2em;
padding-bottom: 0.2em;
margin: 0;
font-size: 85%;
background-color: rgba(0,0,0,0.04);
border-radius: 3px;
}
code:before,
code:after {
letter-spacing: -0.2em;
content: "\00a0";
}
pre>code {
padding: 0;
margin: 0;
font-size: 100%;
word-break: normal;
white-space: pre;
background: transparent;
border: 0;
}
.highlight {
margin-bottom: 16px;
}
.highlight pre,
pre {
padding: 16px;
overflow: auto;
font-size: 85%;
line-height: 1.45;
background-color: #f7f7f7;
border-radius: 3px;
}
.highlight pre {
margin-bottom: 0;
word-break: normal;
}
pre {
word-wrap: normal;
}
pre code {
display: inline;
max-width: initial;
padding: 0;
margin: 0;
overflow: initial;
line-height: inherit;
word-wrap: normal;
background-color: transparent;
border: 0;
}
pre code:before,
pre code:after {
content: normal;
}
kbd {
display: inline-block;
padding: 3px 5px;
font-size: 11px;
line-height: 10px;
color: #555;
vertical-align: middle;
background-color: #fcfcfc;
border: solid 1px #ccc;
border-bottom-color: #bbb;
border-radius: 3px;
box-shadow: inset 0 -1px 0 #bbb;
}
.pl-c {
color: #969896;
}
.pl-c1,
.pl-s .pl-v {
color: #0086b3;
}
.pl-e,
.pl-en {
color: #795da3;
}
.pl-s .pl-s1,
.pl-smi {
color: #333;
}
.pl-ent {
color: #63a35c;
}
.pl-k {
color: #a71d5d;
}
.pl-pds,
.pl-s,
.pl-s .pl-pse .pl-s1,
.pl-sr,
.pl-sr .pl-cce,
.pl-sr .pl-sra,
.pl-sr .pl-sre {
color: #183691;
}
.pl-v {
color: #ed6a43;
}
.pl-id {
color: #b52a1d;
}
.pl-ii {
background-color: #b52a1d;
color: #f8f8f8;
}
.pl-sr .pl-cce {
color: #63a35c;
font-weight: bold;
}
.pl-ml {
color: #693a17;
}
.pl-mh,
.pl-mh .pl-en,
.pl-ms {
color: #1d3e81;
font-weight: bold;
}
.pl-mq {
color: #008080;
}
.pl-mi {
color: #333;
font-style: italic;
}
.pl-mb {
color: #333;
font-weight: bold;
}
.pl-md {
background-color: #ffecec;
color: #bd2c00;
}
.pl-mi1 {
background-color: #eaffea;
color: #55a532;
}
.pl-mdr {
color: #795da3;
font-weight: bold;
}
.pl-mo {
color: #1d3e81;
}
kbd {
display: inline-block;
padding: 3px 5px;
font: 11px Consolas, "Liberation Mono", Menlo, Courier, monospace;
line-height: 10px;
color: #555;
vertical-align: middle;
background-color: #fcfcfc;
border: solid 1px #ccc;
border-bottom-color: #bbb;
border-radius: 3px;
box-shadow: inset 0 -1px 0 #bbb;
}
.task-list-item {
list-style-type: none;
}
.task-list-item+.task-list-item {
margin-top: 3px;
}
.task-list-item input {
margin: 0 0.35em 0.25em -1.6em;
vertical-align: middle;
}
:checked+.radio-label {
z-index: 1;
position: relative;
border-color: #4078c0;
}
.sourceLine {
display: inline-block;
}
code .kw { color: #000000; }
code .dt { color: #ed6a43; }
code .dv { color: #009999; }
code .bn { color: #009999; }
code .fl { color: #009999; }
code .ch { color: #009999; }
code .st { color: #183691; }
code .co { color: #969896; }
code .ot { color: #0086b3; }
code .al { color: #a61717; }
code .fu { color: #63a35c; }
code .er { color: #a61717; background-color: #e3d2d2; }
code .wa { color: #000000; }
code .cn { color: #008080; }
code .sc { color: #008080; }
code .vs { color: #183691; }
code .ss { color: #183691; }
code .im { color: #000000; }
code .va {color: #008080; }
code .cf { color: #000000; }
code .op { color: #000000; }
code .bu { color: #000000; }
code .ex { color: #000000; }
code .pp { color: #999999; }
code .at { color: #008080; }
code .do { color: #969896; }
code .an { color: #008080; }
code .cv { color: #008080; }
code .in { color: #008080; }
</style>
<style>
body {
  box-sizing: border-box;
  min-width: 200px;
  max-width: 980px;
  margin: 0 auto;
  padding: 45px;
  padding-top: 0px;
}
</style>

</head>

<body>

<h1 id="news-popularity-friday-data">News Popularity Friday Data</h1>
<p>Shuang Du 10/16/2020</p>
<h2 id="load-libraries">Load Libraries</h2>
<pre><code>library(readxl);
library(tidyverse);
library(caret);
library(modelr);
library(rpart);
library(kableExtra);</code></pre>
<h2 id="read-in-data">Read in Data</h2>
<pre><code>getData &lt;- function(day) {

  newsPopData &lt;- read_csv(&quot;raw_data/OnlineNewsPopularity.csv&quot;)
  
  if (day == &#39;monday&#39;) {
    newsPopData &lt;- newsPopData %&gt;% filter(weekday_is_monday == 1)
  } else if(day == &#39;tuesday&#39;) {
    newsPopData &lt;- newsPopData %&gt;% filter(weekday_is_tuesday == 1)
  } else if(day == &#39;wednesday&#39;) {
    newsPopData &lt;- newsPopData %&gt;% filter(weekday_is_wednesday == 1)
  } else if(day == &#39;thursday&#39;) {
    newsPopData &lt;- newsPopData %&gt;% filter(weekday_is_thursday == 1)
  } else if(day == &#39;friday&#39;) {
    newsPopData &lt;- newsPopData %&gt;% filter(weekday_is_friday == 1)
  } else if(day == &#39;saturday&#39;) {
    newsPopData &lt;- newsPopData %&gt;% filter(weekday_is_saturday == 1)
  } else if(day == &#39;sunday&#39;) {
    newsPopData &lt;- newsPopData %&gt;% filter(weekday_is_sunday == 1)
  } else {
    stop(&quot;Invalid date&quot;)
  }
  return(newsPopData)
}

newsPopData &lt;- getData(params$day)</code></pre>
<h2 id="set-aside-training-data">Set Aside Training Data</h2>
<pre><code>set.seed(92)
trainIndex &lt;- createDataPartition(newsPopData$shares, 
                                  p = 0.7, list = FALSE)

newsPopTrain &lt;- newsPopData[as.vector(trainIndex),];
newsPopTest &lt;- newsPopData[-as.vector(trainIndex),];</code></pre>
<h2 id="center-and-scale">Center and Scale</h2>
<pre><code>preProcValues &lt;- preProcess(newsPopTrain, method = c(&quot;center&quot;, &quot;scale&quot;))
newsPopTrain &lt;- predict(preProcValues, newsPopTrain) 
newsPopTest &lt;- predict(preProcValues, newsPopTest)</code></pre>
<h2 id="summary-of-a-few-variables">Summary of a Few Variables</h2>
<p>The plots below show a histogram of the number of shares for the given day. Scatter plots on the effect of max positive polarity, article time delta and number of videos in the article are also included.</p>
<p>As expected the histogram has a strong right tail, as seem by the summary stats which show a very high maximum and a median severals orders of magnitude lower. This is expected for because of the “viral” nature of online popularity.</p>
<pre><code>summary(newsPopTrain$shares)

##     Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
## -0.42680 -0.29889 -0.22801  0.00000 -0.06661 30.96279

g0 &lt;- ggplot(newsPopTrain, aes(x=shares))
g0 + geom_histogram(binwidth = 0.5) + ggtitle(&#39;Histogram for Number of Shares&#39;) + ylab(&#39;Number of Shares&#39;) + xlab(&#39;Shares&#39;)</code></pre>
<p><img src="data:image/png;base64,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" /><!-- --></p>
<pre><code>summary(newsPopTrain$max_positive_polarity)

##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
## -3.0308 -0.6086  0.1988  0.0000  1.0062  1.0062

g1 &lt;- ggplot(newsPopTrain, aes(x = max_positive_polarity, y = shares )) 
g1 + geom_point() + ggtitle(&#39;Scatter of Max Positive Polarity Effect&#39;) + ylab(&#39;Shares&#39;) + xlab(&#39;Max Positive Polarity&#39;)</code></pre>
<p><img src="data:image/png;base64,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" /><!-- --></p>
<pre><code>summary(newsPopTrain$timedelta)

##     Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
## -1.59326 -0.87297 -0.08719  0.00000  0.89503  1.74628

g2 &lt;- ggplot(newsPopTrain, aes(x = timedelta, y = shares )) 
g2 + geom_point() + ggtitle(&#39;Scatter of Article Age Effect&#39;) + ylab(&#39;Shares&#39;) + xlab(&#39;Time Delta&#39;)</code></pre>
<p><img src="data:image/png;base64,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" /><!-- --></p>
<pre><code>summary(newsPopTrain$num_videos)

##     Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
## -0.29027 -0.29027 -0.29027  0.00000 -0.06121 20.55418

g3 &lt;- ggplot(newsPopTrain, aes(x = num_videos, y = shares )) 
g3 + geom_point() + ggtitle(&#39;Scatter of Videos Number Effect&#39;) + ylab(&#39;Shares&#39;) + xlab(&#39;Number of Videos&#39;)</code></pre>
<p><img src="data:image/png;base64,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" /><!-- --></p>
<h2 id="modeling">Modeling</h2>
<h3 id="standard-tree-based-model-no-ensemble">Standard Tree Based Model (no ensemble)</h3>
<p>The type of model being fitted here is a decision tree. The tree splits are based on minimizing the residual sum of squares for each region.</p>
<pre><code>rpartFit &lt;- train(shares ~ timedelta + n_tokens_title + n_tokens_content + n_unique_tokens + n_non_stop_words + n_non_stop_unique_tokens
                 + num_hrefs + num_self_hrefs + num_imgs + num_videos + average_token_length + num_keywords + data_channel_is_lifestyle +
                 data_channel_is_entertainment + data_channel_is_bus + data_channel_is_socmed + data_channel_is_tech + data_channel_is_world +
                 self_reference_min_shares + self_reference_max_shares + self_reference_avg_sharess + global_subjectivity + global_sentiment_polarity
                 + global_rate_positive_words + global_rate_negative_words + rate_positive_words + rate_negative_words + avg_positive_polarity +
                  min_positive_polarity + max_positive_polarity + avg_negative_polarity + min_negative_polarity + max_negative_polarity + title_subjectivity
                 + title_sentiment_polarity + abs_title_subjectivity + abs_title_sentiment_polarity, data = newsPopTrain,
             method = &quot;rpart&quot;,
             trControl = trainControl(method = &quot;cv&quot;, number = 10),
             tuneGrid = data.frame(cp = c(.001,.01,.015,.02,.03,.04,.05))
             )
rpartFit

## CART 
## 
## 3993 samples
##   37 predictor
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 3594, 3594, 3594, 3593, 3593, 3594, ... 
## Resampling results across tuning parameters:
## 
##   cp     RMSE       Rsquared     MAE      
##   0.001  1.0184006  0.032329340  0.3998806
##   0.010  0.9717632  0.037997320  0.3797988
##   0.015  0.9778767  0.024587783  0.3805137
##   0.020  0.9788911  0.015408448  0.3820427
##   0.030  0.9630544  0.007326637  0.3812745
##   0.040  0.9555957          NaN  0.3832784
##   0.050  0.9555957          NaN  0.3832784
## 
## RMSE was used to select the optimal model using the smallest value.
## The final value used for the model was cp = 0.05.

# create the prediction
pred1 &lt;- predict(rpartFit, newdata = newsPopTest)

# compare the prediction vs the actual
resample1 &lt;- postResample(pred1, obs = newsPopTest$shares)
resample1

##      RMSE  Rsquared       MAE 
## 1.2930638        NA 0.4239443</code></pre>
<h3 id="boosted-tree-based-model">Boosted Tree Based Model</h3>
<p>A boosted tree is an ensemble method which slowly approaches the tree prediction which would result from the original data. In general, an ensemble model model will have a lower RSME than a single tree model.</p>
<pre><code>gbmFit &lt;- train(shares ~ timedelta + n_tokens_title + n_tokens_content + n_unique_tokens + n_non_stop_words + n_non_stop_unique_tokens
                 + num_hrefs + num_self_hrefs + num_imgs + num_videos + average_token_length + num_keywords + data_channel_is_lifestyle +
                 data_channel_is_entertainment + data_channel_is_bus + data_channel_is_socmed + data_channel_is_tech + data_channel_is_world +
                 self_reference_min_shares + self_reference_max_shares + self_reference_avg_sharess + global_subjectivity + global_sentiment_polarity
                 + global_rate_positive_words + global_rate_negative_words + rate_positive_words + rate_negative_words + avg_positive_polarity +
                  min_positive_polarity + max_positive_polarity + avg_negative_polarity + min_negative_polarity + max_negative_polarity + title_subjectivity
                 + title_sentiment_polarity + abs_title_subjectivity + abs_title_sentiment_polarity, data = newsPopTrain,
             method = &quot;gbm&quot;,
             trControl = trainControl(method = &quot;cv&quot;, number = 10))

## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        0.9955             nan     0.1000    0.0032
##      2        0.9932             nan     0.1000    0.0002
##      3        0.9906             nan     0.1000    0.0012
##      4        0.9879             nan     0.1000    0.0004
##      5        0.9848             nan     0.1000    0.0021
##      6        0.9835             nan     0.1000   -0.0004
##      7        0.9809             nan     0.1000    0.0015
##      8        0.9793             nan     0.1000    0.0009
##      9        0.9770             nan     0.1000    0.0007
##     10        0.9761             nan     0.1000   -0.0001
##     20        0.9646             nan     0.1000    0.0000
##     40        0.9506             nan     0.1000   -0.0004
##     60        0.9411             nan     0.1000   -0.0003
##     80        0.9357             nan     0.1000   -0.0007
##    100        0.9307             nan     0.1000   -0.0016
##    120        0.9241             nan     0.1000   -0.0004
##    140        0.9200             nan     0.1000   -0.0002
##    150        0.9173             nan     0.1000   -0.0012
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        0.9914             nan     0.1000    0.0023
##      2        0.9884             nan     0.1000    0.0012
##      3        0.9809             nan     0.1000   -0.0004
##      4        0.9742             nan     0.1000    0.0012
##      5        0.9664             nan     0.1000    0.0033
##      6        0.9599             nan     0.1000    0.0021
##      7        0.9576             nan     0.1000   -0.0002
##      8        0.9556             nan     0.1000    0.0004
##      9        0.9511             nan     0.1000    0.0004
##     10        0.9451             nan     0.1000   -0.0011
##     20        0.9148             nan     0.1000   -0.0006
##     40        0.8781             nan     0.1000   -0.0001
##     60        0.8540             nan     0.1000   -0.0004
##     80        0.8303             nan     0.1000   -0.0012
##    100        0.8165             nan     0.1000   -0.0012
##    120        0.8024             nan     0.1000   -0.0010
##    140        0.7841             nan     0.1000   -0.0007
##    150        0.7765             nan     0.1000   -0.0014
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        0.9820             nan     0.1000    0.0049
##      2        0.9711             nan     0.1000    0.0023
##      3        0.9677             nan     0.1000    0.0005
##      4        0.9604             nan     0.1000    0.0015
##      5        0.9555             nan     0.1000    0.0013
##      6        0.9498             nan     0.1000   -0.0020
##      7        0.9421             nan     0.1000   -0.0021
##      8        0.9329             nan     0.1000   -0.0004
##      9        0.9308             nan     0.1000   -0.0007
##     10        0.9254             nan     0.1000   -0.0016
##     20        0.8861             nan     0.1000   -0.0017
##     40        0.8185             nan     0.1000   -0.0010
##     60        0.7869             nan     0.1000   -0.0018
##     80        0.7641             nan     0.1000   -0.0020
##    100        0.7432             nan     0.1000   -0.0005
##    120        0.7221             nan     0.1000   -0.0013
##    140        0.7040             nan     0.1000   -0.0010
##    150        0.6934             nan     0.1000   -0.0025
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0051             nan     0.1000    0.0030
##      2        1.0020             nan     0.1000    0.0034
##      3        0.9995             nan     0.1000    0.0012
##      4        0.9964             nan     0.1000    0.0014
##      5        0.9937             nan     0.1000    0.0020
##      6        0.9922             nan     0.1000    0.0007
##      7        0.9904             nan     0.1000    0.0011
##      8        0.9890             nan     0.1000    0.0002
##      9        0.9872             nan     0.1000    0.0019
##     10        0.9847             nan     0.1000    0.0008
##     20        0.9730             nan     0.1000   -0.0000
##     40        0.9611             nan     0.1000    0.0001
##     60        0.9530             nan     0.1000   -0.0009
##     80        0.9460             nan     0.1000   -0.0004
##    100        0.9403             nan     0.1000   -0.0005
##    120        0.9368             nan     0.1000   -0.0006
##    140        0.9341             nan     0.1000   -0.0001
##    150        0.9334             nan     0.1000   -0.0001
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0011             nan     0.1000    0.0047
##      2        0.9936             nan     0.1000    0.0019
##      3        0.9910             nan     0.1000   -0.0013
##      4        0.9877             nan     0.1000    0.0024
##      5        0.9815             nan     0.1000   -0.0018
##      6        0.9719             nan     0.1000    0.0032
##      7        0.9640             nan     0.1000    0.0003
##      8        0.9580             nan     0.1000    0.0005
##      9        0.9499             nan     0.1000    0.0001
##     10        0.9472             nan     0.1000    0.0002
##     20        0.9184             nan     0.1000   -0.0002
##     40        0.8759             nan     0.1000   -0.0007
##     60        0.8539             nan     0.1000   -0.0008
##     80        0.8300             nan     0.1000   -0.0034
##    100        0.8132             nan     0.1000   -0.0000
##    120        0.7962             nan     0.1000   -0.0015
##    140        0.7799             nan     0.1000   -0.0007
##    150        0.7765             nan     0.1000   -0.0010
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        0.9971             nan     0.1000    0.0065
##      2        0.9858             nan     0.1000    0.0036
##      3        0.9723             nan     0.1000   -0.0015
##      4        0.9579             nan     0.1000    0.0040
##      5        0.9507             nan     0.1000   -0.0002
##      6        0.9441             nan     0.1000   -0.0015
##      7        0.9399             nan     0.1000    0.0010
##      8        0.9354             nan     0.1000   -0.0001
##      9        0.9297             nan     0.1000   -0.0013
##     10        0.9221             nan     0.1000   -0.0008
##     20        0.8925             nan     0.1000   -0.0005
##     40        0.8362             nan     0.1000   -0.0025
##     60        0.8052             nan     0.1000   -0.0014
##     80        0.7749             nan     0.1000    0.0001
##    100        0.7475             nan     0.1000    0.0000
##    120        0.7185             nan     0.1000   -0.0019
##    140        0.7006             nan     0.1000   -0.0024
##    150        0.6892             nan     0.1000   -0.0044
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0386             nan     0.1000    0.0040
##      2        1.0364             nan     0.1000    0.0001
##      3        1.0338             nan     0.1000    0.0021
##      4        1.0312             nan     0.1000    0.0026
##      5        1.0274             nan     0.1000    0.0017
##      6        1.0261             nan     0.1000   -0.0004
##      7        1.0237             nan     0.1000    0.0004
##      8        1.0213             nan     0.1000    0.0011
##      9        1.0199             nan     0.1000    0.0009
##     10        1.0181             nan     0.1000    0.0012
##     20        1.0035             nan     0.1000   -0.0007
##     40        0.9897             nan     0.1000   -0.0002
##     60        0.9803             nan     0.1000   -0.0004
##     80        0.9738             nan     0.1000   -0.0001
##    100        0.9687             nan     0.1000   -0.0002
##    120        0.9636             nan     0.1000   -0.0008
##    140        0.9588             nan     0.1000   -0.0011
##    150        0.9562             nan     0.1000   -0.0005
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0394             nan     0.1000    0.0014
##      2        1.0342             nan     0.1000    0.0029
##      3        1.0286             nan     0.1000    0.0004
##      4        1.0224             nan     0.1000   -0.0001
##      5        1.0095             nan     0.1000    0.0038
##      6        1.0065             nan     0.1000   -0.0016
##      7        1.0035             nan     0.1000   -0.0001
##      8        0.9960             nan     0.1000    0.0009
##      9        0.9919             nan     0.1000    0.0022
##     10        0.9900             nan     0.1000    0.0011
##     20        0.9597             nan     0.1000   -0.0021
##     40        0.9136             nan     0.1000   -0.0003
##     60        0.8897             nan     0.1000   -0.0000
##     80        0.8635             nan     0.1000    0.0002
##    100        0.8490             nan     0.1000   -0.0008
##    120        0.8265             nan     0.1000   -0.0022
##    140        0.8039             nan     0.1000   -0.0016
##    150        0.7920             nan     0.1000   -0.0021
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0243             nan     0.1000    0.0037
##      2        1.0203             nan     0.1000    0.0011
##      3        1.0061             nan     0.1000    0.0026
##      4        1.0002             nan     0.1000    0.0036
##      5        0.9974             nan     0.1000    0.0007
##      6        0.9928             nan     0.1000   -0.0006
##      7        0.9885             nan     0.1000    0.0003
##      8        0.9846             nan     0.1000    0.0025
##      9        0.9818             nan     0.1000    0.0011
##     10        0.9789             nan     0.1000   -0.0016
##     20        0.9341             nan     0.1000   -0.0010
##     40        0.8573             nan     0.1000   -0.0087
##     60        0.8129             nan     0.1000   -0.0031
##     80        0.7794             nan     0.1000   -0.0030
##    100        0.7579             nan     0.1000   -0.0019
##    120        0.7389             nan     0.1000   -0.0045
##    140        0.7215             nan     0.1000   -0.0006
##    150        0.7025             nan     0.1000   -0.0014
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        0.7467             nan     0.1000    0.0022
##      2        0.7451             nan     0.1000    0.0009
##      3        0.7429             nan     0.1000    0.0017
##      4        0.7412             nan     0.1000    0.0008
##      5        0.7390             nan     0.1000    0.0014
##      6        0.7371             nan     0.1000    0.0011
##      7        0.7356             nan     0.1000    0.0008
##      8        0.7343             nan     0.1000    0.0005
##      9        0.7325             nan     0.1000    0.0004
##     10        0.7310             nan     0.1000    0.0007
##     20        0.7225             nan     0.1000   -0.0004
##     40        0.7119             nan     0.1000   -0.0002
##     60        0.7053             nan     0.1000   -0.0004
##     80        0.7012             nan     0.1000   -0.0007
##    100        0.6965             nan     0.1000   -0.0002
##    120        0.6924             nan     0.1000   -0.0014
##    140        0.6886             nan     0.1000   -0.0006
##    150        0.6872             nan     0.1000   -0.0006
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        0.7453             nan     0.1000   -0.0001
##      2        0.7392             nan     0.1000    0.0020
##      3        0.7357             nan     0.1000    0.0017
##      4        0.7304             nan     0.1000    0.0009
##      5        0.7265             nan     0.1000    0.0032
##      6        0.7234             nan     0.1000    0.0021
##      7        0.7204             nan     0.1000    0.0007
##      8        0.7169             nan     0.1000    0.0015
##      9        0.7150             nan     0.1000    0.0005
##     10        0.7113             nan     0.1000    0.0001
##     20        0.6902             nan     0.1000   -0.0000
##     40        0.6667             nan     0.1000   -0.0002
##     60        0.6481             nan     0.1000   -0.0006
##     80        0.6325             nan     0.1000   -0.0007
##    100        0.6236             nan     0.1000   -0.0009
##    120        0.6132             nan     0.1000   -0.0010
##    140        0.6043             nan     0.1000    0.0000
##    150        0.6013             nan     0.1000   -0.0007
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        0.7445             nan     0.1000    0.0001
##      2        0.7410             nan     0.1000    0.0019
##      3        0.7385             nan     0.1000    0.0006
##      4        0.7349             nan     0.1000    0.0008
##      5        0.7291             nan     0.1000    0.0015
##      6        0.7257             nan     0.1000    0.0005
##      7        0.7218             nan     0.1000    0.0004
##      8        0.7164             nan     0.1000    0.0007
##      9        0.7123             nan     0.1000    0.0003
##     10        0.7061             nan     0.1000   -0.0016
##     20        0.6761             nan     0.1000   -0.0008
##     40        0.6400             nan     0.1000   -0.0014
##     60        0.6128             nan     0.1000   -0.0010
##     80        0.5964             nan     0.1000   -0.0009
##    100        0.5788             nan     0.1000   -0.0009
##    120        0.5664             nan     0.1000   -0.0008
##    140        0.5545             nan     0.1000   -0.0010
##    150        0.5495             nan     0.1000   -0.0007
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0727             nan     0.1000    0.0018
##      2        1.0679             nan     0.1000    0.0036
##      3        1.0644             nan     0.1000    0.0029
##      4        1.0616             nan     0.1000    0.0024
##      5        1.0603             nan     0.1000    0.0007
##      6        1.0570             nan     0.1000    0.0010
##      7        1.0549             nan     0.1000   -0.0008
##      8        1.0529             nan     0.1000    0.0002
##      9        1.0514             nan     0.1000   -0.0007
##     10        1.0504             nan     0.1000   -0.0001
##     20        1.0375             nan     0.1000   -0.0009
##     40        1.0232             nan     0.1000   -0.0008
##     60        1.0143             nan     0.1000   -0.0007
##     80        1.0069             nan     0.1000   -0.0005
##    100        1.0007             nan     0.1000   -0.0002
##    120        0.9964             nan     0.1000    0.0007
##    140        0.9925             nan     0.1000    0.0005
##    150        0.9903             nan     0.1000   -0.0008
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0635             nan     0.1000    0.0094
##      2        1.0536             nan     0.1000    0.0026
##      3        1.0472             nan     0.1000   -0.0011
##      4        1.0417             nan     0.1000    0.0022
##      5        1.0400             nan     0.1000    0.0002
##      6        1.0350             nan     0.1000    0.0005
##      7        1.0313             nan     0.1000    0.0004
##      8        1.0285             nan     0.1000    0.0008
##      9        1.0246             nan     0.1000    0.0007
##     10        1.0220             nan     0.1000   -0.0002
##     20        0.9834             nan     0.1000    0.0004
##     40        0.9372             nan     0.1000   -0.0001
##     60        0.9144             nan     0.1000   -0.0013
##     80        0.8930             nan     0.1000   -0.0004
##    100        0.8682             nan     0.1000   -0.0006
##    120        0.8443             nan     0.1000   -0.0007
##    140        0.8263             nan     0.1000   -0.0005
##    150        0.8202             nan     0.1000   -0.0031
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0668             nan     0.1000    0.0065
##      2        1.0521             nan     0.1000    0.0029
##      3        1.0352             nan     0.1000    0.0005
##      4        1.0315             nan     0.1000    0.0022
##      5        1.0269             nan     0.1000    0.0007
##      6        1.0189             nan     0.1000    0.0028
##      7        0.9999             nan     0.1000   -0.0000
##      8        0.9948             nan     0.1000   -0.0011
##      9        0.9860             nan     0.1000    0.0007
##     10        0.9793             nan     0.1000   -0.0017
##     20        0.9335             nan     0.1000   -0.0002
##     40        0.8747             nan     0.1000   -0.0021
##     60        0.8413             nan     0.1000   -0.0028
##     80        0.8114             nan     0.1000   -0.0011
##    100        0.7891             nan     0.1000   -0.0018
##    120        0.7675             nan     0.1000   -0.0005
##    140        0.7472             nan     0.1000   -0.0011
##    150        0.7283             nan     0.1000   -0.0012
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0263             nan     0.1000    0.0039
##      2        1.0241             nan     0.1000   -0.0003
##      3        1.0220             nan     0.1000    0.0010
##      4        1.0207             nan     0.1000   -0.0001
##      5        1.0187             nan     0.1000    0.0023
##      6        1.0159             nan     0.1000    0.0008
##      7        1.0133             nan     0.1000    0.0012
##      8        1.0103             nan     0.1000    0.0021
##      9        1.0081             nan     0.1000    0.0006
##     10        1.0069             nan     0.1000   -0.0011
##     20        0.9913             nan     0.1000    0.0003
##     40        0.9774             nan     0.1000   -0.0016
##     60        0.9692             nan     0.1000   -0.0007
##     80        0.9632             nan     0.1000   -0.0003
##    100        0.9593             nan     0.1000   -0.0006
##    120        0.9534             nan     0.1000    0.0006
##    140        0.9501             nan     0.1000   -0.0007
##    150        0.9482             nan     0.1000   -0.0003
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0227             nan     0.1000    0.0030
##      2        1.0109             nan     0.1000    0.0061
##      3        1.0094             nan     0.1000   -0.0003
##      4        1.0018             nan     0.1000   -0.0010
##      5        0.9961             nan     0.1000   -0.0022
##      6        0.9911             nan     0.1000    0.0004
##      7        0.9832             nan     0.1000   -0.0010
##      8        0.9765             nan     0.1000   -0.0006
##      9        0.9699             nan     0.1000    0.0032
##     10        0.9668             nan     0.1000    0.0016
##     20        0.9276             nan     0.1000   -0.0006
##     40        0.8912             nan     0.1000   -0.0007
##     60        0.8578             nan     0.1000    0.0001
##     80        0.8276             nan     0.1000   -0.0004
##    100        0.8151             nan     0.1000   -0.0010
##    120        0.8000             nan     0.1000   -0.0012
##    140        0.7874             nan     0.1000   -0.0008
##    150        0.7824             nan     0.1000   -0.0007
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0048             nan     0.1000    0.0011
##      2        0.9966             nan     0.1000    0.0016
##      3        0.9903             nan     0.1000    0.0039
##      4        0.9815             nan     0.1000    0.0000
##      5        0.9766             nan     0.1000   -0.0008
##      6        0.9683             nan     0.1000    0.0037
##      7        0.9627             nan     0.1000   -0.0015
##      8        0.9559             nan     0.1000    0.0004
##      9        0.9514             nan     0.1000    0.0016
##     10        0.9432             nan     0.1000   -0.0017
##     20        0.8945             nan     0.1000   -0.0035
##     40        0.8348             nan     0.1000    0.0002
##     60        0.7879             nan     0.1000   -0.0028
##     80        0.7595             nan     0.1000   -0.0025
##    100        0.7374             nan     0.1000   -0.0005
##    120        0.7179             nan     0.1000   -0.0024
##    140        0.6981             nan     0.1000   -0.0021
##    150        0.6802             nan     0.1000   -0.0018
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0125             nan     0.1000    0.0033
##      2        1.0094             nan     0.1000    0.0024
##      3        1.0077             nan     0.1000    0.0007
##      4        1.0056             nan     0.1000    0.0012
##      5        1.0039             nan     0.1000   -0.0000
##      6        1.0018             nan     0.1000   -0.0005
##      7        0.9995             nan     0.1000    0.0015
##      8        0.9982             nan     0.1000   -0.0004
##      9        0.9961             nan     0.1000    0.0016
##     10        0.9951             nan     0.1000   -0.0000
##     20        0.9851             nan     0.1000   -0.0004
##     40        0.9693             nan     0.1000    0.0006
##     60        0.9612             nan     0.1000   -0.0001
##     80        0.9543             nan     0.1000   -0.0019
##    100        0.9482             nan     0.1000   -0.0006
##    120        0.9418             nan     0.1000   -0.0012
##    140        0.9365             nan     0.1000   -0.0013
##    150        0.9355             nan     0.1000   -0.0007
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0050             nan     0.1000    0.0018
##      2        0.9972             nan     0.1000    0.0024
##      3        0.9945             nan     0.1000    0.0011
##      4        0.9925             nan     0.1000   -0.0007
##      5        0.9886             nan     0.1000    0.0022
##      6        0.9858             nan     0.1000    0.0016
##      7        0.9802             nan     0.1000   -0.0005
##      8        0.9774             nan     0.1000    0.0007
##      9        0.9751             nan     0.1000    0.0011
##     10        0.9703             nan     0.1000    0.0000
##     20        0.9397             nan     0.1000   -0.0002
##     40        0.8911             nan     0.1000   -0.0002
##     60        0.8574             nan     0.1000   -0.0066
##     80        0.8383             nan     0.1000   -0.0006
##    100        0.8213             nan     0.1000    0.0002
##    120        0.8033             nan     0.1000   -0.0008
##    140        0.7906             nan     0.1000   -0.0015
##    150        0.7807             nan     0.1000   -0.0005
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0090             nan     0.1000    0.0049
##      2        0.9988             nan     0.1000    0.0006
##      3        0.9957             nan     0.1000    0.0003
##      4        0.9866             nan     0.1000    0.0011
##      5        0.9698             nan     0.1000    0.0011
##      6        0.9674             nan     0.1000    0.0011
##      7        0.9602             nan     0.1000    0.0001
##      8        0.9553             nan     0.1000   -0.0006
##      9        0.9469             nan     0.1000    0.0006
##     10        0.9393             nan     0.1000   -0.0022
##     20        0.8970             nan     0.1000    0.0016
##     40        0.8388             nan     0.1000   -0.0029
##     60        0.7917             nan     0.1000   -0.0007
##     80        0.7638             nan     0.1000   -0.0014
##    100        0.7397             nan     0.1000   -0.0036
##    120        0.7173             nan     0.1000   -0.0012
##    140        0.6983             nan     0.1000   -0.0012
##    150        0.6863             nan     0.1000   -0.0007
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0145             nan     0.1000    0.0028
##      2        1.0114             nan     0.1000    0.0026
##      3        1.0096             nan     0.1000    0.0003
##      4        1.0073             nan     0.1000    0.0004
##      5        1.0047             nan     0.1000    0.0024
##      6        1.0019             nan     0.1000    0.0010
##      7        1.0002             nan     0.1000    0.0017
##      8        0.9983             nan     0.1000    0.0006
##      9        0.9975             nan     0.1000   -0.0003
##     10        0.9959             nan     0.1000   -0.0008
##     20        0.9829             nan     0.1000   -0.0002
##     40        0.9700             nan     0.1000   -0.0010
##     60        0.9617             nan     0.1000   -0.0008
##     80        0.9558             nan     0.1000   -0.0004
##    100        0.9500             nan     0.1000   -0.0002
##    120        0.9467             nan     0.1000   -0.0012
##    140        0.9419             nan     0.1000   -0.0013
##    150        0.9407             nan     0.1000   -0.0011
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0100             nan     0.1000   -0.0014
##      2        1.0059             nan     0.1000    0.0025
##      3        0.9988             nan     0.1000    0.0014
##      4        0.9880             nan     0.1000    0.0044
##      5        0.9830             nan     0.1000    0.0005
##      6        0.9790             nan     0.1000   -0.0011
##      7        0.9731             nan     0.1000   -0.0006
##      8        0.9696             nan     0.1000    0.0007
##      9        0.9650             nan     0.1000   -0.0040
##     10        0.9622             nan     0.1000   -0.0008
##     20        0.9299             nan     0.1000    0.0002
##     40        0.8924             nan     0.1000   -0.0011
##     60        0.8600             nan     0.1000   -0.0008
##     80        0.8294             nan     0.1000   -0.0023
##    100        0.8111             nan     0.1000   -0.0029
##    120        0.7916             nan     0.1000   -0.0007
##    140        0.7802             nan     0.1000   -0.0005
##    150        0.7727             nan     0.1000   -0.0012
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0014             nan     0.1000    0.0017
##      2        0.9782             nan     0.1000    0.0004
##      3        0.9728             nan     0.1000    0.0023
##      4        0.9585             nan     0.1000   -0.0020
##      5        0.9549             nan     0.1000    0.0014
##      6        0.9527             nan     0.1000   -0.0002
##      7        0.9450             nan     0.1000    0.0006
##      8        0.9401             nan     0.1000   -0.0008
##      9        0.9346             nan     0.1000   -0.0024
##     10        0.9319             nan     0.1000   -0.0005
##     20        0.8845             nan     0.1000   -0.0014
##     40        0.8301             nan     0.1000    0.0001
##     60        0.7918             nan     0.1000   -0.0008
##     80        0.7565             nan     0.1000   -0.0046
##    100        0.7274             nan     0.1000   -0.0025
##    120        0.7072             nan     0.1000   -0.0019
##    140        0.6792             nan     0.1000   -0.0009
##    150        0.6630             nan     0.1000   -0.0008
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0111             nan     0.1000    0.0024
##      2        1.0086             nan     0.1000   -0.0004
##      3        1.0064             nan     0.1000    0.0006
##      4        1.0029             nan     0.1000    0.0023
##      5        1.0006             nan     0.1000    0.0013
##      6        0.9990             nan     0.1000    0.0003
##      7        0.9973             nan     0.1000    0.0013
##      8        0.9955             nan     0.1000   -0.0006
##      9        0.9941             nan     0.1000    0.0011
##     10        0.9922             nan     0.1000    0.0002
##     20        0.9814             nan     0.1000   -0.0007
##     40        0.9691             nan     0.1000   -0.0005
##     60        0.9607             nan     0.1000   -0.0015
##     80        0.9558             nan     0.1000   -0.0008
##    100        0.9496             nan     0.1000   -0.0011
##    120        0.9443             nan     0.1000   -0.0014
##    140        0.9408             nan     0.1000   -0.0012
##    150        0.9374             nan     0.1000   -0.0014
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0035             nan     0.1000    0.0019
##      2        0.9958             nan     0.1000   -0.0012
##      3        0.9902             nan     0.1000   -0.0029
##      4        0.9836             nan     0.1000    0.0033
##      5        0.9751             nan     0.1000    0.0053
##      6        0.9674             nan     0.1000   -0.0015
##      7        0.9608             nan     0.1000   -0.0007
##      8        0.9567             nan     0.1000   -0.0003
##      9        0.9531             nan     0.1000   -0.0010
##     10        0.9504             nan     0.1000    0.0011
##     20        0.9181             nan     0.1000    0.0016
##     40        0.8746             nan     0.1000   -0.0018
##     60        0.8446             nan     0.1000   -0.0024
##     80        0.8239             nan     0.1000   -0.0030
##    100        0.8079             nan     0.1000   -0.0011
##    120        0.7883             nan     0.1000   -0.0001
##    140        0.7711             nan     0.1000   -0.0010
##    150        0.7652             nan     0.1000   -0.0007
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0032             nan     0.1000    0.0093
##      2        0.9912             nan     0.1000    0.0043
##      3        0.9796             nan     0.1000    0.0059
##      4        0.9713             nan     0.1000    0.0003
##      5        0.9674             nan     0.1000    0.0006
##      6        0.9609             nan     0.1000    0.0021
##      7        0.9515             nan     0.1000    0.0007
##      8        0.9481             nan     0.1000    0.0005
##      9        0.9421             nan     0.1000   -0.0001
##     10        0.9380             nan     0.1000   -0.0026
##     20        0.8888             nan     0.1000   -0.0012
##     40        0.8346             nan     0.1000   -0.0019
##     60        0.8023             nan     0.1000   -0.0014
##     80        0.7689             nan     0.1000   -0.0013
##    100        0.7505             nan     0.1000   -0.0008
##    120        0.7209             nan     0.1000   -0.0027
##    140        0.6985             nan     0.1000   -0.0005
##    150        0.6898             nan     0.1000   -0.0027
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0400             nan     0.1000   -0.0007
##      2        1.0379             nan     0.1000    0.0011
##      3        1.0356             nan     0.1000    0.0026
##      4        1.0343             nan     0.1000    0.0001
##      5        1.0317             nan     0.1000    0.0028
##      6        1.0298             nan     0.1000    0.0001
##      7        1.0281             nan     0.1000    0.0007
##      8        1.0258             nan     0.1000    0.0025
##      9        1.0236             nan     0.1000    0.0012
##     10        1.0221             nan     0.1000    0.0000
##     20        1.0114             nan     0.1000   -0.0000
##     40        0.9971             nan     0.1000   -0.0006
##     60        0.9883             nan     0.1000   -0.0011
##     80        0.9806             nan     0.1000   -0.0009
##    100        0.9767             nan     0.1000   -0.0012
##    120        0.9713             nan     0.1000   -0.0015
##    140        0.9679             nan     0.1000   -0.0002
##    150        0.9656             nan     0.1000   -0.0009
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0373             nan     0.1000    0.0033
##      2        1.0334             nan     0.1000    0.0032
##      3        1.0264             nan     0.1000    0.0016
##      4        1.0238             nan     0.1000    0.0014
##      5        1.0188             nan     0.1000   -0.0020
##      6        1.0101             nan     0.1000    0.0032
##      7        1.0064             nan     0.1000    0.0005
##      8        1.0028             nan     0.1000   -0.0003
##      9        1.0001             nan     0.1000   -0.0008
##     10        0.9970             nan     0.1000   -0.0019
##     20        0.9695             nan     0.1000   -0.0002
##     40        0.9116             nan     0.1000   -0.0016
##     60        0.8891             nan     0.1000   -0.0011
##     80        0.8661             nan     0.1000   -0.0013
##    100        0.8480             nan     0.1000   -0.0011
##    120        0.8299             nan     0.1000   -0.0011
##    140        0.8196             nan     0.1000   -0.0021
##    150        0.8123             nan     0.1000   -0.0021
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0254             nan     0.1000    0.0023
##      2        1.0196             nan     0.1000    0.0019
##      3        1.0134             nan     0.1000   -0.0008
##      4        1.0004             nan     0.1000    0.0021
##      5        0.9915             nan     0.1000    0.0086
##      6        0.9834             nan     0.1000   -0.0013
##      7        0.9784             nan     0.1000    0.0008
##      8        0.9711             nan     0.1000   -0.0004
##      9        0.9667             nan     0.1000   -0.0010
##     10        0.9560             nan     0.1000   -0.0012
##     20        0.9206             nan     0.1000   -0.0005
##     40        0.8673             nan     0.1000   -0.0009
##     60        0.8315             nan     0.1000    0.0002
##     80        0.7957             nan     0.1000   -0.0011
##    100        0.7678             nan     0.1000   -0.0014
##    120        0.7386             nan     0.1000   -0.0025
##    140        0.7151             nan     0.1000   -0.0005
##    150        0.7059             nan     0.1000   -0.0056
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        0.9962             nan     0.1000    0.0036
##      2        0.9926             nan     0.1000    0.0027
##      3        0.9895             nan     0.1000    0.0016
##      4        0.9870             nan     0.1000    0.0021
##      5        0.9851             nan     0.1000   -0.0006
##      6        0.9842             nan     0.1000   -0.0002
##      7        0.9822             nan     0.1000    0.0003
##      8        0.9800             nan     0.1000    0.0012
##      9        0.9785             nan     0.1000    0.0001
##     10        0.9775             nan     0.1000   -0.0001
##     20        0.9662             nan     0.1000   -0.0001
##     40        0.9541             nan     0.1000   -0.0007
##     50        0.9510             nan     0.1000   -0.0001

gbmFit

## Stochastic Gradient Boosting 
## 
## 3993 samples
##   37 predictor
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 3594, 3592, 3594, 3594, 3594, 3594, ... 
## Resampling results across tuning parameters:
## 
##   interaction.depth  n.trees  RMSE       Rsquared    MAE      
##   1                   50      0.9422440  0.02894667  0.3732887
##   1                  100      0.9440748  0.02901458  0.3761952
##   1                  150      0.9464386  0.02618560  0.3769530
##   2                   50      0.9529047  0.02472347  0.3796524
##   2                  100      0.9591986  0.02444009  0.3814391
##   2                  150      0.9666739  0.02260110  0.3864796
##   3                   50      0.9521291  0.02982720  0.3774578
##   3                  100      0.9618167  0.02823872  0.3836890
##   3                  150      0.9729944  0.02453754  0.3922108
## 
## Tuning parameter &#39;shrinkage&#39; was held constant at a value of 0.1
## Tuning parameter &#39;n.minobsinnode&#39; was held constant at a value
##  of 10
## RMSE was used to select the optimal model using the smallest value.
## The final values used for the model were n.trees = 50, interaction.depth = 1, shrinkage = 0.1 and n.minobsinnode = 10.

# create the prediction
pred2 &lt;- predict(gbmFit, newdata = newsPopTest)

# compare the prediction vs the actual
resample2 &lt;- postResample(pred2, obs = newsPopTest$shares)
resample2

##       RMSE   Rsquared        MAE 
## 1.28060459 0.01948384 0.41571273</code></pre>
<h3 id="linear-regression-model">Linear Regression Model</h3>
<p>Linear regression is used to predict the outcome of a response variable for 1 to n predictors. The aim is to establish a linear relationship between the predictor variable(s) and response variable so we can predict the value of the response when only the predictor variable(s) is(are) known.</p>
<pre><code># train the linear model for main effects + interactions on first 3 preds
lmFit &lt;- train(shares ~ timedelta*n_tokens_title*n_tokens_content, data = newsPopTrain,
                                                                   method = &quot;lm&quot;, preProces = c(&quot;center&quot;, &quot;scale&quot;),
                                                                   trControl = trainControl(method = &quot;cv&quot;, number = 10))
lmFit

## Linear Regression 
## 
## 3993 samples
##    3 predictor
## 
## Pre-processing: centered (7), scaled (7) 
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 3593, 3593, 3593, 3595, 3594, 3593, ... 
## Resampling results:
## 
##   RMSE       Rsquared     MAE     
##   0.9710555  0.002483647  0.383183
## 
## Tuning parameter &#39;intercept&#39; was held constant at a value of TRUE

# create the prediction
pred3 &lt;- predict(lmFit, newdata = newsPopTest)

# compare the prediction vs the actual
resample3 &lt;- postResample(pred3, obs = newsPopTest$shares)
resample3

##        RMSE    Rsquared         MAE 
## 1.291410247 0.002670282 0.424692144</code></pre>
<h3 id="comparison">Comparison</h3>
<p>Below is a comparison of the 3 methods. All have relatively high root mean square errors.</p>
<pre><code>comparison &lt;- data.frame(&quot;RSME&quot; = c(resample1[[1]], resample2[[1]], resample3[1]), &quot;MAE&quot; = c(resample1[[3]], resample2[[3]], resample3[[3]]))
rownames(comparison) &lt;- c(&quot;RPART&quot;,&quot;GBM&quot;, &quot;LM&quot;)
kable(comparison)</code></pre>
<table>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
RSME
</th>
<th style="text-align:right;">
MAE
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
RPART
</td>
<td style="text-align:right;">
1.293064
</td>
<td style="text-align:right;">
0.4239443
</td>
</tr>
<tr>
<td style="text-align:left;">
GBM
</td>
<td style="text-align:right;">
1.280605
</td>
<td style="text-align:right;">
0.4157127
</td>
</tr>
<tr>
<td style="text-align:left;">
LM
</td>
<td style="text-align:right;">
1.291410
</td>
<td style="text-align:right;">
0.4246921
</td>
</tr>
</tbody>
</table>

</body>
</html>
