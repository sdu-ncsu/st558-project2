<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1">

<style type="text/css">
@font-face {
font-family: octicons-link;
src: url(data:font/woff;charset=utf-8;base64,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) format('woff');
}
body {
-webkit-text-size-adjust: 100%;
text-size-adjust: 100%;
color: #333;
font-family: "Helvetica Neue", Helvetica, "Segoe UI", Arial, freesans, sans-serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol";
font-size: 16px;
line-height: 1.6;
word-wrap: break-word;
}
a {
background-color: transparent;
}
a:active,
a:hover {
outline: 0;
}
strong {
font-weight: bold;
}
h1 {
font-size: 2em;
margin: 0.67em 0;
}
img {
border: 0;
}
hr {
box-sizing: content-box;
height: 0;
}
pre {
overflow: auto;
}
code,
kbd,
pre {
font-family: monospace, monospace;
font-size: 1em;
}
input {
color: inherit;
font: inherit;
margin: 0;
}
html input[disabled] {
cursor: default;
}
input {
line-height: normal;
}
input[type="checkbox"] {
box-sizing: border-box;
padding: 0;
}
table {
border-collapse: collapse;
border-spacing: 0;
}
td,
th {
padding: 0;
}
* {
box-sizing: border-box;
}
input {
font: 13px / 1.4 Helvetica, arial, nimbussansl, liberationsans, freesans, clean, sans-serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol";
}
a {
color: #4078c0;
text-decoration: none;
}
a:hover,
a:active {
text-decoration: underline;
}
hr {
height: 0;
margin: 15px 0;
overflow: hidden;
background: transparent;
border: 0;
border-bottom: 1px solid #ddd;
}
hr:before {
display: table;
content: "";
}
hr:after {
display: table;
clear: both;
content: "";
}
h1,
h2,
h3,
h4,
h5,
h6 {
margin-top: 15px;
margin-bottom: 15px;
line-height: 1.1;
}
h1 {
font-size: 30px;
}
h2 {
font-size: 21px;
}
h3 {
font-size: 16px;
}
h4 {
font-size: 14px;
}
h5 {
font-size: 12px;
}
h6 {
font-size: 11px;
}
blockquote {
margin: 0;
}
ul,
ol {
padding: 0;
margin-top: 0;
margin-bottom: 0;
}
ol ol,
ul ol {
list-style-type: lower-roman;
}
ul ul ol,
ul ol ol,
ol ul ol,
ol ol ol {
list-style-type: lower-alpha;
}
dd {
margin-left: 0;
}
code {
font-family: Consolas, "Liberation Mono", Menlo, Courier, monospace;
font-size: 12px;
}
pre {
margin-top: 0;
margin-bottom: 0;
font: 12px Consolas, "Liberation Mono", Menlo, Courier, monospace;
}
.select::-ms-expand {
opacity: 0;
}
.octicon {
font: normal normal normal 16px/1 octicons-link;
display: inline-block;
text-decoration: none;
text-rendering: auto;
-webkit-font-smoothing: antialiased;
-moz-osx-font-smoothing: grayscale;
-webkit-user-select: none;
-moz-user-select: none;
-ms-user-select: none;
user-select: none;
}
.octicon-link:before {
content: '\f05c';
}
.markdown-body:before {
display: table;
content: "";
}
.markdown-body:after {
display: table;
clear: both;
content: "";
}
.markdown-body>*:first-child {
margin-top: 0 !important;
}
.markdown-body>*:last-child {
margin-bottom: 0 !important;
}
a:not([href]) {
color: inherit;
text-decoration: none;
}
.anchor {
display: inline-block;
padding-right: 2px;
margin-left: -18px;
}
.anchor:focus {
outline: none;
}
h1,
h2,
h3,
h4,
h5,
h6 {
margin-top: 1em;
margin-bottom: 16px;
font-weight: bold;
line-height: 1.4;
}
h1 .octicon-link,
h2 .octicon-link,
h3 .octicon-link,
h4 .octicon-link,
h5 .octicon-link,
h6 .octicon-link {
color: #000;
vertical-align: middle;
visibility: hidden;
}
h1:hover .anchor,
h2:hover .anchor,
h3:hover .anchor,
h4:hover .anchor,
h5:hover .anchor,
h6:hover .anchor {
text-decoration: none;
}
h1:hover .anchor .octicon-link,
h2:hover .anchor .octicon-link,
h3:hover .anchor .octicon-link,
h4:hover .anchor .octicon-link,
h5:hover .anchor .octicon-link,
h6:hover .anchor .octicon-link {
visibility: visible;
}
h1 {
padding-bottom: 0.3em;
font-size: 2.25em;
line-height: 1.2;
border-bottom: 1px solid #eee;
}
h1 .anchor {
line-height: 1;
}
h2 {
padding-bottom: 0.3em;
font-size: 1.75em;
line-height: 1.225;
border-bottom: 1px solid #eee;
}
h2 .anchor {
line-height: 1;
}
h3 {
font-size: 1.5em;
line-height: 1.43;
}
h3 .anchor {
line-height: 1.2;
}
h4 {
font-size: 1.25em;
}
h4 .anchor {
line-height: 1.2;
}
h5 {
font-size: 1em;
}
h5 .anchor {
line-height: 1.1;
}
h6 {
font-size: 1em;
color: #777;
}
h6 .anchor {
line-height: 1.1;
}
p,
blockquote,
ul,
ol,
dl,
table,
pre {
margin-top: 0;
margin-bottom: 16px;
}
hr {
height: 4px;
padding: 0;
margin: 16px 0;
background-color: #e7e7e7;
border: 0 none;
}
ul,
ol {
padding-left: 2em;
}
ul ul,
ul ol,
ol ol,
ol ul {
margin-top: 0;
margin-bottom: 0;
}
li>p {
margin-top: 16px;
}
dl {
padding: 0;
}
dl dt {
padding: 0;
margin-top: 16px;
font-size: 1em;
font-style: italic;
font-weight: bold;
}
dl dd {
padding: 0 16px;
margin-bottom: 16px;
}
blockquote {
padding: 0 15px;
color: #777;
border-left: 4px solid #ddd;
}
blockquote>:first-child {
margin-top: 0;
}
blockquote>:last-child {
margin-bottom: 0;
}
table {
display: block;
width: 100%;
overflow: auto;
word-break: normal;
word-break: keep-all;
}
table th {
font-weight: bold;
}
table th,
table td {
padding: 6px 13px;
border: 1px solid #ddd;
}
table tr {
background-color: #fff;
border-top: 1px solid #ccc;
}
table tr:nth-child(2n) {
background-color: #f8f8f8;
}
img {
max-width: 100%;
box-sizing: content-box;
background-color: #fff;
}
code {
padding: 0;
padding-top: 0.2em;
padding-bottom: 0.2em;
margin: 0;
font-size: 85%;
background-color: rgba(0,0,0,0.04);
border-radius: 3px;
}
code:before,
code:after {
letter-spacing: -0.2em;
content: "\00a0";
}
pre>code {
padding: 0;
margin: 0;
font-size: 100%;
word-break: normal;
white-space: pre;
background: transparent;
border: 0;
}
.highlight {
margin-bottom: 16px;
}
.highlight pre,
pre {
padding: 16px;
overflow: auto;
font-size: 85%;
line-height: 1.45;
background-color: #f7f7f7;
border-radius: 3px;
}
.highlight pre {
margin-bottom: 0;
word-break: normal;
}
pre {
word-wrap: normal;
}
pre code {
display: inline;
max-width: initial;
padding: 0;
margin: 0;
overflow: initial;
line-height: inherit;
word-wrap: normal;
background-color: transparent;
border: 0;
}
pre code:before,
pre code:after {
content: normal;
}
kbd {
display: inline-block;
padding: 3px 5px;
font-size: 11px;
line-height: 10px;
color: #555;
vertical-align: middle;
background-color: #fcfcfc;
border: solid 1px #ccc;
border-bottom-color: #bbb;
border-radius: 3px;
box-shadow: inset 0 -1px 0 #bbb;
}
.pl-c {
color: #969896;
}
.pl-c1,
.pl-s .pl-v {
color: #0086b3;
}
.pl-e,
.pl-en {
color: #795da3;
}
.pl-s .pl-s1,
.pl-smi {
color: #333;
}
.pl-ent {
color: #63a35c;
}
.pl-k {
color: #a71d5d;
}
.pl-pds,
.pl-s,
.pl-s .pl-pse .pl-s1,
.pl-sr,
.pl-sr .pl-cce,
.pl-sr .pl-sra,
.pl-sr .pl-sre {
color: #183691;
}
.pl-v {
color: #ed6a43;
}
.pl-id {
color: #b52a1d;
}
.pl-ii {
background-color: #b52a1d;
color: #f8f8f8;
}
.pl-sr .pl-cce {
color: #63a35c;
font-weight: bold;
}
.pl-ml {
color: #693a17;
}
.pl-mh,
.pl-mh .pl-en,
.pl-ms {
color: #1d3e81;
font-weight: bold;
}
.pl-mq {
color: #008080;
}
.pl-mi {
color: #333;
font-style: italic;
}
.pl-mb {
color: #333;
font-weight: bold;
}
.pl-md {
background-color: #ffecec;
color: #bd2c00;
}
.pl-mi1 {
background-color: #eaffea;
color: #55a532;
}
.pl-mdr {
color: #795da3;
font-weight: bold;
}
.pl-mo {
color: #1d3e81;
}
kbd {
display: inline-block;
padding: 3px 5px;
font: 11px Consolas, "Liberation Mono", Menlo, Courier, monospace;
line-height: 10px;
color: #555;
vertical-align: middle;
background-color: #fcfcfc;
border: solid 1px #ccc;
border-bottom-color: #bbb;
border-radius: 3px;
box-shadow: inset 0 -1px 0 #bbb;
}
.task-list-item {
list-style-type: none;
}
.task-list-item+.task-list-item {
margin-top: 3px;
}
.task-list-item input {
margin: 0 0.35em 0.25em -1.6em;
vertical-align: middle;
}
:checked+.radio-label {
z-index: 1;
position: relative;
border-color: #4078c0;
}
.sourceLine {
display: inline-block;
}
code .kw { color: #000000; }
code .dt { color: #ed6a43; }
code .dv { color: #009999; }
code .bn { color: #009999; }
code .fl { color: #009999; }
code .ch { color: #009999; }
code .st { color: #183691; }
code .co { color: #969896; }
code .ot { color: #0086b3; }
code .al { color: #a61717; }
code .fu { color: #63a35c; }
code .er { color: #a61717; background-color: #e3d2d2; }
code .wa { color: #000000; }
code .cn { color: #008080; }
code .sc { color: #008080; }
code .vs { color: #183691; }
code .ss { color: #183691; }
code .im { color: #000000; }
code .va {color: #008080; }
code .cf { color: #000000; }
code .op { color: #000000; }
code .bu { color: #000000; }
code .ex { color: #000000; }
code .pp { color: #999999; }
code .at { color: #008080; }
code .do { color: #969896; }
code .an { color: #008080; }
code .cv { color: #008080; }
code .in { color: #008080; }
</style>
<style>
body {
  box-sizing: border-box;
  min-width: 200px;
  max-width: 980px;
  margin: 0 auto;
  padding: 45px;
  padding-top: 0px;
}
</style>

</head>

<body>

<h1 id="news-popularity-monday-data">News Popularity Monday Data</h1>
<p>Shuang Du 10/16/2020</p>
<h2 id="load-libraries">Load Libraries</h2>
<pre><code>library(readxl);
library(tidyverse);
library(caret);
library(modelr);
library(rpart);
library(kableExtra);</code></pre>
<h2 id="read-in-data">Read in Data</h2>
<pre><code>getData &lt;- function(day) {

  newsPopData &lt;- read_csv(&quot;raw_data/OnlineNewsPopularity.csv&quot;)
  
  if (day == &#39;monday&#39;) {
    newsPopData &lt;- newsPopData %&gt;% filter(weekday_is_monday == 1)
  } else if(day == &#39;tuesday&#39;) {
    newsPopData &lt;- newsPopData %&gt;% filter(weekday_is_tuesday == 1)
  } else if(day == &#39;wednesday&#39;) {
    newsPopData &lt;- newsPopData %&gt;% filter(weekday_is_wednesday == 1)
  } else if(day == &#39;thursday&#39;) {
    newsPopData &lt;- newsPopData %&gt;% filter(weekday_is_thursday == 1)
  } else if(day == &#39;friday&#39;) {
    newsPopData &lt;- newsPopData %&gt;% filter(weekday_is_friday == 1)
  } else if(day == &#39;saturday&#39;) {
    newsPopData &lt;- newsPopData %&gt;% filter(weekday_is_saturday == 1)
  } else if(day == &#39;sunday&#39;) {
    newsPopData &lt;- newsPopData %&gt;% filter(weekday_is_sunday == 1)
  } else {
    stop(&quot;Invalid date&quot;)
  }
  return(newsPopData)
}

newsPopData &lt;- getData(params$day)</code></pre>
<h2 id="set-aside-training-data">Set Aside Training Data</h2>
<pre><code>set.seed(92)
trainIndex &lt;- createDataPartition(newsPopData$shares, 
                                  p = 0.7, list = FALSE)

newsPopTrain &lt;- newsPopData[as.vector(trainIndex),];
newsPopTest &lt;- newsPopData[-as.vector(trainIndex),];</code></pre>
<h2 id="center-and-scale">Center and Scale</h2>
<pre><code>preProcValues &lt;- preProcess(newsPopTrain, method = c(&quot;center&quot;, &quot;scale&quot;))
newsPopTrain &lt;- predict(preProcValues, newsPopTrain) 
newsPopTest &lt;- predict(preProcValues, newsPopTest)</code></pre>
<h2 id="summary-of-a-few-variables">Summary of a Few Variables</h2>
<p>The plots below show a histogram of the number of shares for the given day. Scatter plots on the effect of max positive polarity, article time delta and number of videos in the article are also included.</p>
<p>As expected the histogram has a strong right tail, as seem by the summary stats which show a very high maximum and a median severals orders of magnitude lower. This is expected for because of the “viral” nature of online popularity.</p>
<pre><code>summary(newsPopTrain$shares)

##     Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
## -0.26350 -0.19737 -0.16273  0.00000 -0.06909 49.46601

g0 &lt;- ggplot(newsPopTrain, aes(x=shares))
g0 + geom_histogram(binwidth = 0.5) + ggtitle(&#39;Histogram for Number of Shares&#39;) + ylab(&#39;Number of Shares&#39;) + xlab(&#39;Shares&#39;)</code></pre>
<p><img src="data:image/png;base64,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" /><!-- --></p>
<pre><code>summary(newsPopTrain$max_positive_polarity)

##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
## -3.0920 -0.6545  0.1579  0.0000  0.9704  0.9704

g1 &lt;- ggplot(newsPopTrain, aes(x = max_positive_polarity, y = shares )) 
g1 + geom_point() + ggtitle(&#39;Scatter of Max Positive Polarity Effect&#39;) + ylab(&#39;Shares&#39;) + xlab(&#39;Max Positive Polarity&#39;)</code></pre>
<p><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAqAAAAHgCAMAAABNUi8GAAABSlBMVEUAAAAAADoAAGYAOjoAOmYAOpAAZrYzMzM6AAA6ADo6AGY6OgA6Ojo6OmY6OpA6ZmY6ZpA6ZrY6kLY6kNtNTU1NTW5NTY5NbqtNjshmAABmADpmAGZmOgBmOjpmOmZmOpBmZgBmZjpmZmZmkJBmkLZmkNtmtrZmtttmtv9uTU1uTW5uTY5ubo5ubqtuq+SOTU2OTW6OTY6Obk2OyP+QOgCQOjqQOmaQZgCQZjqQZmaQkDqQkGaQkLaQtpCQtraQttuQ27aQ29uQ2/+rbk2rbm6rbo6ryKur5OSr5P+2ZgC2Zjq2kDq2kGa2tpC2ttu225C229u22/+2/7a2/9u2///Ijk3I///bkDrbtmbbtpDb27bb29vb2//b/7bb/9vb///kq27k///r6+v/tmb/yI7/25D/27b/29v/5Kv//7b//8j//9v//+T///9/KSJ9AAAACXBIWXMAAA7DAAAOwwHHb6hkAAAZvUlEQVR4nO2d/Xvb1nmGITuWmXRZm4qJrC1dt2RrmHj+mrSta9els7pOzD5Sr7bodEskjWJGicL//+tw8EEAIgiAFPDyJvk81xVJIYEbD8lb5xxAlOz5igKOt+oCilIWCaqgI0EVdCSogo4EVdCRoAo6ElRBR4Iq6Cws6OTff+B59//yrPje0Z+9jj9U5SvP2w0h/fe/jG/65id7czcfeGHe+bLw3snRg7PwsOEXCzGK9pjiigFB8+QBTB9FPrWeAaVOFhV0chS9RHM8GNx7HX+oyDB+mQNBvZ2X4RejjlcpqOf1ilsFfdxh6wiaZ8wVtOBRZAUNH0D6KG5tWOMZUGplUUGH3oNXvv/9UbEoiwiaAPo7P4i8HNzvlAgaMd/O+87waxy2kDFX6SJBMzeFD2BY9jQoTWRRQQfRcHd14AaOtx3vnfB/3wbT/s5fRcPrj92HwLTvP/a89185A3YH3r1X0e7uxndeuWHT8+IXsX/vF6Eik6NPQ0FjVjBc7TkDYmcH061fpxR/8vNg289Cy74LD+t0izYNGyYdShiRoMlBo7K/S3CRgFcHt0r48QP48+hRpEeJnpBJ/AwoDWTxEXQv83UQJ2w89fWyggYTdnTv5Oh+JxmzhsmNOUG/ftdZPnrvaydowgr2u/f66iBRIivXMEVPt80IOur0/Ghwm3YoZbjpPD2oK/tdgou+D4cJoVjQ9CjxEyJBG8zCJ0lfeTs//Kf/cV9NjoIX5W3wSgQqvXJLyN3MFB/cGYxs3wS3BS9X8mIFX37mFAyUyEzx935/5Dbo7446OdbQC0azZKvp9LyboYw6H5yF2+bWoNGYGFiYdihhRHskB43KpmvQcLDtJ4uAZA0ayRhP8dlHGj8hmuKby+KXmf7w8040r44yS8b//o9/6HhZQeM7B06T6as1ilzpB69jVtDXzoCrg168T8Jyo9T0DCTjRkoZde5/+jv3df4kyS1D3NiXdihhxGvQ+KBR2VRQV3M6wxcLmh4lfUIkaGNZ6jro5JufhJN44lg0yeUEHU5fy8xZSLzH8Lag4Q3xC5yygi+ns3PixvuvchQ30Xo/enVLUMdx/GHGp7mMeI/4oFHZVFDn+XBmjRDumgiaHiV9QiRoY1nyQn261vPdq+j98B//89uDpQV1Y1Q/GvEyLMeYniRnXvIMxf/m43AZmBfUfejnOpQw3MbpQW8LmozvMwAJapQFBb06iF+tfmZGi16Y/Bo0fbFyghZP8e5EqRNNlhnW1cE7H09f6JxcU4rLH/7enZ3lroMOdn7tDE87lDDSb7XpYjYr6ND72XSGLxY0O5Foim88i46gfTej+pO3HXdq4RZzB+713T1z11ri5V/4IbjzS3e9NB7dosw5SQrGup2/iNeteVZ6zSDzkqeUoffjYLz8t3iUHiTn5AHkE4dPO5QwIkGTg2YFDb8BJkd/lFlnFAmafaTxE5JcjFPunkUFDWbDzHlCcm0mui26XrMXfYhnvr3clfBh5opMVtCAuhuNQCkrGtAK5Jq5zBR7NYgvM4X6xcNf3KGU4Xb3sqDppSe348BL95r+JClcP/SmliZHSZ6QZF/l7lnuZ/E7P0quS7vT+eii95ehaR97u2fhB38U3Hj/s1s/qhkll9jzggYDcy+eIqescAofJdeIcpPmKHeh/oNo1Rke+7voYIP49D/pUMIId50eNCNo9CjSBv48QTNHSZ6QeF/l7tG7mSoy76eZik0kaHm+/7jk3SdK+5GgZXErbi0mVxoJWpbg7OmDVXfY8khQBR0JqqAjQRV0JKiCjgRV0JGgCjoLCvq/dVN/y+2BgKrwIRLUHgKqwodIUHsIqAofIkHtIaAqfIgEtYeAqvAhEtQeAqrCh0hQewioCh8iQe0hoCp8iAS1h4Cq8CES1B4CqsKHSFB7CKgKH1JD0PNut/vRqX/9rLt/IUExlC2B1BD0zaH7eHN86J8/kqAYypZAqgW9+c2J+3T94tQfPz6VoBTKlkCqBQ2m9m730B8/ufCvnztXHwaZP94qShuZL+j4ixM3il7uJ4K6ML671hQCqsKHVAsa5s1hOoJKUARlcyCe5zUgqNagjUFAVQiQ8K9c3UFQN7ff/MvpzfFTncVL0BYgdxXUXQf98MTXddDGIKAqBMidBS2KVfmNhICqICBNrEElaIMQUBU+RILaQ0BV+BAJag8BVeFDJKg9BFSFD5Gg9hBQFT5EgtpDQFX4EAlqDwFV4UMkqD0EVIUPkaD2EFAVPkSC2kNAVfgQCWoPAVXhQySoPQRUhQ+RoPYQUBU+RILaQ0BV+BAJag8BVeFDJKg9BFSFD5Gg9hBQFT5EgtpDQFX4EAlqDwFV4UMkqD0EVIUPkaD2EFAVPkSC2kNAVfgQCWoPAVXhQySoPQRUhQ+RoPYQUBU+RILaQ0BV+BAJag8BVeFDJKg9BFSFD5Gg9hBQFT5EgtpDQFX4kCUFVRTbaAS1g4Cq8CES1B4CqsKHSFB7CKgKHyJB7SGgKnyIBLWHgKrwIRLUHgKqwodIUHsIqAofIkHtIaAqfIgEtYeAqvAhEtQeAqrCh0hQewioCh8iQe0hoCp8iAS1h4Cq8CES1B4CqsKHSFB7CKgKHyJB7SGgKnyIBLWHgKrwIRLUHgKqwodIUHsIqAofIkHtIaAqfIgEtYeAqvAhEtQeAqrCh0hQewioCh8iQe0hoCp8iAS1h4Cq8CES1B4CqsKHSFB7CKgKHyJB7SGgKnyIBLWHgKrwIRLUHgKqwodIUHsIqAofIkHtIaAqfIgEtYeAqvAhtQS9OT70/etn3f0LCYqhbAmklqDn3cNQ0vNHEhRD2RJIHUHHf/03h/71i1N//PhUglIoWwKpIejNb/41GD3HTy786+cnwf8/DFI23ipK8ykR9Pypm94v9xNBXRjfXWsKAVXhQ6oFDYbOm9wIKkERlC2BVAt63nV5qjVoYxBQFT6kxhQfXWa6OX6qs3gJag6pLaiugzYGAVXhQ2oJOhtG+TWFgKrwIRLUHgKqwodIUHsIqAofIkHtIaAqfIgEtYeAqvAhEtQeAqrCh0hQewioCh8iQe0hoCp8iAS1h4Cq8CES1B4CqsKHSFB7CKgKHyJB7SGgKnyIBLWHgKrwIRLUHgKqwodIUHsIqAofIkHtIaAqfIgEtYeAqvAhEtQeAqrCh0hQewioCh8iQe0hoCp8iAS1h4Cq8CES1B4CqsKHSFB7CKgKHyJB7SGgKnyIBLWHgKrwIRLUHgKqwodIUHsIqAofIkHtIaAqfIgEtYeAqvAhEtQeAqrCh0hQewioCh+ypKCKYhuNoHYQUBU+RILaQ0BV+BAJag8BVeFDJKg9BFSFD5Gg9hBQFT5EgtpDQFX4EAlqDwFV4UMkqD0EVIUPkaD2EFAVPkSC2kNAVfgQCWoPAVXhQySoPQRUhQ+RoPYQUBU+RILaQ0BV+BAJag8BVeFDJKg9BFSFD5Gg9hBQFT5EgtpDQFX4EAlqDwFV4UMkqD0EVIUPkaD2EFAVPkSC2kNAVfgQCWoPAVXhQySoPQRUhQ+RoPYQUBU+RILaQ0BV+BAJag8BVeFDJKg9BFSFD5Gg9hBQFT5EgtpDQFX4EAlqDwFV4UMkqD0EVIUPkaD2EFAVPqSGoJfd7kenvn/9rLt/IUExlC2BVAs6fnzqnz/yb44P3ScJSqFsCaTeFB9Iev3iNHRVgkIoWwKpJ2gwdI6fXPjXz0+C/3kYpHRrRWk8ZYKOP//wxL/cTwR1YXx3rSkEVIUPqSOo78xMR1AJiqBsCaSeoP6bQ61BG4OAqvAh1YLGc/vN8VOdxUtQc0iNEfS82w3WoLoO2hgEVIUPqTnF3w6j/JpCQFX4EAlqDwFV4UMkqD0EVIUPkaD2EFAVPkSC2kNAVfgQCWoPAVXhQySoPQRUhQ+RoPYQUBU+RILaQ0BV+BAJag8BVeFDJKg9BFSFD5Gg9hBQFT6kUNCrg97VgXfvtQRtBQKqwocUCtrf9Qf3Xg92JWgrEFAVPqRI0GAAnRzt+sOSIZRRfk0hoCp8yBxBrw72JGhbEFAVPqRI0MnR3nDnpZvoJWgbEFAVPqRIUH/U8Xb9/oMzCdoKBFSFDykUtDqM8msKAVXhQySoPQRUhQ8pFnTgeb2BpviWIKAqfEihoP0H30ZXmiRoGxBQFT6kSNDwMlNPl5nagoCq8CES1B4CqsKHFE7xAzfFu2v1ErQNCKgKH1IoqD/0gpT4KUFXT9kSSLGglWGUX1MIqAofUiTo5KgnQVuEgKrwIUWCujMkCdoeBFSFDykS1C+9Ri9BGZQtgRSPoF4YXWZqBwKqwocUjqCKQovO4u0goCp8SKGgo46m+BYhoCp8SJGgk6O9yVGv9FyeUX5NIaAqfEiRoE7N/p4/LDmXZ5RfUwioCh8yT9CBfquzNQioCh9SJKj7dbnAzrKroYzyawoBVeFDCgUNFqF+39t5OddPCbp6ypZACgWtDqP8mkJAVfgQCWoPAVXhQwoF1XXQViGgKnxIkaClvy4nQSGULYEUCaq327ULAVXhQ4pHUAnaJgRUhQ8pErT0Er0EhVC2BDIjaPJmUJ0ktQYBVeFDCkfQ6jDKrykEVIUPkaD2EFAVPqRA0MHOy3Ci1+/FtwQBVeFDZgV1f1zZXQnVXxZpCwKqwofMCOreKOKPOr3y3+1klF9TCKgKHzIjaHiV3o2iej9oWxBQFT6kWNBw8JSgLUFAVfiQgim+F/8wvuxfUWCUX1MIqAofMiOoGz3DJejQ0y/NtQMBVeFDZgX1++4K0+So7A31EnT1lC2BFAhaJ4zyawoBVeFDJKg9BFSFD5Gg9hBQFT5EgtpDQFX4EAlqDwFV4UMkqD0EVIUPkaD2EFAVPqSGoOPPu91D379+1t2/kKAYypZAqgW9fn7ij784uTk+9M8fSVAMZUsg1YJeOivfHF6/OPXHj08lKIWyJZAaU3w0io6fXISDqe8/DFK6taI0nlJBb46f+pf7iaAujO+uNYWAqvAhdQS9fvY0OFV6IkElqD2khqDjzw+dpVqDNgUBVeFDqgWN/AyneZ3FS1BrSLWg512XQ10HbQwCqsKH1Jjii8Iov6YQUBU+RILaQ0BV+BAJag8BVeFDJKg9BFSFD5Gg9hBQFT5EgtpDQFX4EAlqDwFV4UMkqD0EVIUPkaD2EFAVPkSC2kNAVfgQCWoPAVXhQySoPQRUhQ+RoPYQUBU+RILaQ0BV+BAJag8BVeFDJKg9BFSFD5Gg9hBQFT5EgtpDQFX4EAlqDwFV4UMkqD0EVIUPkaD2EFAVPkSC2kNAVfgQCWoPAVXhQySoPQRUhQ+RoPYQUBU+RILaQ0BV+BAJag8BVeFDJKg9BFSFD5Gg9hBQFT5EgtpDQFX4EAlqDwFV4UOWFFRRbKMR1A4CqsKHSFB7CKgKHyJB7SGgKnyIBLWHgKrwIc0L6nmeVfk1hYCq8CGNC+p5OUP5z4A9BFQFAQmFkaAcCKgKARIZI0E5EFAVAsRYUK1BjSgbA7EWtNHyGwkBVUFAbNegDZffRAioCh8iQe0hoCp8iAS1h4Cq8CES1B4CqsKHSFB7CKgKHyJB7SGgKnyIBLWHgKrwIRLUHgKqwodIUHsIqAofIkHtIaAqfIgEtYeAqvAhEtQeAqrCh0hQewioCh8iQe0hoCp8SPOC6v2gNpQtgTQuqN5Rb0TZEogEtYeAqvAhEtQeAqrChzQuqNagRpQtgTQvqGH5NYWAqvAhEtQeAqrCh0hQewioCh8iQe0hoCp8SC1Bx49Pff/6WXf/QoLaU/Jnnc1W4UPqCHrZ/ejUvzk+9M8fSdDlk4q2EOXWdbtGqqwRpIagbz78bTCCXr84jUZSCbpcMqJJ0Fzu/pdFnJjjJxf+9fOT4P8eBinbWilMKJrhfmuTeg+wUtDL/URQF7Pvrs2BLDuCbvwatIE/HpYfQSXocllyDdpGFRSkIUG1Bm0MAqpCgDQk6M3xU53FS9A2IM2cJOk66F0hmuKXgdQSdDaM8msFWfokqfkq6wSRoFYQCboURIJaQSToUhAJagbRGnQZiAS1h4Cq8CES1B4CqsKHSFB7CKgKHyJB7SGgKnyIBLWHgKrwIRLUHgKqwodIUHsIqAoCon8KEQYBVSFA9I/J0iBWVea803kFTUojQWkQoyrzfpnJvkl5JCgNIkFzkaA0iATNRYLSIOu8Bi1i6ix+MyDm72ZqQdDCUVkj6EZAzN8P2sYUL0E3FyJBS5kSdNWQjRC0jTWoBIVANmEN2gpEJ0kwCKgKHyJB7SGgKnyIBLWHgKrwIRLUHgKqwodIUHsIqAofIkHtIaAqfIgEtYeAqiAguswEg4CqECC6UE+DgKps7E+SlO1MG/+iQwP/iMJsan97rPFg0RoEVEVvFlnf16I9CKgKQVCdJNEgoCqENWg5RILaQ0BVEBCNoDAIqAoBojUoDQKqUgip8T7SJptIUBpkQcocX1p7PHXeid9kEwlKgyxGmeeLBJWgLUEkaMHxJCgHAhdUa9CFs2EQqzXokr80pxF04WwGZMnf6lx6BF32144l6MLZCMiyvxcvQSWoCWQzBF2Xt9vVPvqqteBAlhUUtQbVu5k2GLLkGrSNKqUQCbpwNgwCqiJB2a+FKWTZEVRTfLOC5h/ByrXAQHSSNB9pKeith7dqLTiQzRC0DLLgbvnjSdBVQ9ZG0GV/1Lmw2OnhJGiTkDsNFItXkaDNCrrxa9C7vQ5LVFn2JMl6ipegDMh2C1p2kqQ1KAJiLejSU7wuM9V5CCi3GoGsjaB1RkIJinKrEUgrgpar1LygyX1bKOj6rEGX8awlQRd2ogiyDHQLBV2bEXQp0SRoiaDLPS8SdA5kAdHSDTdF0DbWoHd7YiToFBL3q/983lLrTgNFvkr2zhr75bKSEbTsMpMEbQYyLbjIANq2oPX2ywU3xUvQilQ8PU0J2sYUvzYjKFnQ62fd/QuioLem7NzhM/9zW9CC5zO94TakQtA6r0yZoAs7UQRZBrpBgt4cH/rnj1oUtPDRzX8aZw4Yf84dP/s/1WvQ9Jb8fZWC1nppJGgp886CXr849cePT5cSdMEBZuZGf87QltuxcUGndy8gaMkjbUXQOk9M/qb8fTUFLXoqbjVZuaDjJxf+9fOT4KuHQeZvFx6u8qZa+01vTO8roc9sOwd6a/vCComgRQcte4Blj7Td+2o97aWbt7BfvdTbr3KLy/1EUJeq74fcd1etb63CjeIb0/uKv7tza8rsBtnNq9egtw5TdNCKEbTskeYpNR58xX35Z7as1bwHWNSk5n4zTSoeRFmi/RocQeGCzoNK0M0WtO4a9NZiqPYatPQkKb2v2OK5gMxtt9egxau2zFdFB51zHXR6U8kjbUPQ8sVhyS2LCVq61KUIenP8tNZZfHH5u2UzILODedF9ZfuVVVlQjnjzwsezqGd3/Fl8tJ/ZddA55e+UDYOAqvAh9QXNhVF+TSGgKnyIBLWHgKrwIRLUHgKqwodIUHsIqAofIkHtIaAqfIgEtYeAqvAhEtQeAqrCh0hQewioCh8iQe0hoCp8iAS1h4Cq8CES1B4CqsKHSFB7CKgKHyJB7SGgKnyIBLWHgKrwIUsKWjslv71kHE4TUJX1aSJBDcOpsj5NJKhhOFXWp4kENQynyvo0aUtQRWkkElRBR4Iq6EhQBR0JqqDTkqCX3e5Hp9WbGWT8ebd7uOoSSdI/0bLK5P7SwYpT+Yy0I6g7bPrnSFYZ92elxl+cVG9okUvEd23+L76uNtXPSHtTPGO0uHSvxBvGEPrmw98SnpP8X9taaWo8I+0JSvkm9TN/nG/VQXiR/3uFK86Kpni39PsQ8hSEf/4MEoSg+b/4uuKsQNA33W44dq7+OYiaXD8D+Bk/KQhBNYLGYaz8xp8jakRBCApag65MUM4sgvKT4UX+L76uOKsaQc+7XcYaNCjS5VwIRQiq66CK0lgkqIKOBFXQkaAKOhJUQUeCKuhI0IqMOvdeB5+uDh6cFdw7OQr/Oaqdl7P7vfvS//5V+KnObre3i3dXJGhFRp1Qo1FnjqB77tMglHhm10I5i3cr2Hb+7tsUCVqRUecTJ9PgkzJBrw56RbtWCZrZTYLOiQStyKjzs5+e+ZO//WUg6KgTzMt7/iAYU68OQsUyprlpezfcIdioF+j1q+CLvdG7/xxuEgyWboN4yJzdzdkY40fv/cK793W0e98RB7ureeiISNCKjDqf/d1rf/THbx+chQOem5YDbfqRNLFpfaffru/+C8e9UacXfA6le/flIFA72M7d6Q+icbhwtwQ/6kTCut2HwdEmR0XD87ZEglYkcG3Q84d7wwdn/+fkiqz71XvJUBie7QQaOZXch1F8Typo/CncIJ7UC3Z792WCD4443d1tnxC3MxK0IoEuw2DA7A3d2DeMT70HXjyoxUNhkPB+51Q/numnZrptgpFzEP1L9HvFu4UDb4SPxuD4pmB63+oZXoJWJRD06qff/unroZvid15GU3jfi6UpENQNk144JMaCBnd9Fzk6hRYKmuBzgo7e+/1Wz/AStCpuwv3ql7vOpGgQ3XErw/+Kz78zprmRdRifBAUzc0bQqz9xK4Jh5qrn7G5uDRDjc4JOjj7d6hleglbFCToIJmYnqBvhOjvh2UysYmpacrYT3pEMib3MgDs5CgSMLZ3dzQka4xNBo/XqwNvqGV6CVsUJGs3TZ255ufPrg14/PC0PvUlNm15mitep0XJ0N15b9uIN4lF0drd49erwiaCR1+Ep0xZHgsKz3efwEhSfwV71NpscCYrOnLcAbFEkqIKOBFXQkaAKOhJUQUeCKuhIUAUdCaqg8//Ye3yQx1u3iQAAAABJRU5ErkJggg==" /><!-- --></p>
<pre><code>summary(newsPopTrain$timedelta)

##     Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
## -1.57188 -0.89940 -0.06681  0.00000  0.89388  1.72648

g2 &lt;- ggplot(newsPopTrain, aes(x = timedelta, y = shares )) 
g2 + geom_point() + ggtitle(&#39;Scatter of Article Age Effect&#39;) + ylab(&#39;Shares&#39;) + xlab(&#39;Time Delta&#39;)</code></pre>
<p><img src="data:image/png;base64,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" /><!-- --></p>
<pre><code>summary(newsPopTrain$num_videos)

##     Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
## -0.29034 -0.29034 -0.29034  0.00000 -0.07625 15.55264

g3 &lt;- ggplot(newsPopTrain, aes(x = num_videos, y = shares )) 
g3 + geom_point() + ggtitle(&#39;Scatter of Videos Number Effect&#39;) + ylab(&#39;Shares&#39;) + xlab(&#39;Number of Videos&#39;)</code></pre>
<p><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAqAAAAHgCAMAAABNUi8GAAABNVBMVEUAAAAAADoAAGYAOjoAOmYAOpAAZpAAZrYzMzM6AAA6ADo6AGY6OgA6Ojo6OmY6OpA6ZmY6ZpA6ZrY6kJA6kLY6kNtNTU1NTW5NTY5NbqtNjshmAABmADpmOgBmOjpmOmZmZgBmkJBmkLZmkNtmtrZmtttmtv9uTU1uTW5uTY5ubo5ubqtuq+SOTU2OTW6OTY6Obk2OyP+QOgCQOjqQZgCQZjqQZmaQkDqQkGaQkLaQtpCQtraQttuQ2/+rbk2rbm6rbo6ryKur5OSr5P+2ZgC2Zjq2kDq2kGa2tpC2ttu229u22/+2/9u2///Ijk3I///bkDrbkGbbtmbbtpDb27bb29vb2//b/7bb/9vb///kq27k///r6+v/tmb/yI7/25D/27b/5Kv//7b//8j//9v//+T///8k44D8AAAACXBIWXMAAA7DAAAOwwHHb6hkAAAZQklEQVR4nO2dfUMj13nFh32pVt62sdOgNUvcNk2teLtvhSaN6wacFOK2cXZR12kdIEIBifn+H6H33pnRGyPpSpp5dI44zx8LEjM/HR39mDcBm6QaDfAkmw6g0cwbCaqBHgmqgR4JqoEeCaqBHgmqgR4JqoEeCaqBnqUFHfznXybJw384L/9q7+/e5f8smt8mScNBbvYfZ6jB4YPfH+afuxuNmCydZDd8vNnfnbnMzf58VCfJp1GEypNNT9Sz0lQ9ywo6OMxezsflhnYevMv/WTDdXAknSDvc4UQaLC/ozlG2bjWChlDDZNMLRjwrTeWzrKDd5PG3afrnw1yr6VlC0BzQazYm7/ATLWj2jbKWoGNhQ4buvKemsZ5lBe0U2yz/sn9oJo/CzQ9ut7/z02zz+iP/jxPmz58lyV9/G2TrJA++zVb3dz5yn5+6ZfIX/DT76D5kW1AP/V0QtCCMVksHv3AP9PkwzINfhp28FzRb2Zvda+5+aLo03WbyyblP6j55NMRMRxrzLoT6+yzZ6LGzJznIn5XGeJbfgu6Ofe7GC5vvJtvjgvaa+VcHhw+bxRFBt7hzTNBu7lgjcyywHn3WSEeE0Wr5AUY7D9Bxh63+69OCfuyW3/mqGfbVN/sPmzmmNFK5oGOPnX0iQTc0S58k/TbZ+fjf/89/NvByfEi8G35rFPbVw128+6Lb0H3X9NoNX1j36edeZ+fGaEeameVv+89u9nd+5Y8gGpOEfLVe84fnw4OC8EC95uPzO4K6xT9k3yQemPzofPDNNHDoWnEMmsnYLpKMFs2fpHbxm5nlLzP94RfNbDfrdqXDO//3v/61mYwLmn+x43fcw1c2V+vUveZjR3rhqKHj9PKOZev5BUeE0Wq95sOf/G4UxT+QP5OfFrSRXx3IjM/u95iSSOWCjj/27tiDacxnpeugg+/+Nmyf2vntbIc4IWh3+LqPzs2LNbqTgmZ67Wbb0ux+79mIMLaa3wsnn+QHtMWm+ujOMWhxkHzqBc1c2zkqjVR+knTnsVMJuqFZ8UJ9trFrZzfcXvTjf/vv7/dXFNSfH/U+OooSNP3us9HRa/Zobj/+vQTd2llS0OF19dOxvV/2Ik4eg45e2AlBy3bxftlOZlexi/d6jW+gh6v5+cPPi3UzZzrJ33gJw9WAbMVJQRtpsYsviVQu6Phjaxe/0Vl2C3oadrCDD+70I5w/9Pa9VI1zf13Gn4OH48lwouxOdtzZTnHxKEzpSZK/+y9+vpumxUnS5365xgShWK3rTnjSwTe5qbkz/gTbC5r8NFtxWlB/GvfNFHCBoOOL5k+yuMCmsZ1lBXWv99g5RXbNZ+zdpY53JfyT7yV3JzZX3bGrN+0RtJu9IxSW7A4vMw0Jdy4zFcBcLncIvJuOVpwW1F90CkcFpZGG7ySF45L20NLhYxcXtjq6zLSJWe29+J1PimvY4ap5uI7+K7+PvfksaZyHf9Keu/Ph55P703BnuGg+IWh+4JAt6Y4yH/0+XKgvCGOrhQv1Pyx4xdYve0/+f5rJJ38sOwZ1fv/g23QMuFjQsccunmT2rDTGo59m0kCPBNVAjwTVQI8E1UCPBNVAjwTVQI8E1UCPBNVAjwTVQI8E1UDPkoL+KWoiF1t+6MB0gWGakKAmYLrAME1IUBMwXWCYJiSoCZguMEwTEtQETBcYpgkJagKmCwzThAQ1AdMFhmlCgpqA6QLDNCFBTcB0gWGakKAmYLrAME1IUBMwXWCYJiIEvWi1Wp+epf3Xrb1LCYrF5QPXIOj7A//v7fFBevFcgmJx+cDVC3r79Yn/0H97ll6/OJOgUFw+cPWCul17q3WQXr+8TPtvvKtP3Mze3mo0dcxsQa+/OPFb0au9QlA/9Xy3xH9bsYHpAsM0sVjQMO8PRlvQDQiaJEk94OlBeVm2F1yboJs8Bg1/M6kO8J1BeVm2F1y9oH7ffvvrs9vjVxs7i5eg2wOu5zros5N0k9dBJej2gLfznSQdg24NeDsFpQfTBYZpQoKagOkCwzQhQU3AdIFhmpCgJmC6wDBNSFATMF1gmCYkqAmYLjBMExLUBEwXGKYJCWoCpgsM04QENQHTBYZpQoKagOkCwzQhQU3AdIFhmpCgJmC6wDBNSFATMF1gmCYkqAmYLjBMExLUBEwXGKYJCWoCpgsM04QENQHTBYZpQoKagOkCwzQhQU3AdIFhmpCgJmC6wDBNSFATMF1gmCYkqAmYLjBMExLUBEwXGKYJCWoCpgsM04QENQHTBYZpQoKagOkCwzQhQU3AdIFhmpCgJmC6wDBNSFATMF1gmCYkqAmYLjBMEysKqtHYjragtYLpAsM0IUFNwHSBYZqQoCZgusAwTUhQEzBdYJgmJKgJmC4wTBMS1ARMFximCQlqAqYLDNOEBDUB0wWGaUKCmoDpAsM0IUFNwHSBYZqQoCZgusAwTUhQEzBdYJgmJKgJmC4wTBMS1ARMFximCQlqAqYLDNOEBDUB0wWGaUKCmoDpAsM0IUFNwHSBYZqQoCZgusAwTUhQEzBdYJgmJKgJmC4wTBMS1ARMFximCQlqAqYLDNOEBDUB0wWGaUKCmoDpAsM0IUFNwHSBYZqQoCZgusAwTUhQEzBdYJgmJKgJmC4wTBMS1ARMFximCQlqAqYLDNOEBDUB0wWGaUKCmoDpAsM0ESXo7fFBmvZft/YuJSgWlw9ci6AXrYMg6cVzCYrF5QPXIej1P/3zQdp/e5ZevziToFBcPnANgt5+/R9u63n98jLtvzlxt5+4mbe91WiqnzmCXrzyu/ervUJQP/V8t8R/W7GB6QLDNLFYULfpvJ3YgkpQHC4fuHpBL1p+XukYFJHLB67tMtPt8SudxcNx+cC6DgoJpgsM00SUoHennjDxqdnAdIFhmpCgJmC6wDBNSFATMF1gmCYkqAmYLjBMExLUBEwXGKYJCWoCpgsM04QENQHTBYZpQoKagOkCwzQhQU3AdIFhmpCgJmC6wDBNSFATMF1gmCYkqAmYLjBMExLUBEwXGKYJCWoCpgsM04QENQHTBYZpQoKagOkCwzQhQU3AdIFhmpCgJmC6wDBNSFATMF1gmCYkqAmYLjBMExLUBEwXGKYJCWoCpgsM04QENQHTBYZpQoKagOkCwzQhQU3AdIFhmpCgJmC6wDBNSFATMF1gmCYkqAmYLjBMExLUBEwXGKYJCWoCpgsM04QENQHTBYZpYkVBNRrb0Ra0VjBdYJgmJKgJmC4wTBMS1ARMFximCQlqAqYLDNOEBDUB0wWGaUKCmoDpAsM0IUFNwHSBYZqQoCZgusAwTUhQEzBdYJgmJKgJmC4wTBMS1ARMFximCQlqAqYLDNOEBDUB0wWGaUKCmoDpAsM0IUFNwHSBYZqQoCZgusAwTUhQEzBdYJgmJKgJmC4wTBMS1ARMFximCQlqAqYLDNOEBDUB0wWGaUKCmoDpAsM0IUFNwHSBYZqQoCZgusAwTUhQEzBdYJgmJKgJmC4wTBMS1ARMFximCQlqAqYLDNOEBDUB0wWGaUKCmoDpAsM0IUFNwHSBYZqQoCZgusAwTUhQEzBdYJgmIgS9arU+PUvT/uvW3qUExeLygasX9PrFWXrxPL09PvAfJCgUlw9czy7eSdp/exZclaBIXD5wPYK6Tef1y8u0/+bE3XjiZu7SGk3lM0/Q6589O0mv9gpB/dTz3RL/bcUGpgsM00SMoKk3c7QFlaA4XD5wTZeZ3h/oGBSRyweuXtB83357/Epn8XBcPnANW9CLVssdg+o6KCKXD6x3kiDBdIFhmpCgJmC6wDBNSFATMF1gmCYkqAmYLjBMExLUBEwXGKYJCWoCpgsM04QENQHTBYZpQoKagOkCwzQhQU3AdIFhmpCgJmC6wDBNSFATMF1gmCYkqAmYLjBME6WC3uy3b/aTB+8kKDqXD1yJoKeNtPPgXachQdG5fOAqBHUb0MFhI+3O2YTWEyY+NRuYLjBMEzMEvdnflaAEXD5wFYIODne7O0d+Ry9Bwbl84EqOQXvNpJGePj6XoOhcPrAuM0GC6QLDNCFBTcB0gWGaKBe0kyTtjnbx+Fw+cDXXQR9/n11pkqDgXD5wZZeZ2rrMRMDlA0tQSDBdYJgmSnfxHb+L99fqJSg4lw9czUlSN3Ezx08JCsLlA+syEySYLjBME2WCDg7bEpSDyweu6CRJgnJw+cAVnSTNuUYvQYG4fOBqtqBJGF1mgufygY1OkjQa29FZfK1gusAwTZQK2mtqF8/B5QNXc5lpd3DYnnsuX0+Y+NRsYLrAME2UCerVPN1Nu3PO5esJE5+aDUwXGKaJWYJ29FudDFw+cDU/DxrsnHc1tJ4w8anZwHSBYZooFdQdhKanyc7RTD8lKAiXD6wfFoEE0wWGaUKCmoDpAsM0USqoroOycPnA1VwHnfPrchIUicsH1o/bQYLpAsM0Ub4FlaAkXD5wJceg8y7RS1AkLh94bUGLHwbVSRIDlw+sy0yQYLrAME1IUBMwXWCYJkoE7ewchR29fi8en8sHXl9Q/8eV/ZVQ/WURAi4feG1B/Q+KpL1me/7vdtYTJj41G5guMEwTdwQNV+n9VlQ/D0rA5QNXI2jYeEpQfC4fuIJdfDt/M37e/6JQT5j41GxgusAwTdwR1G89wyFoN2nP9FOCgnD5wBVcZjr1V5gGh/N+oF6CgnD5wLpQDwmmCwzThAQ1AdMFhmlCgpqA6QLDNCFBTcB0gWGakKAmYLrAME1IUBMwXWCYJiSoCZguMEwTEYJe/6zVOkjT/uvW3qUExeLygasXtP/mJL3+4uT2+CC9eC5Bsbh84OoFvfJWvj/ovz1Lr1+cSVAoLh+4nmNQtxW9fnkZNqZp+sTN3KU1mspnrqC3x6/Sq71CUD/1fLfEf1uxgekCwzQRI2j/9St3qvRSguJx+cC1nMUfeEt1DArI5QNXL2jmZ9jN6ywejcsHrl7Qi5afA10HReTygfVOEiSYLjBMExLUBEwXGKYJCWoCpgsM04QENQHTBYZpQoKagOkCwzQhQU3AdIFhmpCgJmC6wDBNSFATMF1gmCYkqAmYLjBMExLUBEwXGKYJCWoCpgsM04QENQHTBYZpQoKagOkCwzQhQU3AdIFhmpCgJmC6wDBNSFATMF1gmCYkqAmYLjBMExLUBEwXGKYJCWoCpgsM04QENQHTBYZpQoKagOkCwzQhQU3AdIFhmpCgJmC6wDBNSFATMF1gmCYkqAmYLjBMExLUBEwXGKYJCWoCpgsM04QENQHTBYZpQoKagOkCwzQhQU3AdIFhmpCgJmC6wDBNrCioRmM72oLWCqYLDNOEBDUB0wWGaUKCmoDpAsM0IUFNwHSBYZqoT9AkSejag3lZthcMI2jiZ6WnEJN6+qHqAVc3dB7BNLEFglb5SCgvy/aCJWh14AqHziOYJmoT1O4YVIIygXEEXSFMfOqJWzoGJQLfR0EJwHSBYZqQoCZgusAwTUhQEzBdYJgmJKgJmC4wTBMS1ARMFximCQlqAqYLDNOEBDUB0wWGaUKCmoDpAsM0IUFNwHSBYZqQoCZgusAwTUhQEzBdYJgmJKgJmC4wTBMS1ARMFximCQlqAqYLDNNEfYLqd5IMuHxgGEENfyeJAEwXGKYJCWoCpgsM04QENQHTBYZpojZBdQxqweUD4wi6Qpj41GxgusAwTUhQEzBdYJgmJKgJmC4wTBMS1ARMFximiShBr1+cpWn/dWvvcglBdZJkwOUD1yHoVevTs/T2+CC9eB4haH51SZeZLLh84BoEff/sN24L2n97lm1JFwhaiClBLbh84Np28dcvL9P+mxN364mb2csGMcc+ajRVzEJBr/YKQf3MNn645dQxqAGXD2ywBY0UdIUw8anZwHSBYZqIFnTZY9BVwsSnZgPTBYZpIlrQ2+NXS53FrxImPjUbmC4wTBPRgkZfB5Wghlw+8MbfSdIu3pLLB5agkGC6wDBNSFATMF1gmCYqF1THoJZcPvDmBV0jTHxqNjBdYJgmJKgJmC4wTBMS1ARMFximCQlqAqYLDNOEBDUB0wWGaUKCmoDpAsM0UbugtfzY8ta/LNsLRhO0nh+s3/qXZXvBmxe0EDL7geX1BJ217ta/LNsL3rigU7+TtJagM1fe+pdle8Fogq51DCpBtw8MJ+g6I0G3D7xxQaeOQdc7i9cx6NaBNy7o1G916iy+Vi4fGEbQKk6SZqeunFgzmC4wTBMS1ARMFximCQlqAqYLDNNE5YJWepI0M3X1yHrBdIFhmqhe0DXCxKdmA9MFhmlCgpqA6QLDNCFBTcB0gWGakKAmYLrAME1IUBMwXWCYJiSoCZguMEwT1QuqP9xgyOUDb1xQ/ekbSy4fGE5QXaivk8sHNhJ09kz95wn6vxQ0lUxdW1C9F18rlw+88V381EmSBK2VywfevKBTYXQMWieXD7x5QXWZyZDLB964oFO/8lHP0IHpAsM0UZug9Rx8FqnZwHSBYZqQoCZgusAwTUhQEzBdYJgmJKgJmC4wTBMS1ARMFximCQlqAqYLDNOEmaCV6rr1L8v2glEFrXaDuvUvy/aCYQSdulAvQQVeiastqAmYLjBME7ULOvaHRqYWWzLpROoKGHPA1Q+dRzBN1C3ojC3nmhvUtALGbHANQ+cRTBMS9C64hqHzCKYJCXoXXMPQeQTTxIYE1THofQXDCqoL9QKvwrUStI7LTNqCEoLvkaArIueuhPKybC94uwSdtc4ags5fC+Vl2V7wVgk6cyUJSgu+R4KudgwqQTcL3k5Bp9ddpz0dg24UjCroypu7ceYo9fKouEF5WbYXDCvo2NeXflISdHvA6IJWcyyaTn95xlpL3F0Grm7oPIJpYlOCLqXpfEFnOL/c3WXgCofOI5gmzASdPJycpUn58UAdgpY/fjq2WNmzW3XoPDIRNKZkK0EXb1jHVy5njZ7Q+oLO+Go6uVRlU7NHlYSdhBgIGlVyvKD91629y5oEnWHigq3x2Np/mnP35M1tFLSStFOQ5RLHP35tgt4eH6QXzysXdO5XF99d8ogznv7875BhHVPMqmbLBV0iQG2C9t+epdcvzioSdMb2bClB49CzNC66mfhGWbRUyZMtuVmy8LJHXtFTKuhKjzD1lCMFLd02zJsSQeeuGy3o9cvLtP/mxH32xM3s5cKjjj5O3ZxxdxUrGSw167lO3pyx8IyVKplJ4oqPMPepzl4n4ilXsfLCJa72CkH9zP2WWntjuNJKBkvNeq6TN8sWXnbHFj1lr8Raj1CsHLcFHSsokn+3iflxowUdbUEl6PRzXVz4tgsaP3cPdioSdMVj0OmDu+njtKibNS41FTNdsPLdJ1tys2Theo9BF8Raboomllo6fkq4cxnRgt4ev4o6ix9/TW1fltVmMhfK+yfbC67vnaTI66DrhIlPzQamCwzTRLygE1NPmPjUbGC6wDBNSFATMF1gmCYkqAmYLjBMExLUBEwXGKYJCWoCpgsM04QENQHTBYZpQoKagOkCwzQhQU3AdIFhmpCgJmC6wDBNSFATMF1gmCYkqAmYLjBMExLUBEwXGKYJCWoCpgsM04QENQHTBYZpYkVB42bOry6BDl3iexNYgoahS3xvAkvQMHSJ701gCRqGLvG9CVyLoBpNVSNBNdAjQTXQI0E10CNBNdBTvaATv0dPMRetVuvTs8XLoUz4Qy9MNYfAK7ZcuaCTf0+UYt4fbDrBUnPlX2emmkPgVVuuXNDJv+XEMLdfnyxeCGfeP/uNq5eo5izwqi1XLujkX8NjGLezbLWYNqJeTKqafeBVW65c0Mm/J8ow11+ccG1F/etNVXP4jlqxZW1Bs2E6DqXcgoZZoWUdg2bDJihVzVCCTv49UYbxe8vbX5O81n78601Vc3FMskrLug4artA9I9lZhqG9DrpKy3onSQM9ElQDPRJUAz0SVAM9ElQDPRJUAz0SNHZu9hv+Q/fBu9Iv9z46WgDoJDtukcFhI7vVKNaYRdT4kaCxc7OftNM1BL3Zb4ePnQAYHLaLL0jQeSNBY+dm/yc/OF9D0GKB7GPv6RAjQeeNBI0dtwU83Q06BcXcP72PvmomyW7P/dN2t79MksfnftuYJE653tNfJpl5/o5G6pfKdu6e4vbwwVS3Wd750i2Wr5Qvm4alwwb73o8EjR0nqN/sjQvadEJ2vJVut+1v+OPLcIzZeXzea2Y6psWdw01s163g9/Dujpv9Xcd98K5YaWLZXrO9sSeLMxI0dvwxZGd3UtB2rtHwxkdHYYftZS70CncUawXQj4/CHr5Y2NldrDRc9qn2+vlI0Njxgjq3JnbxR/khpb/xNHOsE/6jb7fjH99gDpcO4/bxbg/v7+uErz19V6xULJueFscD934kaOyEs/BOY6Gg3rE0TecI2n38R38OPy5ovtJQ0HDRQCdPqQSNnyDo4F++nCVo/rG7M36y7ibcMb6Ld9vhr7zNxS7e/VOsVCw7esB7PxI0djJfum675k9tBoc7U4IOT5LcVrC7M9pg3jlJcvv4vwpn6v4kqZGfJGUrFcsGRxdf+r8PI0FjJ9+gnfpLSM0k+ccfT29Bv8yOG/2VIrchHOmVXzoa860briBNX2bK3mfKIN0ku62RoBrokaAa6JGgGuiRoBrokaAa6JGgGuiRoBrokaAa6JGgGuiRoBro+X9p6XizCM3vvwAAAABJRU5ErkJggg==" /><!-- --></p>
<h2 id="modeling">Modeling</h2>
<h3 id="standard-tree-based-model-no-ensemble">Standard Tree Based Model (no ensemble)</h3>
<p>The type of model being fitted here is a decision tree. The tree splits are based on minimizing the residual sum of squares for each region.</p>
<pre><code>rpartFit &lt;- train(shares ~ timedelta + n_tokens_title + n_tokens_content + n_unique_tokens + n_non_stop_words + n_non_stop_unique_tokens
                 + num_hrefs + num_self_hrefs + num_imgs + num_videos + average_token_length + num_keywords + data_channel_is_lifestyle +
                 data_channel_is_entertainment + data_channel_is_bus + data_channel_is_socmed + data_channel_is_tech + data_channel_is_world +
                 self_reference_min_shares + self_reference_max_shares + self_reference_avg_sharess + global_subjectivity + global_sentiment_polarity
                 + global_rate_positive_words + global_rate_negative_words + rate_positive_words + rate_negative_words + avg_positive_polarity +
                  min_positive_polarity + max_positive_polarity + avg_negative_polarity + min_negative_polarity + max_negative_polarity + title_subjectivity
                 + title_sentiment_polarity + abs_title_subjectivity + abs_title_sentiment_polarity, data = newsPopTrain,
             method = &quot;rpart&quot;,
             trControl = trainControl(method = &quot;cv&quot;, number = 10),
             tuneGrid = data.frame(cp = c(.001,.01,.015,.02,.03,.04,.05))
             )
             
rpartFit

## CART 
## 
## 4664 samples
##   37 predictor
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 4197, 4197, 4198, 4198, 4198, 4198, ... 
## Resampling results across tuning parameters:
## 
##   cp     RMSE       Rsquared     MAE      
##   0.001  0.9415776  0.008291090  0.2724841
##   0.010  0.9040358  0.006221227  0.2642650
##   0.015  0.9012953  0.006476592  0.2640466
##   0.020  0.9008808  0.007501558  0.2660116
##   0.030  0.8754077  0.010782680  0.2660516
##   0.040  0.8629773          NaN  0.2669994
##   0.050  0.8629773          NaN  0.2669994
## 
## RMSE was used to select the optimal model using the smallest value.
## The final value used for the model was cp = 0.05.

# create the prediction
pred1 &lt;- predict(rpartFit, newdata = newsPopTest)

# compare the prediction vs the actual
resample1 &lt;- postResample(pred1, obs = newsPopTest$shares)
resample1

##      RMSE  Rsquared       MAE 
## 1.1829896        NA 0.2640217</code></pre>
<h3 id="boosted-tree-based-model">Boosted Tree Based Model</h3>
<p>A boosted tree is an ensemble method which slowly approaches the tree prediction which would result from the original data. In general, an ensemble model model will have a lower RSME than a single tree model.</p>
<pre><code>gbmFit &lt;- train(shares ~ timedelta + n_tokens_title + n_tokens_content + n_unique_tokens + n_non_stop_words + n_non_stop_unique_tokens
                 + num_hrefs + num_self_hrefs + num_imgs + num_videos + average_token_length + num_keywords + data_channel_is_lifestyle +
                 data_channel_is_entertainment + data_channel_is_bus + data_channel_is_socmed + data_channel_is_tech + data_channel_is_world +
                 self_reference_min_shares + self_reference_max_shares + self_reference_avg_sharess + global_subjectivity + global_sentiment_polarity
                 + global_rate_positive_words + global_rate_negative_words + rate_positive_words + rate_negative_words + avg_positive_polarity +
                  min_positive_polarity + max_positive_polarity + avg_negative_polarity + min_negative_polarity + max_negative_polarity + title_subjectivity
                 + title_sentiment_polarity + abs_title_subjectivity + abs_title_sentiment_polarity, data = newsPopTrain,
             method = &quot;gbm&quot;,
             trControl = trainControl(method = &quot;cv&quot;, number = 10))

## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0903             nan     0.1000    0.0016
##      2        1.0881             nan     0.1000    0.0010
##      3        1.0865             nan     0.1000    0.0004
##      4        1.0848             nan     0.1000    0.0003
##      5        1.0838             nan     0.1000   -0.0005
##      6        1.0834             nan     0.1000   -0.0002
##      7        1.0823             nan     0.1000   -0.0009
##      8        1.0817             nan     0.1000   -0.0000
##      9        1.0812             nan     0.1000    0.0000
##     10        1.0805             nan     0.1000   -0.0010
##     20        1.0733             nan     0.1000   -0.0001
##     40        1.0664             nan     0.1000   -0.0007
##     60        1.0613             nan     0.1000   -0.0012
##     80        1.0573             nan     0.1000   -0.0012
##    100        1.0527             nan     0.1000    0.0001
##    120        1.0519             nan     0.1000   -0.0008
##    140        1.0478             nan     0.1000   -0.0009
##    150        1.0459             nan     0.1000   -0.0010
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0897             nan     0.1000    0.0003
##      2        1.0812             nan     0.1000   -0.0001
##      3        1.0693             nan     0.1000   -0.0005
##      4        1.0603             nan     0.1000   -0.0030
##      5        1.0578             nan     0.1000    0.0009
##      6        1.0480             nan     0.1000   -0.0077
##      7        1.0424             nan     0.1000   -0.0080
##      8        1.0404             nan     0.1000    0.0010
##      9        1.0392             nan     0.1000    0.0002
##     10        1.0297             nan     0.1000   -0.0011
##     20        0.9820             nan     0.1000    0.0007
##     40        0.9385             nan     0.1000   -0.0030
##     60        0.9071             nan     0.1000   -0.0041
##     80        0.8851             nan     0.1000   -0.0020
##    100        0.8565             nan     0.1000   -0.0019
##    120        0.8371             nan     0.1000   -0.0032
##    140        0.8234             nan     0.1000   -0.0006
##    150        0.8141             nan     0.1000   -0.0038
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0844             nan     0.1000   -0.0007
##      2        1.0727             nan     0.1000   -0.0020
##      3        1.0702             nan     0.1000   -0.0000
##      4        1.0653             nan     0.1000    0.0011
##      5        1.0542             nan     0.1000   -0.0027
##      6        1.0518             nan     0.1000    0.0001
##      7        1.0441             nan     0.1000   -0.0026
##      8        1.0421             nan     0.1000    0.0005
##      9        1.0396             nan     0.1000   -0.0003
##     10        1.0387             nan     0.1000   -0.0004
##     20        0.9779             nan     0.1000   -0.0002
##     40        0.9144             nan     0.1000   -0.0057
##     60        0.8694             nan     0.1000   -0.0003
##     80        0.8164             nan     0.1000   -0.0031
##    100        0.7871             nan     0.1000   -0.0021
##    120        0.7502             nan     0.1000   -0.0023
##    140        0.7353             nan     0.1000   -0.0002
##    150        0.7200             nan     0.1000   -0.0029
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0107             nan     0.1000    0.0016
##      2        1.0097             nan     0.1000    0.0004
##      3        1.0089             nan     0.1000    0.0002
##      4        1.0084             nan     0.1000   -0.0002
##      5        1.0067             nan     0.1000   -0.0004
##      6        1.0055             nan     0.1000   -0.0008
##      7        1.0045             nan     0.1000   -0.0011
##      8        1.0031             nan     0.1000    0.0003
##      9        1.0025             nan     0.1000   -0.0000
##     10        1.0015             nan     0.1000   -0.0002
##     20        0.9979             nan     0.1000    0.0001
##     40        0.9914             nan     0.1000    0.0000
##     60        0.9877             nan     0.1000   -0.0013
##     80        0.9852             nan     0.1000   -0.0003
##    100        0.9808             nan     0.1000   -0.0003
##    120        0.9781             nan     0.1000   -0.0015
##    140        0.9753             nan     0.1000   -0.0008
##    150        0.9747             nan     0.1000   -0.0007
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0018             nan     0.1000    0.0042
##      2        0.9911             nan     0.1000   -0.0037
##      3        0.9892             nan     0.1000    0.0006
##      4        0.9828             nan     0.1000   -0.0007
##      5        0.9796             nan     0.1000    0.0034
##      6        0.9698             nan     0.1000   -0.0029
##      7        0.9604             nan     0.1000   -0.0004
##      8        0.9553             nan     0.1000   -0.0007
##      9        0.9542             nan     0.1000   -0.0003
##     10        0.9528             nan     0.1000    0.0008
##     20        0.9246             nan     0.1000   -0.0055
##     40        0.8851             nan     0.1000   -0.0048
##     60        0.8392             nan     0.1000   -0.0040
##     80        0.8142             nan     0.1000   -0.0035
##    100        0.7877             nan     0.1000   -0.0020
##    120        0.7680             nan     0.1000   -0.0004
##    140        0.7424             nan     0.1000   -0.0002
##    150        0.7334             nan     0.1000   -0.0043
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0094             nan     0.1000   -0.0001
##      2        0.9974             nan     0.1000   -0.0004
##      3        0.9944             nan     0.1000    0.0005
##      4        0.9910             nan     0.1000    0.0014
##      5        0.9807             nan     0.1000   -0.0016
##      6        0.9707             nan     0.1000   -0.0046
##      7        0.9618             nan     0.1000   -0.0022
##      8        0.9540             nan     0.1000   -0.0017
##      9        0.9526             nan     0.1000    0.0000
##     10        0.9439             nan     0.1000   -0.0027
##     20        0.8726             nan     0.1000   -0.0013
##     40        0.8306             nan     0.1000   -0.0011
##     60        0.7628             nan     0.1000   -0.0004
##     80        0.7149             nan     0.1000   -0.0028
##    100        0.6798             nan     0.1000   -0.0021
##    120        0.6460             nan     0.1000   -0.0009
##    140        0.6021             nan     0.1000   -0.0014
##    150        0.5813             nan     0.1000   -0.0004
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        0.5141             nan     0.1000    0.0011
##      2        0.5134             nan     0.1000   -0.0000
##      3        0.5125             nan     0.1000    0.0001
##      4        0.5111             nan     0.1000    0.0012
##      5        0.5102             nan     0.1000    0.0006
##      6        0.5091             nan     0.1000    0.0008
##      7        0.5083             nan     0.1000    0.0007
##      8        0.5077             nan     0.1000   -0.0001
##      9        0.5067             nan     0.1000    0.0001
##     10        0.5061             nan     0.1000    0.0006
##     20        0.5014             nan     0.1000    0.0004
##     40        0.4948             nan     0.1000   -0.0001
##     60        0.4920             nan     0.1000   -0.0004
##     80        0.4902             nan     0.1000   -0.0006
##    100        0.4884             nan     0.1000   -0.0004
##    120        0.4870             nan     0.1000   -0.0000
##    140        0.4853             nan     0.1000   -0.0003
##    150        0.4847             nan     0.1000   -0.0002
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        0.5124             nan     0.1000    0.0019
##      2        0.5100             nan     0.1000    0.0014
##      3        0.5081             nan     0.1000    0.0011
##      4        0.5060             nan     0.1000    0.0016
##      5        0.5049             nan     0.1000    0.0007
##      6        0.5032             nan     0.1000    0.0005
##      7        0.5017             nan     0.1000   -0.0001
##      8        0.5007             nan     0.1000    0.0001
##      9        0.4997             nan     0.1000    0.0003
##     10        0.4980             nan     0.1000   -0.0002
##     20        0.4871             nan     0.1000    0.0000
##     40        0.4709             nan     0.1000   -0.0004
##     60        0.4628             nan     0.1000   -0.0008
##     80        0.4564             nan     0.1000    0.0002
##    100        0.4509             nan     0.1000   -0.0005
##    120        0.4464             nan     0.1000   -0.0007
##    140        0.4415             nan     0.1000   -0.0004
##    150        0.4393             nan     0.1000   -0.0003
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        0.5115             nan     0.1000   -0.0006
##      2        0.5087             nan     0.1000   -0.0005
##      3        0.5042             nan     0.1000    0.0012
##      4        0.5000             nan     0.1000   -0.0002
##      5        0.4968             nan     0.1000    0.0005
##      6        0.4947             nan     0.1000   -0.0001
##      7        0.4926             nan     0.1000   -0.0003
##      8        0.4899             nan     0.1000    0.0005
##      9        0.4867             nan     0.1000    0.0016
##     10        0.4851             nan     0.1000    0.0005
##     20        0.4700             nan     0.1000   -0.0003
##     40        0.4422             nan     0.1000   -0.0000
##     60        0.4210             nan     0.1000   -0.0005
##     80        0.4086             nan     0.1000   -0.0011
##    100        0.3989             nan     0.1000   -0.0011
##    120        0.3890             nan     0.1000   -0.0007
##    140        0.3786             nan     0.1000   -0.0008
##    150        0.3760             nan     0.1000   -0.0007
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0500             nan     0.1000    0.0006
##      2        1.0490             nan     0.1000    0.0007
##      3        1.0474             nan     0.1000   -0.0007
##      4        1.0462             nan     0.1000    0.0004
##      5        1.0449             nan     0.1000   -0.0009
##      6        1.0439             nan     0.1000   -0.0001
##      7        1.0431             nan     0.1000    0.0004
##      8        1.0424             nan     0.1000    0.0000
##      9        1.0415             nan     0.1000   -0.0011
##     10        1.0403             nan     0.1000    0.0003
##     20        1.0348             nan     0.1000    0.0002
##     40        1.0288             nan     0.1000   -0.0016
##     60        1.0226             nan     0.1000    0.0003
##     80        1.0190             nan     0.1000   -0.0011
##    100        1.0155             nan     0.1000   -0.0004
##    120        1.0137             nan     0.1000   -0.0016
##    140        1.0114             nan     0.1000   -0.0007
##    150        1.0106             nan     0.1000   -0.0003
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0497             nan     0.1000   -0.0004
##      2        1.0342             nan     0.1000   -0.0016
##      3        1.0325             nan     0.1000   -0.0016
##      4        1.0294             nan     0.1000    0.0014
##      5        1.0216             nan     0.1000   -0.0048
##      6        1.0191             nan     0.1000    0.0014
##      7        1.0170             nan     0.1000    0.0016
##      8        1.0059             nan     0.1000   -0.0019
##      9        1.0045             nan     0.1000    0.0009
##     10        0.9948             nan     0.1000   -0.0015
##     20        0.9691             nan     0.1000    0.0000
##     40        0.8997             nan     0.1000   -0.0055
##     60        0.8685             nan     0.1000   -0.0041
##     80        0.8363             nan     0.1000   -0.0031
##    100        0.8235             nan     0.1000   -0.0053
##    120        0.8034             nan     0.1000   -0.0054
##    140        0.7847             nan     0.1000   -0.0024
##    150        0.7769             nan     0.1000   -0.0028
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0389             nan     0.1000   -0.0005
##      2        1.0236             nan     0.1000   -0.0025
##      3        1.0207             nan     0.1000   -0.0000
##      4        1.0078             nan     0.1000    0.0001
##      5        0.9968             nan     0.1000   -0.0013
##      6        0.9862             nan     0.1000   -0.0010
##      7        0.9811             nan     0.1000    0.0008
##      8        0.9704             nan     0.1000    0.0006
##      9        0.9625             nan     0.1000   -0.0014
##     10        0.9603             nan     0.1000    0.0008
##     20        0.9082             nan     0.1000   -0.0010
##     40        0.8380             nan     0.1000   -0.0038
##     60        0.8147             nan     0.1000   -0.0009
##     80        0.7562             nan     0.1000   -0.0041
##    100        0.7133             nan     0.1000   -0.0008
##    120        0.6934             nan     0.1000   -0.0078
##    140        0.6589             nan     0.1000   -0.0038
##    150        0.6433             nan     0.1000   -0.0031
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0626             nan     0.1000   -0.0005
##      2        1.0617             nan     0.1000    0.0009
##      3        1.0607             nan     0.1000    0.0001
##      4        1.0592             nan     0.1000    0.0004
##      5        1.0587             nan     0.1000   -0.0001
##      6        1.0575             nan     0.1000   -0.0011
##      7        1.0570             nan     0.1000   -0.0000
##      8        1.0556             nan     0.1000    0.0004
##      9        1.0547             nan     0.1000    0.0005
##     10        1.0538             nan     0.1000   -0.0002
##     20        1.0478             nan     0.1000   -0.0000
##     40        1.0420             nan     0.1000   -0.0019
##     60        1.0351             nan     0.1000   -0.0001
##     80        1.0320             nan     0.1000   -0.0016
##    100        1.0277             nan     0.1000    0.0003
##    120        1.0269             nan     0.1000   -0.0004
##    140        1.0251             nan     0.1000   -0.0011
##    150        1.0226             nan     0.1000   -0.0005
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0499             nan     0.1000   -0.0016
##      2        1.0397             nan     0.1000   -0.0034
##      3        1.0375             nan     0.1000   -0.0007
##      4        1.0273             nan     0.1000    0.0003
##      5        1.0246             nan     0.1000    0.0012
##      6        1.0155             nan     0.1000   -0.0066
##      7        1.0145             nan     0.1000   -0.0001
##      8        1.0050             nan     0.1000   -0.0010
##      9        0.9957             nan     0.1000   -0.0006
##     10        0.9896             nan     0.1000   -0.0034
##     20        0.9612             nan     0.1000    0.0003
##     40        0.9200             nan     0.1000    0.0002
##     60        0.8669             nan     0.1000   -0.0005
##     80        0.8329             nan     0.1000    0.0002
##    100        0.8058             nan     0.1000   -0.0020
##    120        0.7888             nan     0.1000   -0.0008
##    140        0.7773             nan     0.1000   -0.0017
##    150        0.7644             nan     0.1000   -0.0030
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0546             nan     0.1000    0.0013
##      2        1.0522             nan     0.1000   -0.0002
##      3        1.0473             nan     0.1000    0.0009
##      4        1.0356             nan     0.1000   -0.0032
##      5        1.0180             nan     0.1000   -0.0026
##      6        1.0160             nan     0.1000   -0.0005
##      7        1.0061             nan     0.1000   -0.0005
##      8        1.0035             nan     0.1000    0.0012
##      9        0.9955             nan     0.1000   -0.0021
##     10        0.9864             nan     0.1000   -0.0060
##     20        0.9434             nan     0.1000   -0.0001
##     40        0.8547             nan     0.1000   -0.0052
##     60        0.8084             nan     0.1000   -0.0021
##     80        0.7852             nan     0.1000   -0.0037
##    100        0.7453             nan     0.1000   -0.0032
##    120        0.6977             nan     0.1000   -0.0021
##    140        0.6633             nan     0.1000   -0.0012
##    150        0.6517             nan     0.1000   -0.0038
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0191             nan     0.1000    0.0008
##      2        1.0182             nan     0.1000    0.0006
##      3        1.0172             nan     0.1000    0.0010
##      4        1.0161             nan     0.1000   -0.0000
##      5        1.0146             nan     0.1000    0.0002
##      6        1.0130             nan     0.1000    0.0004
##      7        1.0123             nan     0.1000    0.0000
##      8        1.0118             nan     0.1000   -0.0002
##      9        1.0107             nan     0.1000   -0.0004
##     10        1.0103             nan     0.1000   -0.0001
##     20        1.0018             nan     0.1000   -0.0001
##     40        0.9949             nan     0.1000   -0.0010
##     60        0.9913             nan     0.1000    0.0005
##     80        0.9870             nan     0.1000    0.0006
##    100        0.9842             nan     0.1000   -0.0007
##    120        0.9817             nan     0.1000   -0.0009
##    140        0.9809             nan     0.1000   -0.0005
##    150        0.9807             nan     0.1000   -0.0010
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0181             nan     0.1000    0.0011
##      2        1.0163             nan     0.1000    0.0018
##      3        1.0143             nan     0.1000   -0.0001
##      4        1.0026             nan     0.1000   -0.0020
##      5        0.9940             nan     0.1000   -0.0007
##      6        0.9914             nan     0.1000   -0.0002
##      7        0.9810             nan     0.1000   -0.0014
##      8        0.9800             nan     0.1000    0.0003
##      9        0.9784             nan     0.1000    0.0011
##     10        0.9695             nan     0.1000   -0.0009
##     20        0.9292             nan     0.1000   -0.0005
##     40        0.8746             nan     0.1000   -0.0008
##     60        0.8533             nan     0.1000   -0.0038
##     80        0.8330             nan     0.1000   -0.0003
##    100        0.7942             nan     0.1000   -0.0056
##    120        0.7830             nan     0.1000   -0.0004
##    140        0.7657             nan     0.1000   -0.0017
##    150        0.7636             nan     0.1000   -0.0013
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0069             nan     0.1000   -0.0013
##      2        0.9994             nan     0.1000   -0.0005
##      3        0.9946             nan     0.1000    0.0002
##      4        0.9920             nan     0.1000   -0.0005
##      5        0.9811             nan     0.1000   -0.0009
##      6        0.9770             nan     0.1000    0.0014
##      7        0.9751             nan     0.1000   -0.0000
##      8        0.9654             nan     0.1000   -0.0012
##      9        0.9557             nan     0.1000   -0.0014
##     10        0.9472             nan     0.1000   -0.0045
##     20        0.9172             nan     0.1000    0.0001
##     40        0.8589             nan     0.1000   -0.0024
##     60        0.8103             nan     0.1000   -0.0032
##     80        0.7940             nan     0.1000   -0.0012
##    100        0.7390             nan     0.1000   -0.0041
##    120        0.6981             nan     0.1000   -0.0053
##    140        0.6853             nan     0.1000   -0.0013
##    150        0.6714             nan     0.1000   -0.0028
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0782             nan     0.1000    0.0018
##      2        1.0765             nan     0.1000    0.0005
##      3        1.0751             nan     0.1000    0.0001
##      4        1.0746             nan     0.1000   -0.0001
##      5        1.0728             nan     0.1000   -0.0008
##      6        1.0723             nan     0.1000    0.0002
##      7        1.0715             nan     0.1000    0.0003
##      8        1.0702             nan     0.1000   -0.0010
##      9        1.0695             nan     0.1000    0.0004
##     10        1.0688             nan     0.1000    0.0002
##     20        1.0624             nan     0.1000   -0.0019
##     40        1.0555             nan     0.1000   -0.0000
##     60        1.0501             nan     0.1000   -0.0008
##     80        1.0482             nan     0.1000   -0.0014
##    100        1.0453             nan     0.1000   -0.0007
##    120        1.0435             nan     0.1000   -0.0004
##    140        1.0412             nan     0.1000   -0.0014
##    150        1.0406             nan     0.1000   -0.0016
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0775             nan     0.1000    0.0011
##      2        1.0666             nan     0.1000   -0.0010
##      3        1.0648             nan     0.1000   -0.0000
##      4        1.0613             nan     0.1000    0.0016
##      5        1.0600             nan     0.1000    0.0002
##      6        1.0499             nan     0.1000   -0.0013
##      7        1.0483             nan     0.1000    0.0001
##      8        1.0477             nan     0.1000   -0.0002
##      9        1.0412             nan     0.1000    0.0002
##     10        1.0403             nan     0.1000   -0.0002
##     20        0.9881             nan     0.1000   -0.0001
##     40        0.9161             nan     0.1000   -0.0099
##     60        0.8807             nan     0.1000   -0.0038
##     80        0.8625             nan     0.1000   -0.0068
##    100        0.8370             nan     0.1000   -0.0024
##    120        0.8182             nan     0.1000   -0.0051
##    140        0.8048             nan     0.1000   -0.0075
##    150        0.7958             nan     0.1000    0.0003
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0680             nan     0.1000   -0.0008
##      2        1.0552             nan     0.1000   -0.0006
##      3        1.0533             nan     0.1000    0.0003
##      4        1.0389             nan     0.1000   -0.0014
##      5        1.0371             nan     0.1000    0.0001
##      6        1.0346             nan     0.1000   -0.0000
##      7        1.0324             nan     0.1000   -0.0002
##      8        1.0297             nan     0.1000    0.0002
##      9        1.0202             nan     0.1000   -0.0004
##     10        1.0106             nan     0.1000   -0.0007
##     20        0.9734             nan     0.1000   -0.0002
##     40        0.8969             nan     0.1000   -0.0019
##     60        0.8546             nan     0.1000   -0.0033
##     80        0.8097             nan     0.1000   -0.0055
##    100        0.7598             nan     0.1000   -0.0030
##    120        0.7238             nan     0.1000   -0.0043
##    140        0.7002             nan     0.1000   -0.0020
##    150        0.6893             nan     0.1000   -0.0031
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0565             nan     0.1000    0.0009
##      2        1.0547             nan     0.1000    0.0006
##      3        1.0537             nan     0.1000   -0.0001
##      4        1.0518             nan     0.1000   -0.0006
##      5        1.0511             nan     0.1000    0.0004
##      6        1.0505             nan     0.1000    0.0002
##      7        1.0498             nan     0.1000    0.0003
##      8        1.0493             nan     0.1000    0.0003
##      9        1.0481             nan     0.1000   -0.0010
##     10        1.0476             nan     0.1000   -0.0001
##     20        1.0412             nan     0.1000    0.0005
##     40        1.0327             nan     0.1000   -0.0002
##     60        1.0273             nan     0.1000   -0.0014
##     80        1.0235             nan     0.1000   -0.0012
##    100        1.0202             nan     0.1000   -0.0002
##    120        1.0179             nan     0.1000   -0.0013
##    140        1.0158             nan     0.1000   -0.0009
##    150        1.0157             nan     0.1000   -0.0008
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0549             nan     0.1000    0.0007
##      2        1.0534             nan     0.1000    0.0006
##      3        1.0400             nan     0.1000   -0.0010
##      4        1.0296             nan     0.1000   -0.0013
##      5        1.0231             nan     0.1000   -0.0004
##      6        1.0121             nan     0.1000   -0.0041
##      7        1.0036             nan     0.1000   -0.0018
##      8        0.9936             nan     0.1000   -0.0023
##      9        0.9866             nan     0.1000   -0.0001
##     10        0.9759             nan     0.1000   -0.0014
##     20        0.9380             nan     0.1000   -0.0083
##     40        0.9101             nan     0.1000   -0.0077
##     60        0.8785             nan     0.1000   -0.0005
##     80        0.8611             nan     0.1000   -0.0013
##    100        0.8339             nan     0.1000   -0.0078
##    120        0.8093             nan     0.1000   -0.0014
##    140        0.8006             nan     0.1000   -0.0047
##    150        0.7871             nan     0.1000   -0.0028
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0543             nan     0.1000    0.0016
##      2        1.0519             nan     0.1000    0.0010
##      3        1.0497             nan     0.1000    0.0009
##      4        1.0451             nan     0.1000   -0.0001
##      5        1.0409             nan     0.1000    0.0002
##      6        1.0394             nan     0.1000   -0.0004
##      7        1.0378             nan     0.1000   -0.0002
##      8        1.0363             nan     0.1000   -0.0002
##      9        1.0201             nan     0.1000   -0.0019
##     10        1.0175             nan     0.1000   -0.0006
##     20        0.9691             nan     0.1000   -0.0069
##     40        0.8730             nan     0.1000    0.0005
##     60        0.8209             nan     0.1000   -0.0032
##     80        0.7927             nan     0.1000   -0.0029
##    100        0.7481             nan     0.1000   -0.0029
##    120        0.7191             nan     0.1000   -0.0009
##    140        0.6974             nan     0.1000    0.0002
##    150        0.6803             nan     0.1000   -0.0045
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0099             nan     0.1000    0.0008
##      2        1.0084             nan     0.1000   -0.0003
##      3        1.0072             nan     0.1000   -0.0010
##      4        1.0065             nan     0.1000    0.0004
##      5        1.0056             nan     0.1000   -0.0016
##      6        1.0049             nan     0.1000    0.0003
##      7        1.0036             nan     0.1000   -0.0003
##      8        1.0026             nan     0.1000   -0.0006
##      9        1.0021             nan     0.1000   -0.0010
##     10        1.0014             nan     0.1000   -0.0009
##     20        0.9926             nan     0.1000   -0.0001
##     40        0.9863             nan     0.1000   -0.0003
##     60        0.9823             nan     0.1000   -0.0011
##     80        0.9796             nan     0.1000   -0.0006
##    100        0.9788             nan     0.1000   -0.0009
##    120        0.9763             nan     0.1000   -0.0010
##    140        0.9754             nan     0.1000   -0.0012
##    150        0.9756             nan     0.1000   -0.0016
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0083             nan     0.1000    0.0004
##      2        1.0021             nan     0.1000   -0.0002
##      3        1.0009             nan     0.1000    0.0006
##      4        0.9905             nan     0.1000   -0.0022
##      5        0.9806             nan     0.1000   -0.0012
##      6        0.9795             nan     0.1000   -0.0002
##      7        0.9699             nan     0.1000    0.0036
##      8        0.9612             nan     0.1000   -0.0021
##      9        0.9539             nan     0.1000   -0.0025
##     10        0.9447             nan     0.1000   -0.0011
##     20        0.9015             nan     0.1000   -0.0067
##     40        0.8591             nan     0.1000   -0.0016
##     60        0.8294             nan     0.1000   -0.0037
##     80        0.7958             nan     0.1000   -0.0028
##    100        0.7737             nan     0.1000   -0.0050
##    120        0.7687             nan     0.1000   -0.0027
##    140        0.7504             nan     0.1000   -0.0005
##    150        0.7440             nan     0.1000   -0.0039
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        0.9980             nan     0.1000    0.0001
##      2        0.9942             nan     0.1000   -0.0003
##      3        0.9925             nan     0.1000    0.0001
##      4        0.9903             nan     0.1000    0.0010
##      5        0.9793             nan     0.1000   -0.0005
##      6        0.9694             nan     0.1000   -0.0009
##      7        0.9671             nan     0.1000    0.0011
##      8        0.9555             nan     0.1000   -0.0064
##      9        0.9525             nan     0.1000   -0.0005
##     10        0.9504             nan     0.1000   -0.0000
##     20        0.9136             nan     0.1000   -0.0063
##     40        0.8417             nan     0.1000   -0.0051
##     60        0.8119             nan     0.1000   -0.0029
##     80        0.7769             nan     0.1000   -0.0034
##    100        0.7108             nan     0.1000   -0.0016
##    120        0.6677             nan     0.1000   -0.0036
##    140        0.6365             nan     0.1000   -0.0007
##    150        0.6258             nan     0.1000   -0.0021
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0914             nan     0.1000   -0.0005
##      2        1.0890             nan     0.1000    0.0014
##      3        1.0876             nan     0.1000    0.0002
##      4        1.0868             nan     0.1000    0.0001
##      5        1.0854             nan     0.1000    0.0004
##      6        1.0848             nan     0.1000   -0.0000
##      7        1.0843             nan     0.1000   -0.0004
##      8        1.0835             nan     0.1000    0.0002
##      9        1.0828             nan     0.1000   -0.0002
##     10        1.0812             nan     0.1000    0.0006
##     20        1.0728             nan     0.1000   -0.0015
##     40        1.0657             nan     0.1000   -0.0017
##     60        1.0612             nan     0.1000    0.0009
##     80        1.0569             nan     0.1000   -0.0012
##    100        1.0541             nan     0.1000   -0.0007
##    120        1.0530             nan     0.1000   -0.0012
##    140        1.0516             nan     0.1000   -0.0007
##    150        1.0510             nan     0.1000   -0.0006
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0821             nan     0.1000   -0.0025
##      2        1.0733             nan     0.1000   -0.0008
##      3        1.0706             nan     0.1000    0.0013
##      4        1.0606             nan     0.1000   -0.0013
##      5        1.0577             nan     0.1000    0.0005
##      6        1.0556             nan     0.1000    0.0005
##      7        1.0463             nan     0.1000   -0.0007
##      8        1.0447             nan     0.1000   -0.0003
##      9        1.0332             nan     0.1000   -0.0060
##     10        1.0319             nan     0.1000    0.0004
##     20        0.9830             nan     0.1000   -0.0007
##     40        0.9358             nan     0.1000   -0.0014
##     60        0.9035             nan     0.1000   -0.0028
##     80        0.8728             nan     0.1000   -0.0073
##    100        0.8519             nan     0.1000   -0.0024
##    120        0.8348             nan     0.1000   -0.0022
##    140        0.8191             nan     0.1000   -0.0018
##    150        0.8197             nan     0.1000   -0.0005
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0797             nan     0.1000    0.0002
##      2        1.0753             nan     0.1000    0.0031
##      3        1.0683             nan     0.1000   -0.0011
##      4        1.0653             nan     0.1000    0.0005
##      5        1.0633             nan     0.1000    0.0005
##      6        1.0612             nan     0.1000    0.0002
##      7        1.0594             nan     0.1000   -0.0002
##      8        1.0562             nan     0.1000    0.0004
##      9        1.0436             nan     0.1000   -0.0008
##     10        1.0415             nan     0.1000   -0.0000
##     20        1.0035             nan     0.1000   -0.0054
##     40        0.9312             nan     0.1000   -0.0048
##     60        0.8919             nan     0.1000   -0.0015
##     80        0.8408             nan     0.1000   -0.0039
##    100        0.7804             nan     0.1000   -0.0047
##    120        0.7543             nan     0.1000   -0.0031
##    140        0.7308             nan     0.1000   -0.0039
##    150        0.7232             nan     0.1000   -0.0003
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        0.9988             nan     0.1000    0.0010
##      2        0.9975             nan     0.1000    0.0001
##      3        0.9964             nan     0.1000    0.0006
##      4        0.9954             nan     0.1000   -0.0007
##      5        0.9944             nan     0.1000    0.0002
##      6        0.9933             nan     0.1000   -0.0005
##      7        0.9917             nan     0.1000    0.0004
##      8        0.9906             nan     0.1000    0.0001
##      9        0.9894             nan     0.1000    0.0004
##     10        0.9888             nan     0.1000    0.0001
##     20        0.9832             nan     0.1000   -0.0001
##     40        0.9767             nan     0.1000   -0.0003
##     50        0.9746             nan     0.1000   -0.0008

gbmFit

## Stochastic Gradient Boosting 
## 
## 4664 samples
##   37 predictor
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 4199, 4198, 4197, 4198, 4197, 4198, ... 
## Resampling results across tuning parameters:
## 
##   interaction.depth  n.trees  RMSE       Rsquared     MAE      
##   1                   50      0.8504771  0.013003609  0.2629133
##   1                  100      0.8509822  0.015723635  0.2622797
##   1                  150      0.8529123  0.014518025  0.2626208
##   2                   50      0.8773335  0.005365322  0.2704992
##   2                  100      0.8991825  0.005294142  0.2860585
##   2                  150      0.9037200  0.006089261  0.2906115
##   3                   50      0.8756815  0.010855112  0.2724991
##   3                  100      0.8974778  0.009220545  0.2861893
##   3                  150      0.9118208  0.008551262  0.2958861
## 
## Tuning parameter &#39;shrinkage&#39; was held constant at a value of 0.1
## Tuning parameter &#39;n.minobsinnode&#39; was held constant at a value
##  of 10
## RMSE was used to select the optimal model using the smallest value.
## The final values used for the model were n.trees = 50, interaction.depth = 1, shrinkage = 0.1 and n.minobsinnode = 10.

# create the prediction
pred2 &lt;- predict(gbmFit, newdata = newsPopTest)

# compare the prediction vs the actual
resample2 &lt;- postResample(pred2, obs = newsPopTest$shares)
resample2

##       RMSE   Rsquared        MAE 
## 1.17615643 0.01156287 0.25556953</code></pre>
<h3 id="linear-regression-model">Linear Regression Model</h3>
<p>Linear regression is used to predict the outcome of a response variable for 1 to n predictors. The aim is to establish a linear relationship between the predictor variable(s) and response variable so we can predict the value of the response when only the predictor variable(s) is(are) known.</p>
<pre><code># train the linear model for main effects + interactions on first 3 preds
lmFit &lt;- train(shares ~ timedelta*n_tokens_title*n_tokens_content, data = newsPopTrain,
                                                                   method = &quot;lm&quot;, preProces = c(&quot;center&quot;, &quot;scale&quot;),
                                                                   trControl = trainControl(method = &quot;cv&quot;, number = 10))
lmFit

## Linear Regression 
## 
## 4664 samples
##    3 predictor
## 
## Pre-processing: centered (7), scaled (7) 
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 4198, 4197, 4198, 4198, 4199, 4197, ... 
## Resampling results:
## 
##   RMSE       Rsquared     MAE      
##   0.8580445  0.001270155  0.2683756
## 
## Tuning parameter &#39;intercept&#39; was held constant at a value of TRUE

# create the prediction
pred3 &lt;- predict(lmFit, newdata = newsPopTest)

# compare the prediction vs the actual
resample3 &lt;- postResample(pred3, obs = newsPopTest$shares)
resample3

##         RMSE     Rsquared          MAE 
## 1.1830460871 0.0002752878 0.2651960249</code></pre>
<h3 id="comparison">Comparison</h3>
<p>Below is a comparison of the three methods. All have relatively high root mean square errors.</p>
<pre><code># compare results from 3 methods
comparison &lt;- data.frame(&quot;RSME&quot; = c(resample1[[1]], resample2[[1]], resample3[1]), &quot;MAE&quot; = c(resample1[[3]], resample2[[3]], resample3[[3]]))
rownames(comparison) &lt;- c(&quot;RPART&quot;,&quot;GBM&quot;, &quot;LM&quot;)
kable(comparison)</code></pre>
<table>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
RSME
</th>
<th style="text-align:right;">
MAE
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
RPART
</td>
<td style="text-align:right;">
1.182990
</td>
<td style="text-align:right;">
0.2640217
</td>
</tr>
<tr>
<td style="text-align:left;">
GBM
</td>
<td style="text-align:right;">
1.176156
</td>
<td style="text-align:right;">
0.2555695
</td>
</tr>
<tr>
<td style="text-align:left;">
LM
</td>
<td style="text-align:right;">
1.183046
</td>
<td style="text-align:right;">
0.2651960
</td>
</tr>
</tbody>
</table>

</body>
</html>
