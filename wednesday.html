<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1">

<style type="text/css">
@font-face {
font-family: octicons-link;
src: url(data:font/woff;charset=utf-8;base64,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) format('woff');
}
body {
-webkit-text-size-adjust: 100%;
text-size-adjust: 100%;
color: #333;
font-family: "Helvetica Neue", Helvetica, "Segoe UI", Arial, freesans, sans-serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol";
font-size: 16px;
line-height: 1.6;
word-wrap: break-word;
}
a {
background-color: transparent;
}
a:active,
a:hover {
outline: 0;
}
strong {
font-weight: bold;
}
h1 {
font-size: 2em;
margin: 0.67em 0;
}
img {
border: 0;
}
hr {
box-sizing: content-box;
height: 0;
}
pre {
overflow: auto;
}
code,
kbd,
pre {
font-family: monospace, monospace;
font-size: 1em;
}
input {
color: inherit;
font: inherit;
margin: 0;
}
html input[disabled] {
cursor: default;
}
input {
line-height: normal;
}
input[type="checkbox"] {
box-sizing: border-box;
padding: 0;
}
table {
border-collapse: collapse;
border-spacing: 0;
}
td,
th {
padding: 0;
}
* {
box-sizing: border-box;
}
input {
font: 13px / 1.4 Helvetica, arial, nimbussansl, liberationsans, freesans, clean, sans-serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol";
}
a {
color: #4078c0;
text-decoration: none;
}
a:hover,
a:active {
text-decoration: underline;
}
hr {
height: 0;
margin: 15px 0;
overflow: hidden;
background: transparent;
border: 0;
border-bottom: 1px solid #ddd;
}
hr:before {
display: table;
content: "";
}
hr:after {
display: table;
clear: both;
content: "";
}
h1,
h2,
h3,
h4,
h5,
h6 {
margin-top: 15px;
margin-bottom: 15px;
line-height: 1.1;
}
h1 {
font-size: 30px;
}
h2 {
font-size: 21px;
}
h3 {
font-size: 16px;
}
h4 {
font-size: 14px;
}
h5 {
font-size: 12px;
}
h6 {
font-size: 11px;
}
blockquote {
margin: 0;
}
ul,
ol {
padding: 0;
margin-top: 0;
margin-bottom: 0;
}
ol ol,
ul ol {
list-style-type: lower-roman;
}
ul ul ol,
ul ol ol,
ol ul ol,
ol ol ol {
list-style-type: lower-alpha;
}
dd {
margin-left: 0;
}
code {
font-family: Consolas, "Liberation Mono", Menlo, Courier, monospace;
font-size: 12px;
}
pre {
margin-top: 0;
margin-bottom: 0;
font: 12px Consolas, "Liberation Mono", Menlo, Courier, monospace;
}
.select::-ms-expand {
opacity: 0;
}
.octicon {
font: normal normal normal 16px/1 octicons-link;
display: inline-block;
text-decoration: none;
text-rendering: auto;
-webkit-font-smoothing: antialiased;
-moz-osx-font-smoothing: grayscale;
-webkit-user-select: none;
-moz-user-select: none;
-ms-user-select: none;
user-select: none;
}
.octicon-link:before {
content: '\f05c';
}
.markdown-body:before {
display: table;
content: "";
}
.markdown-body:after {
display: table;
clear: both;
content: "";
}
.markdown-body>*:first-child {
margin-top: 0 !important;
}
.markdown-body>*:last-child {
margin-bottom: 0 !important;
}
a:not([href]) {
color: inherit;
text-decoration: none;
}
.anchor {
display: inline-block;
padding-right: 2px;
margin-left: -18px;
}
.anchor:focus {
outline: none;
}
h1,
h2,
h3,
h4,
h5,
h6 {
margin-top: 1em;
margin-bottom: 16px;
font-weight: bold;
line-height: 1.4;
}
h1 .octicon-link,
h2 .octicon-link,
h3 .octicon-link,
h4 .octicon-link,
h5 .octicon-link,
h6 .octicon-link {
color: #000;
vertical-align: middle;
visibility: hidden;
}
h1:hover .anchor,
h2:hover .anchor,
h3:hover .anchor,
h4:hover .anchor,
h5:hover .anchor,
h6:hover .anchor {
text-decoration: none;
}
h1:hover .anchor .octicon-link,
h2:hover .anchor .octicon-link,
h3:hover .anchor .octicon-link,
h4:hover .anchor .octicon-link,
h5:hover .anchor .octicon-link,
h6:hover .anchor .octicon-link {
visibility: visible;
}
h1 {
padding-bottom: 0.3em;
font-size: 2.25em;
line-height: 1.2;
border-bottom: 1px solid #eee;
}
h1 .anchor {
line-height: 1;
}
h2 {
padding-bottom: 0.3em;
font-size: 1.75em;
line-height: 1.225;
border-bottom: 1px solid #eee;
}
h2 .anchor {
line-height: 1;
}
h3 {
font-size: 1.5em;
line-height: 1.43;
}
h3 .anchor {
line-height: 1.2;
}
h4 {
font-size: 1.25em;
}
h4 .anchor {
line-height: 1.2;
}
h5 {
font-size: 1em;
}
h5 .anchor {
line-height: 1.1;
}
h6 {
font-size: 1em;
color: #777;
}
h6 .anchor {
line-height: 1.1;
}
p,
blockquote,
ul,
ol,
dl,
table,
pre {
margin-top: 0;
margin-bottom: 16px;
}
hr {
height: 4px;
padding: 0;
margin: 16px 0;
background-color: #e7e7e7;
border: 0 none;
}
ul,
ol {
padding-left: 2em;
}
ul ul,
ul ol,
ol ol,
ol ul {
margin-top: 0;
margin-bottom: 0;
}
li>p {
margin-top: 16px;
}
dl {
padding: 0;
}
dl dt {
padding: 0;
margin-top: 16px;
font-size: 1em;
font-style: italic;
font-weight: bold;
}
dl dd {
padding: 0 16px;
margin-bottom: 16px;
}
blockquote {
padding: 0 15px;
color: #777;
border-left: 4px solid #ddd;
}
blockquote>:first-child {
margin-top: 0;
}
blockquote>:last-child {
margin-bottom: 0;
}
table {
display: block;
width: 100%;
overflow: auto;
word-break: normal;
word-break: keep-all;
}
table th {
font-weight: bold;
}
table th,
table td {
padding: 6px 13px;
border: 1px solid #ddd;
}
table tr {
background-color: #fff;
border-top: 1px solid #ccc;
}
table tr:nth-child(2n) {
background-color: #f8f8f8;
}
img {
max-width: 100%;
box-sizing: content-box;
background-color: #fff;
}
code {
padding: 0;
padding-top: 0.2em;
padding-bottom: 0.2em;
margin: 0;
font-size: 85%;
background-color: rgba(0,0,0,0.04);
border-radius: 3px;
}
code:before,
code:after {
letter-spacing: -0.2em;
content: "\00a0";
}
pre>code {
padding: 0;
margin: 0;
font-size: 100%;
word-break: normal;
white-space: pre;
background: transparent;
border: 0;
}
.highlight {
margin-bottom: 16px;
}
.highlight pre,
pre {
padding: 16px;
overflow: auto;
font-size: 85%;
line-height: 1.45;
background-color: #f7f7f7;
border-radius: 3px;
}
.highlight pre {
margin-bottom: 0;
word-break: normal;
}
pre {
word-wrap: normal;
}
pre code {
display: inline;
max-width: initial;
padding: 0;
margin: 0;
overflow: initial;
line-height: inherit;
word-wrap: normal;
background-color: transparent;
border: 0;
}
pre code:before,
pre code:after {
content: normal;
}
kbd {
display: inline-block;
padding: 3px 5px;
font-size: 11px;
line-height: 10px;
color: #555;
vertical-align: middle;
background-color: #fcfcfc;
border: solid 1px #ccc;
border-bottom-color: #bbb;
border-radius: 3px;
box-shadow: inset 0 -1px 0 #bbb;
}
.pl-c {
color: #969896;
}
.pl-c1,
.pl-s .pl-v {
color: #0086b3;
}
.pl-e,
.pl-en {
color: #795da3;
}
.pl-s .pl-s1,
.pl-smi {
color: #333;
}
.pl-ent {
color: #63a35c;
}
.pl-k {
color: #a71d5d;
}
.pl-pds,
.pl-s,
.pl-s .pl-pse .pl-s1,
.pl-sr,
.pl-sr .pl-cce,
.pl-sr .pl-sra,
.pl-sr .pl-sre {
color: #183691;
}
.pl-v {
color: #ed6a43;
}
.pl-id {
color: #b52a1d;
}
.pl-ii {
background-color: #b52a1d;
color: #f8f8f8;
}
.pl-sr .pl-cce {
color: #63a35c;
font-weight: bold;
}
.pl-ml {
color: #693a17;
}
.pl-mh,
.pl-mh .pl-en,
.pl-ms {
color: #1d3e81;
font-weight: bold;
}
.pl-mq {
color: #008080;
}
.pl-mi {
color: #333;
font-style: italic;
}
.pl-mb {
color: #333;
font-weight: bold;
}
.pl-md {
background-color: #ffecec;
color: #bd2c00;
}
.pl-mi1 {
background-color: #eaffea;
color: #55a532;
}
.pl-mdr {
color: #795da3;
font-weight: bold;
}
.pl-mo {
color: #1d3e81;
}
kbd {
display: inline-block;
padding: 3px 5px;
font: 11px Consolas, "Liberation Mono", Menlo, Courier, monospace;
line-height: 10px;
color: #555;
vertical-align: middle;
background-color: #fcfcfc;
border: solid 1px #ccc;
border-bottom-color: #bbb;
border-radius: 3px;
box-shadow: inset 0 -1px 0 #bbb;
}
.task-list-item {
list-style-type: none;
}
.task-list-item+.task-list-item {
margin-top: 3px;
}
.task-list-item input {
margin: 0 0.35em 0.25em -1.6em;
vertical-align: middle;
}
:checked+.radio-label {
z-index: 1;
position: relative;
border-color: #4078c0;
}
.sourceLine {
display: inline-block;
}
code .kw { color: #000000; }
code .dt { color: #ed6a43; }
code .dv { color: #009999; }
code .bn { color: #009999; }
code .fl { color: #009999; }
code .ch { color: #009999; }
code .st { color: #183691; }
code .co { color: #969896; }
code .ot { color: #0086b3; }
code .al { color: #a61717; }
code .fu { color: #63a35c; }
code .er { color: #a61717; background-color: #e3d2d2; }
code .wa { color: #000000; }
code .cn { color: #008080; }
code .sc { color: #008080; }
code .vs { color: #183691; }
code .ss { color: #183691; }
code .im { color: #000000; }
code .va {color: #008080; }
code .cf { color: #000000; }
code .op { color: #000000; }
code .bu { color: #000000; }
code .ex { color: #000000; }
code .pp { color: #999999; }
code .at { color: #008080; }
code .do { color: #969896; }
code .an { color: #008080; }
code .cv { color: #008080; }
code .in { color: #008080; }
</style>
<style>
body {
  box-sizing: border-box;
  min-width: 200px;
  max-width: 980px;
  margin: 0 auto;
  padding: 45px;
  padding-top: 0px;
}
</style>

</head>

<body>

<h1 id="news-popularity-wednesday-data">News Popularity Wednesday Data</h1>
<p>Shuang Du 10/16/2020</p>
<h2 id="load-libraries">Load Libraries</h2>
<pre><code>library(readxl);
library(tidyverse);
library(caret);
library(modelr);
library(rpart);
library(kableExtra);</code></pre>
<h2 id="read-in-data">Read in Data</h2>
<pre><code>getData &lt;- function(day) {

  newsPopData &lt;- read_csv(&quot;raw_data/OnlineNewsPopularity.csv&quot;)
  
  if (day == &#39;monday&#39;) {
    newsPopData &lt;- newsPopData %&gt;% filter(weekday_is_monday == 1)
  } else if(day == &#39;tuesday&#39;) {
    newsPopData &lt;- newsPopData %&gt;% filter(weekday_is_tuesday == 1)
  } else if(day == &#39;wednesday&#39;) {
    newsPopData &lt;- newsPopData %&gt;% filter(weekday_is_wednesday == 1)
  } else if(day == &#39;thursday&#39;) {
    newsPopData &lt;- newsPopData %&gt;% filter(weekday_is_thursday == 1)
  } else if(day == &#39;friday&#39;) {
    newsPopData &lt;- newsPopData %&gt;% filter(weekday_is_friday == 1)
  } else if(day == &#39;saturday&#39;) {
    newsPopData &lt;- newsPopData %&gt;% filter(weekday_is_saturday == 1)
  } else if(day == &#39;sunday&#39;) {
    newsPopData &lt;- newsPopData %&gt;% filter(weekday_is_sunday == 1)
  } else {
    stop(&quot;Invalid date&quot;)
  }
  return(newsPopData)
}

newsPopData &lt;- getData(params$day)</code></pre>
<h2 id="set-aside-training-data">Set Aside Training Data</h2>
<pre><code>set.seed(92)
trainIndex &lt;- createDataPartition(newsPopData$shares, 
                                  p = 0.7, list = FALSE)

newsPopTrain &lt;- newsPopData[as.vector(trainIndex),];
newsPopTest &lt;- newsPopData[-as.vector(trainIndex),];</code></pre>
<h2 id="center-and-scale">Center and Scale</h2>
<pre><code>preProcValues &lt;- preProcess(newsPopTrain, method = c(&quot;center&quot;, &quot;scale&quot;))
newsPopTrain &lt;- predict(preProcValues, newsPopTrain) 
newsPopTest &lt;- predict(preProcValues, newsPopTest)</code></pre>
<h2 id="summary-of-a-few-variables">Summary of a Few Variables</h2>
<p>The plots below show a histogram of the number of shares for the given day. Scatter plots on the effect of max positive polarity, article time delta and number of videos in the article are also included.</p>
<p>As expected the histogram has a strong right tail, as seem by the summary stats which show a very high maximum and a median severals orders of magnitude lower. This is expected for because of the “viral” nature of online popularity.</p>
<pre><code>summary(newsPopTrain$shares)

##     Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
## -0.26734 -0.19394 -0.15892  0.00000 -0.04855 56.07103

g0 &lt;- ggplot(newsPopTrain, aes(x=shares))
g0 + geom_histogram(binwidth = 0.5) + ggtitle(&#39;Histogram for Number of Shares&#39;) + ylab(&#39;Number of Shares&#39;) + xlab(&#39;Shares&#39;)</code></pre>
<p><img src="data:image/png;base64,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" /><!-- --></p>
<pre><code>summary(newsPopTrain$max_positive_polarity)

##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
## -3.0402 -0.6017  0.2112  0.0000  1.0240  1.0240

g1 &lt;- ggplot(newsPopTrain, aes(x = max_positive_polarity, y = shares )) 
g1 + geom_point() + ggtitle(&#39;Scatter of Max Positive Polarity Effect&#39;) + ylab(&#39;Shares&#39;) + xlab(&#39;Max Positive Polarity&#39;)</code></pre>
<p><img src="data:image/png;base64,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" /><!-- --></p>
<pre><code>summary(newsPopTrain$timedelta)

##     Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
## -1.63207 -0.88664 -0.07638  0.00000  0.89593  1.70619

g2 &lt;- ggplot(newsPopTrain, aes(x = timedelta, y = shares )) 
g2 + geom_point() + ggtitle(&#39;Scatter of Article Age Effect&#39;) + ylab(&#39;Shares&#39;) + xlab(&#39;Time Delta&#39;)</code></pre>
<p><img src="data:image/png;base64,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" /><!-- --></p>
<pre><code>summary(newsPopTrain$num_videos)

##     Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
## -0.31360 -0.31360 -0.31360  0.00000 -0.06619 17.74741

g3 &lt;- ggplot(newsPopTrain, aes(x = num_videos, y = shares )) 
g3 + geom_point() + ggtitle(&#39;Scatter of Videos Number Effect&#39;) + ylab(&#39;Shares&#39;) + xlab(&#39;Number of Videos&#39;)</code></pre>
<p><img src="data:image/png;base64,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" /><!-- --></p>
<h2 id="modeling">Modeling</h2>
<h3 id="standard-tree-based-model-no-ensemble">Standard Tree Based Model (no ensemble)</h3>
<p>The type of model being fitted here is a decision tree. The tree splits are based on minimizing the residual sum of squares for each region.</p>
<pre><code>rpartFit &lt;- train(shares ~ timedelta + n_tokens_title + n_tokens_content + n_unique_tokens + n_non_stop_words + n_non_stop_unique_tokens
                 + num_hrefs + num_self_hrefs + num_imgs + num_videos + average_token_length + num_keywords + data_channel_is_lifestyle +
                 data_channel_is_entertainment + data_channel_is_bus + data_channel_is_socmed + data_channel_is_tech + data_channel_is_world +
                 self_reference_min_shares + self_reference_max_shares + self_reference_avg_sharess + global_subjectivity + global_sentiment_polarity
                 + global_rate_positive_words + global_rate_negative_words + rate_positive_words + rate_negative_words + avg_positive_polarity +
                  min_positive_polarity + max_positive_polarity + avg_negative_polarity + min_negative_polarity + max_negative_polarity + title_subjectivity
                 + title_sentiment_polarity + abs_title_subjectivity + abs_title_sentiment_polarity, data = newsPopTrain,
             method = &quot;rpart&quot;,
             trControl = trainControl(method = &quot;cv&quot;, number = 10),
             tuneGrid = data.frame(cp = c(.001,.01,.015,.02,.03,.04,.05,.06,.07,.08))
             )
rpartFit

## CART 
## 
## 5207 samples
##   37 predictor
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 4686, 4687, 4687, 4686, 4686, 4686, ... 
## Resampling results across tuning parameters:
## 
##   cp     RMSE       Rsquared      MAE      
##   0.001  0.8848906  0.0047158308  0.2689431
##   0.010  0.8471028  0.0009442458  0.2586998
##   0.015  0.8414431  0.0014392420  0.2580866
##   0.020  0.8406259  0.0016165696  0.2576059
##   0.030  0.8406259  0.0016165696  0.2576059
##   0.040  0.8406259  0.0016165696  0.2576059
##   0.050  0.8121741           NaN  0.2561187
##   0.060  0.8121741           NaN  0.2561187
##   0.070  0.8121741           NaN  0.2561187
##   0.080  0.8121741           NaN  0.2561187
## 
## RMSE was used to select the optimal model using the smallest value.
## The final value used for the model was cp = 0.08.

# create the prediction
pred1 &lt;- predict(rpartFit, newdata = newsPopTest)

# compare the prediction vs the actual
resample1 &lt;- postResample(pred1, obs = newsPopTest$shares)
resample1

##      RMSE  Rsquared       MAE 
## 1.6680328        NA 0.2935443</code></pre>
<h3 id="boosted-tree-based-model">Boosted Tree Based Model</h3>
<p>A boosted tree is an ensemble method which slowly approaches the tree prediction which would result from the original data. In general, an ensemble model model will have a lower RSME than a single tree model.</p>
<pre><code>gbmFit &lt;- train(shares ~ timedelta + n_tokens_title + n_tokens_content + n_unique_tokens + n_non_stop_words + n_non_stop_unique_tokens
                 + num_hrefs + num_self_hrefs + num_imgs + num_videos + average_token_length + num_keywords + data_channel_is_lifestyle +
                 data_channel_is_entertainment + data_channel_is_bus + data_channel_is_socmed + data_channel_is_tech + data_channel_is_world +
                 self_reference_min_shares + self_reference_max_shares + self_reference_avg_sharess + global_subjectivity + global_sentiment_polarity
                 + global_rate_positive_words + global_rate_negative_words + rate_positive_words + rate_negative_words + avg_positive_polarity +
                  min_positive_polarity + max_positive_polarity + avg_negative_polarity + min_negative_polarity + max_negative_polarity + title_subjectivity
                 + title_sentiment_polarity + abs_title_subjectivity + abs_title_sentiment_polarity, data = newsPopTrain,
             method = &quot;gbm&quot;,
             trControl = trainControl(method = &quot;cv&quot;, number = 10))

## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0638             nan     0.1000   -0.0016
##      2        1.0539             nan     0.1000   -0.0012
##      3        1.0529             nan     0.1000    0.0001
##      4        1.0467             nan     0.1000   -0.0065
##      5        1.0406             nan     0.1000   -0.0021
##      6        1.0418             nan     0.1000   -0.0051
##      7        1.0385             nan     0.1000   -0.0072
##      8        1.0395             nan     0.1000   -0.0047
##      9        1.0408             nan     0.1000   -0.0057
##     10        1.0370             nan     0.1000   -0.0077
##     20        1.0300             nan     0.1000   -0.0078
##     40        1.0162             nan     0.1000   -0.0086
##     60        1.0058             nan     0.1000   -0.0022
##     80        0.9810             nan     0.1000   -0.0049
##    100        0.9571             nan     0.1000   -0.0043
##    120        0.9525             nan     0.1000   -0.0108
##    140        0.9477             nan     0.1000   -0.0079
##    150        0.9413             nan     0.1000   -0.0065
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0738             nan     0.1000    0.0003
##      2        1.0602             nan     0.1000   -0.0023
##      3        1.0575             nan     0.1000    0.0013
##      4        1.0563             nan     0.1000    0.0002
##      5        1.0457             nan     0.1000   -0.0016
##      6        1.0376             nan     0.1000   -0.0014
##      7        1.0381             nan     0.1000   -0.0031
##      8        1.0314             nan     0.1000   -0.0066
##      9        1.0265             nan     0.1000   -0.0042
##     10        1.0271             nan     0.1000   -0.0038
##     20        1.0174             nan     0.1000   -0.0138
##     40        0.9690             nan     0.1000   -0.0051
##     60        0.9618             nan     0.1000   -0.0110
##     80        0.9303             nan     0.1000   -0.0055
##    100        0.9318             nan     0.1000   -0.0059
##    120        0.8992             nan     0.1000   -0.0078
##    140        0.8502             nan     0.1000   -0.0030
##    150        0.8371             nan     0.1000   -0.0085
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0728             nan     0.1000    0.0022
##      2        1.0569             nan     0.1000   -0.0004
##      3        1.0458             nan     0.1000   -0.0028
##      4        1.0369             nan     0.1000   -0.0033
##      5        1.0316             nan     0.1000   -0.0077
##      6        1.0275             nan     0.1000   -0.0061
##      7        1.0276             nan     0.1000   -0.0067
##      8        1.0279             nan     0.1000   -0.0054
##      9        1.0249             nan     0.1000    0.0016
##     10        1.0217             nan     0.1000   -0.0059
##     20        0.9972             nan     0.1000   -0.0036
##     40        0.9411             nan     0.1000   -0.0062
##     60        0.9198             nan     0.1000   -0.0086
##     80        0.9018             nan     0.1000   -0.0093
##    100        0.8739             nan     0.1000   -0.0084
##    120        0.8417             nan     0.1000   -0.0077
##    140        0.8024             nan     0.1000   -0.0029
##    150        0.7946             nan     0.1000   -0.0068
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0669             nan     0.1000   -0.0003
##      2        1.0570             nan     0.1000   -0.0040
##      3        1.0557             nan     0.1000    0.0002
##      4        1.0548             nan     0.1000   -0.0000
##      5        1.0533             nan     0.1000    0.0002
##      6        1.0525             nan     0.1000   -0.0001
##      7        1.0517             nan     0.1000    0.0002
##      8        1.0440             nan     0.1000   -0.0058
##      9        1.0391             nan     0.1000   -0.0064
##     10        1.0362             nan     0.1000   -0.0059
##     20        1.0290             nan     0.1000   -0.0062
##     40        1.0131             nan     0.1000   -0.0071
##     60        0.9871             nan     0.1000   -0.0068
##     80        0.9792             nan     0.1000   -0.0065
##    100        0.9722             nan     0.1000   -0.0074
##    120        0.9638             nan     0.1000   -0.0053
##    140        0.9363             nan     0.1000    0.0057
##    150        0.9327             nan     0.1000   -0.0055
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0773             nan     0.1000    0.0005
##      2        1.0762             nan     0.1000    0.0008
##      3        1.0737             nan     0.1000    0.0020
##      4        1.0722             nan     0.1000   -0.0003
##      5        1.0715             nan     0.1000   -0.0004
##      6        1.0698             nan     0.1000    0.0000
##      7        1.0684             nan     0.1000   -0.0004
##      8        1.0642             nan     0.1000   -0.0005
##      9        1.0505             nan     0.1000   -0.0002
##     10        1.0384             nan     0.1000   -0.0028
##     20        1.0137             nan     0.1000   -0.0082
##     40        0.9966             nan     0.1000    0.0022
##     60        0.9797             nan     0.1000    0.0019
##     80        0.9575             nan     0.1000   -0.0057
##    100        0.9210             nan     0.1000   -0.0031
##    120        0.8961             nan     0.1000   -0.0054
##    140        0.8732             nan     0.1000   -0.0058
##    150        0.8693             nan     0.1000   -0.0064
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0774             nan     0.1000    0.0003
##      2        1.0623             nan     0.1000   -0.0009
##      3        1.0586             nan     0.1000    0.0011
##      4        1.0560             nan     0.1000    0.0009
##      5        1.0438             nan     0.1000   -0.0018
##      6        1.0412             nan     0.1000    0.0003
##      7        1.0367             nan     0.1000    0.0004
##      8        1.0350             nan     0.1000   -0.0003
##      9        1.0265             nan     0.1000   -0.0035
##     10        1.0261             nan     0.1000   -0.0055
##     20        0.9798             nan     0.1000   -0.0048
##     40        0.9387             nan     0.1000   -0.0049
##     60        0.8932             nan     0.1000   -0.0048
##     80        0.8712             nan     0.1000   -0.0039
##    100        0.8456             nan     0.1000   -0.0071
##    120        0.8301             nan     0.1000   -0.0064
##    140        0.7961             nan     0.1000   -0.0050
##    150        0.7917             nan     0.1000   -0.0058
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0508             nan     0.1000   -0.0000
##      2        1.0493             nan     0.1000   -0.0001
##      3        1.0484             nan     0.1000    0.0008
##      4        1.0337             nan     0.1000   -0.0022
##      5        1.0326             nan     0.1000    0.0000
##      6        1.0316             nan     0.1000   -0.0003
##      7        1.0312             nan     0.1000   -0.0002
##      8        1.0209             nan     0.1000   -0.0019
##      9        1.0203             nan     0.1000    0.0003
##     10        1.0134             nan     0.1000   -0.0048
##     20        1.0051             nan     0.1000   -0.0080
##     40        0.9860             nan     0.1000   -0.0065
##     60        0.9587             nan     0.1000    0.0029
##     80        0.9476             nan     0.1000   -0.0065
##    100        0.9401             nan     0.1000   -0.0057
##    120        0.9303             nan     0.1000   -0.0066
##    140        0.9178             nan     0.1000   -0.0066
##    150        0.9225             nan     0.1000   -0.0056
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0494             nan     0.1000    0.0000
##      2        1.0468             nan     0.1000    0.0021
##      3        1.0325             nan     0.1000    0.0002
##      4        1.0307             nan     0.1000   -0.0005
##      5        1.0180             nan     0.1000   -0.0036
##      6        1.0171             nan     0.1000   -0.0001
##      7        1.0163             nan     0.1000    0.0000
##      8        1.0157             nan     0.1000   -0.0003
##      9        1.0088             nan     0.1000   -0.0023
##     10        1.0033             nan     0.1000   -0.0038
##     20        0.9910             nan     0.1000   -0.0025
##     40        0.9646             nan     0.1000   -0.0058
##     60        0.9108             nan     0.1000   -0.0038
##     80        0.8626             nan     0.1000   -0.0033
##    100        0.8275             nan     0.1000   -0.0117
##    120        0.7835             nan     0.1000   -0.0068
##    140        0.7652             nan     0.1000   -0.0058
##    150        0.7589             nan     0.1000   -0.0046
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0347             nan     0.1000    0.0004
##      2        1.0227             nan     0.1000   -0.0043
##      3        1.0196             nan     0.1000    0.0009
##      4        1.0176             nan     0.1000    0.0002
##      5        1.0087             nan     0.1000   -0.0016
##      6        1.0081             nan     0.1000   -0.0030
##      7        1.0087             nan     0.1000   -0.0053
##      8        1.0068             nan     0.1000   -0.0001
##      9        0.9962             nan     0.1000   -0.0038
##     10        0.9950             nan     0.1000   -0.0002
##     20        0.9659             nan     0.1000   -0.0106
##     40        0.8841             nan     0.1000    0.0010
##     60        0.8566             nan     0.1000   -0.0045
##     80        0.8048             nan     0.1000   -0.0045
##    100        0.7683             nan     0.1000   -0.0061
##    120        0.7509             nan     0.1000   -0.0070
##    140        0.7245             nan     0.1000   -0.0042
##    150        0.7105             nan     0.1000   -0.0111
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        0.4078             nan     0.1000    0.0008
##      2        0.4062             nan     0.1000    0.0003
##      3        0.4051             nan     0.1000    0.0002
##      4        0.4043             nan     0.1000    0.0007
##      5        0.4033             nan     0.1000    0.0000
##      6        0.4024             nan     0.1000   -0.0003
##      7        0.4015             nan     0.1000   -0.0003
##      8        0.4004             nan     0.1000    0.0004
##      9        0.3999             nan     0.1000   -0.0003
##     10        0.3992             nan     0.1000    0.0001
##     20        0.3941             nan     0.1000   -0.0003
##     40        0.3881             nan     0.1000   -0.0001
##     60        0.3848             nan     0.1000   -0.0001
##     80        0.3827             nan     0.1000   -0.0001
##    100        0.3818             nan     0.1000   -0.0010
##    120        0.3800             nan     0.1000   -0.0003
##    140        0.3778             nan     0.1000   -0.0000
##    150        0.3770             nan     0.1000   -0.0001
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        0.4063             nan     0.1000    0.0002
##      2        0.4042             nan     0.1000    0.0006
##      3        0.4025             nan     0.1000    0.0005
##      4        0.4011             nan     0.1000   -0.0002
##      5        0.3984             nan     0.1000    0.0019
##      6        0.3974             nan     0.1000    0.0006
##      7        0.3949             nan     0.1000   -0.0002
##      8        0.3938             nan     0.1000   -0.0008
##      9        0.3903             nan     0.1000   -0.0011
##     10        0.3896             nan     0.1000   -0.0005
##     20        0.3765             nan     0.1000    0.0000
##     40        0.3669             nan     0.1000   -0.0011
##     60        0.3550             nan     0.1000   -0.0004
##     80        0.3477             nan     0.1000   -0.0005
##    100        0.3409             nan     0.1000   -0.0010
##    120        0.3365             nan     0.1000   -0.0010
##    140        0.3326             nan     0.1000   -0.0002
##    150        0.3280             nan     0.1000   -0.0007
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        0.4052             nan     0.1000    0.0020
##      2        0.4028             nan     0.1000    0.0016
##      3        0.4016             nan     0.1000    0.0002
##      4        0.3987             nan     0.1000    0.0010
##      5        0.3969             nan     0.1000    0.0002
##      6        0.3952             nan     0.1000    0.0001
##      7        0.3926             nan     0.1000   -0.0000
##      8        0.3907             nan     0.1000   -0.0004
##      9        0.3891             nan     0.1000    0.0001
##     10        0.3872             nan     0.1000   -0.0003
##     20        0.3761             nan     0.1000   -0.0001
##     40        0.3527             nan     0.1000   -0.0005
##     60        0.3418             nan     0.1000   -0.0014
##     80        0.3272             nan     0.1000   -0.0004
##    100        0.3201             nan     0.1000   -0.0010
##    120        0.3125             nan     0.1000   -0.0004
##    140        0.3051             nan     0.1000   -0.0004
##    150        0.3020             nan     0.1000   -0.0008
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0843             nan     0.1000   -0.0006
##      2        1.0827             nan     0.1000    0.0002
##      3        1.0714             nan     0.1000   -0.0019
##      4        1.0642             nan     0.1000   -0.0032
##      5        1.0578             nan     0.1000   -0.0103
##      6        1.0545             nan     0.1000   -0.0046
##      7        1.0522             nan     0.1000   -0.0032
##      8        1.0504             nan     0.1000   -0.0045
##      9        1.0510             nan     0.1000   -0.0039
##     10        1.0521             nan     0.1000   -0.0058
##     20        1.0444             nan     0.1000   -0.0050
##     40        1.0251             nan     0.1000   -0.0075
##     60        1.0140             nan     0.1000   -0.0073
##     80        0.9848             nan     0.1000    0.0036
##    100        0.9762             nan     0.1000   -0.0042
##    120        0.9633             nan     0.1000   -0.0060
##    140        0.9410             nan     0.1000   -0.0042
##    150        0.9392             nan     0.1000   -0.0046
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0960             nan     0.1000    0.0011
##      2        1.0934             nan     0.1000    0.0013
##      3        1.0894             nan     0.1000   -0.0009
##      4        1.0880             nan     0.1000    0.0002
##      5        1.0866             nan     0.1000   -0.0003
##      6        1.0850             nan     0.1000    0.0001
##      7        1.0841             nan     0.1000   -0.0000
##      8        1.0831             nan     0.1000   -0.0003
##      9        1.0819             nan     0.1000   -0.0003
##     10        1.0663             nan     0.1000   -0.0013
##     20        1.0294             nan     0.1000   -0.0053
##     40        0.9755             nan     0.1000   -0.0022
##     60        0.9432             nan     0.1000   -0.0044
##     80        0.9429             nan     0.1000   -0.0064
##    100        0.9341             nan     0.1000   -0.0068
##    120        0.9263             nan     0.1000   -0.0053
##    140        0.9088             nan     0.1000   -0.0063
##    150        0.8882             nan     0.1000   -0.0029
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0955             nan     0.1000    0.0003
##      2        1.0773             nan     0.1000   -0.0025
##      3        1.0727             nan     0.1000    0.0037
##      4        1.0697             nan     0.1000   -0.0005
##      5        1.0583             nan     0.1000   -0.0038
##      6        1.0564             nan     0.1000    0.0006
##      7        1.0490             nan     0.1000   -0.0073
##      8        1.0498             nan     0.1000   -0.0060
##      9        1.0504             nan     0.1000   -0.0041
##     10        1.0482             nan     0.1000    0.0001
##     20        1.0271             nan     0.1000   -0.0042
##     40        0.9928             nan     0.1000   -0.0057
##     60        0.9728             nan     0.1000   -0.0049
##     80        0.9425             nan     0.1000   -0.0067
##    100        0.9321             nan     0.1000   -0.0066
##    120        0.9247             nan     0.1000   -0.0064
##    140        0.8998             nan     0.1000    0.0016
##    150        0.8946             nan     0.1000   -0.0046
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0531             nan     0.1000   -0.0013
##      2        1.0518             nan     0.1000    0.0001
##      3        1.0410             nan     0.1000   -0.0052
##      4        1.0345             nan     0.1000   -0.0039
##      5        1.0337             nan     0.1000    0.0006
##      6        1.0285             nan     0.1000   -0.0041
##      7        1.0253             nan     0.1000   -0.0065
##      8        1.0268             nan     0.1000   -0.0069
##      9        1.0257             nan     0.1000    0.0002
##     10        1.0231             nan     0.1000   -0.0084
##     20        1.0114             nan     0.1000    0.0030
##     40        0.9968             nan     0.1000    0.0023
##     60        0.9788             nan     0.1000   -0.0053
##     80        0.9543             nan     0.1000    0.0045
##    100        0.9353             nan     0.1000    0.0029
##    120        0.9184             nan     0.1000   -0.0048
##    140        0.9042             nan     0.1000   -0.0041
##    150        0.8884             nan     0.1000   -0.0041
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0509             nan     0.1000    0.0018
##      2        1.0493             nan     0.1000    0.0008
##      3        1.0471             nan     0.1000    0.0004
##      4        1.0375             nan     0.1000   -0.0024
##      5        1.0342             nan     0.1000   -0.0010
##      6        1.0351             nan     0.1000   -0.0045
##      7        1.0337             nan     0.1000    0.0009
##      8        1.0255             nan     0.1000   -0.0054
##      9        1.0195             nan     0.1000   -0.0050
##     10        1.0209             nan     0.1000   -0.0075
##     20        1.0002             nan     0.1000    0.0040
##     40        0.9564             nan     0.1000   -0.0016
##     60        0.9087             nan     0.1000   -0.0051
##     80        0.8899             nan     0.1000   -0.0041
##    100        0.8453             nan     0.1000   -0.0026
##    120        0.7886             nan     0.1000   -0.0037
##    140        0.7666             nan     0.1000   -0.0058
##    150        0.7612             nan     0.1000   -0.0039
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0506             nan     0.1000    0.0000
##      2        1.0403             nan     0.1000   -0.0019
##      3        1.0382             nan     0.1000    0.0011
##      4        1.0275             nan     0.1000   -0.0055
##      5        1.0209             nan     0.1000   -0.0043
##      6        1.0166             nan     0.1000   -0.0044
##      7        1.0158             nan     0.1000   -0.0077
##      8        1.0158             nan     0.1000   -0.0036
##      9        1.0094             nan     0.1000   -0.0029
##     10        1.0099             nan     0.1000   -0.0044
##     20        0.9477             nan     0.1000   -0.0031
##     40        0.8930             nan     0.1000   -0.0057
##     60        0.8481             nan     0.1000   -0.0008
##     80        0.8474             nan     0.1000   -0.0039
##    100        0.8182             nan     0.1000   -0.0041
##    120        0.7849             nan     0.1000   -0.0058
##    140        0.7637             nan     0.1000   -0.0096
##    150        0.7501             nan     0.1000   -0.0049
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0157             nan     0.1000    0.0001
##      2        1.0017             nan     0.1000   -0.0003
##      3        0.9916             nan     0.1000   -0.0016
##      4        0.9909             nan     0.1000    0.0003
##      5        0.9904             nan     0.1000   -0.0001
##      6        0.9827             nan     0.1000   -0.0067
##      7        0.9768             nan     0.1000   -0.0034
##      8        0.9791             nan     0.1000   -0.0077
##      9        0.9746             nan     0.1000   -0.0040
##     10        0.9712             nan     0.1000   -0.0066
##     20        0.9801             nan     0.1000   -0.0029
##     40        0.9574             nan     0.1000   -0.0043
##     60        0.9424             nan     0.1000   -0.0095
##     80        0.9299             nan     0.1000   -0.0073
##    100        0.9013             nan     0.1000   -0.0089
##    120        0.8893             nan     0.1000   -0.0042
##    140        0.8833             nan     0.1000   -0.0038
##    150        0.8857             nan     0.1000   -0.0034
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        0.9994             nan     0.1000   -0.0011
##      2        0.9887             nan     0.1000   -0.0006
##      3        0.9808             nan     0.1000   -0.0036
##      4        0.9734             nan     0.1000   -0.0086
##      5        0.9707             nan     0.1000    0.0005
##      6        0.9665             nan     0.1000   -0.0049
##      7        0.9634             nan     0.1000   -0.0055
##      8        0.9634             nan     0.1000   -0.0031
##      9        0.9635             nan     0.1000   -0.0031
##     10        0.9645             nan     0.1000   -0.0069
##     20        0.9565             nan     0.1000   -0.0255
##     40        0.9371             nan     0.1000   -0.0093
##     60        0.9018             nan     0.1000   -0.0055
##     80        0.8948             nan     0.1000   -0.0064
##    100        0.8617             nan     0.1000   -0.0047
##    120        0.8107             nan     0.1000   -0.0037
##    140        0.7953             nan     0.1000   -0.0051
##    150        0.7953             nan     0.1000   -0.0027
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0146             nan     0.1000   -0.0002
##      2        0.9988             nan     0.1000    0.0029
##      3        0.9880             nan     0.1000   -0.0013
##      4        0.9849             nan     0.1000   -0.0002
##      5        0.9830             nan     0.1000    0.0002
##      6        0.9734             nan     0.1000   -0.0054
##      7        0.9662             nan     0.1000   -0.0060
##      8        0.9668             nan     0.1000   -0.0047
##      9        0.9678             nan     0.1000   -0.0068
##     10        0.9686             nan     0.1000   -0.0052
##     20        0.9423             nan     0.1000   -0.0045
##     40        0.8716             nan     0.1000   -0.0041
##     60        0.8430             nan     0.1000   -0.0058
##     80        0.8019             nan     0.1000   -0.0039
##    100        0.7906             nan     0.1000   -0.0052
##    120        0.7744             nan     0.1000   -0.0041
##    140        0.7572             nan     0.1000   -0.0058
##    150        0.7421             nan     0.1000   -0.0081
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0546             nan     0.1000    0.0000
##      2        1.0392             nan     0.1000   -0.0003
##      3        1.0284             nan     0.1000   -0.0018
##      4        1.0272             nan     0.1000   -0.0005
##      5        1.0175             nan     0.1000   -0.0038
##      6        1.0109             nan     0.1000   -0.0071
##      7        1.0073             nan     0.1000   -0.0027
##      8        1.0050             nan     0.1000   -0.0119
##      9        1.0032             nan     0.1000   -0.0088
##     10        1.0028             nan     0.1000   -0.0050
##     20        0.9977             nan     0.1000    0.0015
##     40        0.9801             nan     0.1000   -0.0080
##     60        0.9766             nan     0.1000   -0.0117
##     80        0.9625             nan     0.1000   -0.0072
##    100        0.9537             nan     0.1000   -0.0004
##    120        0.9434             nan     0.1000   -0.0091
##    140        0.9350             nan     0.1000   -0.0058
##    150        0.9317             nan     0.1000   -0.0032
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0407             nan     0.1000    0.0006
##      2        1.0378             nan     0.1000    0.0028
##      3        1.0341             nan     0.1000    0.0004
##      4        1.0328             nan     0.1000    0.0000
##      5        1.0315             nan     0.1000    0.0007
##      6        1.0186             nan     0.1000   -0.0011
##      7        1.0089             nan     0.1000   -0.0043
##      8        1.0022             nan     0.1000   -0.0020
##      9        0.9970             nan     0.1000   -0.0050
##     10        0.9982             nan     0.1000   -0.0062
##     20        0.9753             nan     0.1000   -0.0069
##     40        0.9621             nan     0.1000   -0.0047
##     60        0.9478             nan     0.1000   -0.0029
##     80        0.9453             nan     0.1000   -0.0056
##    100        0.9434             nan     0.1000   -0.0066
##    120        0.9200             nan     0.1000   -0.0069
##    140        0.9071             nan     0.1000   -0.0054
##    150        0.8920             nan     0.1000   -0.0080
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0385             nan     0.1000    0.0025
##      2        1.0257             nan     0.1000   -0.0010
##      3        1.0139             nan     0.1000   -0.0009
##      4        1.0111             nan     0.1000    0.0002
##      5        1.0032             nan     0.1000   -0.0080
##      6        0.9976             nan     0.1000   -0.0077
##      7        0.9933             nan     0.1000   -0.0099
##      8        0.9908             nan     0.1000   -0.0078
##      9        0.9894             nan     0.1000   -0.0030
##     10        0.9890             nan     0.1000   -0.0146
##     20        0.9644             nan     0.1000   -0.0068
##     40        0.9525             nan     0.1000   -0.0048
##     60        0.9279             nan     0.1000   -0.0067
##     80        0.8929             nan     0.1000   -0.0047
##    100        0.8866             nan     0.1000   -0.0028
##    120        0.8648             nan     0.1000   -0.0083
##    140        0.8624             nan     0.1000   -0.0054
##    150        0.8299             nan     0.1000   -0.0028
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0563             nan     0.1000   -0.0011
##      2        1.0555             nan     0.1000    0.0006
##      3        1.0461             nan     0.1000   -0.0027
##      4        1.0445             nan     0.1000   -0.0004
##      5        1.0436             nan     0.1000    0.0004
##      6        1.0353             nan     0.1000   -0.0071
##      7        1.0312             nan     0.1000   -0.0050
##      8        1.0286             nan     0.1000   -0.0060
##      9        1.0272             nan     0.1000   -0.0096
##     10        1.0261             nan     0.1000   -0.0053
##     20        1.0137             nan     0.1000    0.0057
##     40        1.0001             nan     0.1000   -0.0123
##     60        0.9839             nan     0.1000   -0.0020
##     80        0.9711             nan     0.1000    0.0049
##    100        0.9559             nan     0.1000   -0.0059
##    120        0.9424             nan     0.1000   -0.0043
##    140        0.9347             nan     0.1000   -0.0043
##    150        0.9246             nan     0.1000   -0.0048
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0564             nan     0.1000   -0.0006
##      2        1.0444             nan     0.1000   -0.0030
##      3        1.0361             nan     0.1000   -0.0033
##      4        1.0295             nan     0.1000   -0.0032
##      5        1.0236             nan     0.1000   -0.0087
##      6        1.0205             nan     0.1000   -0.0062
##      7        1.0208             nan     0.1000   -0.0060
##      8        1.0209             nan     0.1000   -0.0039
##      9        1.0176             nan     0.1000   -0.0093
##     10        1.0166             nan     0.1000   -0.0083
##     20        0.9964             nan     0.1000   -0.0058
##     40        0.9616             nan     0.1000   -0.0116
##     60        0.9400             nan     0.1000   -0.0134
##     80        0.8810             nan     0.1000   -0.0039
##    100        0.8625             nan     0.1000   -0.0014
##    120        0.8322             nan     0.1000   -0.0035
##    140        0.8250             nan     0.1000   -0.0067
##    150        0.7868             nan     0.1000   -0.0078
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0544             nan     0.1000   -0.0008
##      2        1.0522             nan     0.1000    0.0004
##      3        1.0389             nan     0.1000   -0.0009
##      4        1.0392             nan     0.1000   -0.0029
##      5        1.0375             nan     0.1000    0.0004
##      6        1.0351             nan     0.1000   -0.0003
##      7        1.0249             nan     0.1000   -0.0022
##      8        1.0225             nan     0.1000    0.0008
##      9        1.0200             nan     0.1000    0.0001
##     10        1.0181             nan     0.1000   -0.0006
##     20        0.9871             nan     0.1000    0.0018
##     40        0.9596             nan     0.1000   -0.0067
##     60        0.9329             nan     0.1000   -0.0032
##     80        0.8885             nan     0.1000   -0.0052
##    100        0.8394             nan     0.1000   -0.0065
##    120        0.8246             nan     0.1000   -0.0055
##    140        0.7758             nan     0.1000   -0.0046
##    150        0.7596             nan     0.1000   -0.0036
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0622             nan     0.1000   -0.0010
##      2        1.0605             nan     0.1000   -0.0001
##      3        1.0599             nan     0.1000   -0.0000
##      4        1.0480             nan     0.1000   -0.0007
##      5        1.0417             nan     0.1000   -0.0004
##      6        1.0406             nan     0.1000    0.0003
##      7        1.0341             nan     0.1000   -0.0062
##      8        1.0296             nan     0.1000   -0.0052
##      9        1.0271             nan     0.1000   -0.0081
##     10        1.0287             nan     0.1000   -0.0077
##     20        1.0188             nan     0.1000   -0.0068
##     40        1.0057             nan     0.1000   -0.0084
##     60        1.0000             nan     0.1000    0.0005
##     80        0.9784             nan     0.1000   -0.0041
##    100        0.9667             nan     0.1000   -0.0079
##    120        0.9480             nan     0.1000   -0.0060
##    140        0.9352             nan     0.1000   -0.0061
##    150        0.9320             nan     0.1000   -0.0054
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0721             nan     0.1000    0.0006
##      2        1.0698             nan     0.1000    0.0011
##      3        1.0558             nan     0.1000   -0.0004
##      4        1.0442             nan     0.1000   -0.0016
##      5        1.0429             nan     0.1000   -0.0002
##      6        1.0341             nan     0.1000   -0.0038
##      7        1.0347             nan     0.1000   -0.0036
##      8        1.0324             nan     0.1000    0.0012
##      9        1.0263             nan     0.1000   -0.0054
##     10        1.0244             nan     0.1000   -0.0011
##     20        0.9960             nan     0.1000   -0.0068
##     40        0.9466             nan     0.1000    0.0013
##     60        0.9157             nan     0.1000    0.0012
##     80        0.9040             nan     0.1000   -0.0062
##    100        0.8940             nan     0.1000   -0.0048
##    120        0.8374             nan     0.1000   -0.0093
##    140        0.8088             nan     0.1000   -0.0030
##    150        0.8043             nan     0.1000   -0.0056
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.0579             nan     0.1000   -0.0003
##      2        1.0547             nan     0.1000    0.0012
##      3        1.0524             nan     0.1000    0.0003
##      4        1.0390             nan     0.1000   -0.0026
##      5        1.0362             nan     0.1000    0.0024
##      6        1.0342             nan     0.1000    0.0007
##      7        1.0320             nan     0.1000   -0.0007
##      8        1.0220             nan     0.1000   -0.0070
##      9        1.0152             nan     0.1000   -0.0036
##     10        1.0158             nan     0.1000   -0.0056
##     20        0.9826             nan     0.1000   -0.0145
##     40        0.9328             nan     0.1000    0.0005
##     60        0.8805             nan     0.1000   -0.0078
##     80        0.8478             nan     0.1000   -0.0061
##    100        0.8298             nan     0.1000   -0.0056
##    120        0.8086             nan     0.1000   -0.0064
##    140        0.7849             nan     0.1000   -0.0045
##    150        0.7700             nan     0.1000   -0.0015
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        0.9878             nan     0.1000    0.0001
##      2        0.9871             nan     0.1000    0.0005
##      3        0.9788             nan     0.1000   -0.0028
##      4        0.9779             nan     0.1000    0.0004
##      5        0.9713             nan     0.1000   -0.0033
##      6        0.9707             nan     0.1000    0.0006
##      7        0.9672             nan     0.1000   -0.0011
##      8        0.9642             nan     0.1000   -0.0033
##      9        0.9614             nan     0.1000   -0.0031
##     10        0.9624             nan     0.1000   -0.0045
##     20        0.9522             nan     0.1000   -0.0070
##     40        0.9289             nan     0.1000    0.0026
##     60        0.9165             nan     0.1000   -0.0045
##     80        0.9000             nan     0.1000   -0.0044
##    100        0.8930             nan     0.1000   -0.0058
##    120        0.8723             nan     0.1000   -0.0026
##    140        0.8709             nan     0.1000   -0.0044
##    150        0.8562             nan     0.1000   -0.0048

gbmFit

## Stochastic Gradient Boosting 
## 
## 5207 samples
##   37 predictor
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 4686, 4687, 4685, 4686, 4687, 4687, ... 
## Resampling results across tuning parameters:
## 
##   interaction.depth  n.trees  RMSE       Rsquared     MAE      
##   1                   50      0.8302885  0.006769974  0.2570549
##   1                  100      0.8399081  0.007736524  0.2590773
##   1                  150      0.8288418  0.007904398  0.2559856
##   2                   50      0.8293711  0.012863443  0.2544807
##   2                  100      0.8415449  0.013501280  0.2561651
##   2                  150      0.8456839  0.019501219  0.2570319
##   3                   50      0.8379272  0.014209535  0.2558103
##   3                  100      0.8398891  0.017319809  0.2563939
##   3                  150      0.8481992  0.017966826  0.2604332
## 
## Tuning parameter &#39;shrinkage&#39; was held constant at a value of 0.1
## Tuning parameter &#39;n.minobsinnode&#39; was held constant at a value
##  of 10
## RMSE was used to select the optimal model using the smallest value.
## The final values used for the model were n.trees = 150, interaction.depth = 1, shrinkage = 0.1 and n.minobsinnode = 10.

# create the prediction
pred2 &lt;- predict(gbmFit, newdata = newsPopTest)

# compare the prediction vs the actual
resample2 &lt;- postResample(pred2, obs = newsPopTest$shares)
resample2

##        RMSE    Rsquared         MAE 
## 1.673504344 0.002972075 0.299653937</code></pre>
<h3 id="linear-regression-model">Linear Regression Model</h3>
<p>Linear regression is used to predict the outcome of a response variable for 1 to n predictors. The aim is to establish a linear relationship between the predictor variable(s) and response variable so we can predict the value of the response when only the predictor variable(s) is(are) known.</p>
<pre><code># train the linear model for main effects + interactions on first 3 preds
lmFit &lt;- train(shares ~ timedelta*n_tokens_title*n_tokens_content, data = newsPopTrain,
                                                                   method = &quot;lm&quot;, preProces = c(&quot;center&quot;, &quot;scale&quot;),
                                                                   trControl = trainControl(method = &quot;cv&quot;, number = 10))
lmFit

## Linear Regression 
## 
## 5207 samples
##    3 predictor
## 
## Pre-processing: centered (7), scaled (7) 
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 4686, 4687, 4686, 4687, 4686, 4687, ... 
## Resampling results:
## 
##   RMSE       Rsquared     MAE      
##   0.8173304  0.004894377  0.2614436
## 
## Tuning parameter &#39;intercept&#39; was held constant at a value of TRUE

# create the prediction
pred3 &lt;- predict(lmFit, newdata = newsPopTest)

# compare the prediction vs the actual
resample3 &lt;- postResample(pred3, obs = newsPopTest$shares)
resample3

##         RMSE     Rsquared          MAE 
## 1.6684085434 0.0002962049 0.2969239559</code></pre>
<h3 id="comparison">Comparison</h3>
<p>Below is a comparison of the 3 methods. All have relatively high root mean square errors.</p>
<pre><code># compare results from 3 methods
comparison &lt;- data.frame(&quot;RSME&quot; = c(resample1[[1]], resample2[[1]], resample3[1]), &quot;MAE&quot; = c(resample1[[3]], resample2[[3]], resample3[[3]]))
rownames(comparison) &lt;- c(&quot;RPART&quot;,&quot;GBM&quot;, &quot;LM&quot;)
kable(comparison)</code></pre>
<table>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
RSME
</th>
<th style="text-align:right;">
MAE
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
RPART
</td>
<td style="text-align:right;">
1.668033
</td>
<td style="text-align:right;">
0.2935443
</td>
</tr>
<tr>
<td style="text-align:left;">
GBM
</td>
<td style="text-align:right;">
1.673504
</td>
<td style="text-align:right;">
0.2996539
</td>
</tr>
<tr>
<td style="text-align:left;">
LM
</td>
<td style="text-align:right;">
1.668408
</td>
<td style="text-align:right;">
0.2969240
</td>
</tr>
</tbody>
</table>

</body>
</html>
